#+STARTUP: inlineimages
#+OPTIONS: ^:{}

* [2015-09-30 mer.]
** which-func for org-mode                                            :emacs:
:PROPERTIES:
:header-args: :results none
:END:
Trying to come up with a fast equivalent to ~which-func-mode~ under Spacemacs.
The most naive implementation would be to lookup backward for the first heading.

#+BEGIN_SRC elisp
(spacemacs|define-mode-line-segment which-org-headline-segment
  (fmdkdd/org-current-headline)
  :when (eq major-mode 'org-mode))

(add-to-list 'spacemacs|define-mode-line-segment 'which-org-headline-segment t)

(defun fmdkdd/org-current-headline ()
  (save-excursion
    (re-search-backward org-complex-heading-regexp nil t)
    (match-string-no-properties 4)))
#+END_SRC

That does not give you the full current hierarchy (bread crumbs).
Actually, there is an ~org-get-heading~.

#+BEGIN_SRC elisp
(spacemacs|define-mode-line-segment which-org-headline-segment
  (org-get-heading)
  :when (eq major-mode 'org-mode))
#+END_SRC

It even gives us the font-lock properties.

There is also a ~org-get-outline-path~ that gives the rest of the crumbs.

#+BEGIN_SRC elisp
(spacemacs|define-mode-line-segment which-org-headline-segment
  (fmdkdd/org-current-headline)
  :when (eq major-mode 'org-mode))

(defun fmdkdd/org-current-headline ()
  (let ((path (append (org-get-outline-path)
                      (cons (org-get-heading t t) nil))))
    (org-format-outline-path path 40)))
#+END_SRC

Removing the text properties can be achieved by calling
~substring-no-properties~.  Though I rather like the effect as is.

Another, longer (but more proper?) way of removing them is the following:

#+BEGIN_SRC elisp
(defun fmdkdd/org-current-headline ()
  (let* ((path (append (org-get-outline-path)
                      (cons (org-get-heading t t) nil)))
        (formatted (org-format-outline-path path 40)))
    (set-text-properties 0 (length formatted) nil formatted)
    formatted))
#+END_SRC

* [2015-10-01 jeu.]
** Collaborative editing in Emacs                                     :emacs:
I would like to be able to use Emacs for collaborative editing.  I have light
requirements:

- over local network would suffice.  I just want to be able to share a buffer
  with someone next to me, each with their own computer.  For pair programming
  or teaching.
- I don’t care much about security: I trust the other person since she is right
  next to me.  When we finish, the computer should not be left in a vulnerable
  state however.
- I prefer to stay with my own Spacemacs config, rather than having to use the
  config of the peer.
- it should be painless to setup, and stable.

This [[http://stackoverflow.com/questions/12546722/using-emacs-server-and-emacsclient-on-other-machines-as-other-users][SO thread]] is a good start.

The scenario is as follows.  Host is where the files to be modified reside.
Host has an Emacs session and buffer on file A.  Client wants to drop in Host
and take control of Emacs from his machine, and edit the same buffer.  He can
also split windows, switch buffers, etc.

*** Using tramp and ssh
Client needs ssh access to Host.  Client can browse to file A from his Emacs.

However, Host will not see the changes until Client saves.  This is
insufficient.

*** Using ~make-frame-on-display~
Emacs can spawn a frame on another X display.

The requirements:

- Allow X to listen to TCP connections.

  Under Ubuntu, X is spawned by lightdm, so, in =/etc/lightdm/lightdm.conf=
  : xserver-allow-tcp=true

  and restart lightdm.

- After that, allow the Host to access the X server with xhost
  : xhost +host

  In Ubuntu, my LAN machines can be accessed via =host.local=.

  One can also use ~xauth~ here, as described in the SO thread.  Deauthorize the
  Host with ~xhost -host~.

- Finally, the Host can spawn a frame from its Emacs on the client display
  server with
  : make-frame-on-display client.local:0

Now, Client can write in the buffer, and Host can see the changes.  Both can
even edit at the same time.

Seems stable.  There is the issue that if any of the peer starts a modal action
(helm lookup, M-x minibuffer spawn), the other cannot type anymore.  When the
modal action is over, the input will be sent to the frame however.

This is a distinct frame, so Client cannot control the Emacs frame on Host.
Splitting windows should be done on both machines.  Client can browse the Host
files.

Host only has one command to spawn.  But Client needs to restart X before
pairing, because tcplisten seems like a fun backdoor to leave open.

Alas, Client is stuck with the Emacs configuration from Host.  This cannot be
avoided, since there is only one Emacs process.

*** Using tmux
As suggested [[http://www.emacswiki.org/emacs/tmux_for_collaborative_editing][there]].  However, I could not make the socket sharing work.

Rather, sharing the same tmux session is simple:

- Host does ~tmux new -s pp~ to create a new session named ‘pp’.
- Client does (connected on Host) ~tmux attach -t pp~ to join the session.

With tmux, Client can connect to Host using ssh, and join a tmux session.  Both
share the same cursor.

Since tmux is terminal-based, Emacs runs in tty mode.  Functionality is the
same, but can be unfamiliar for Host.  Using frames would be possible through
ssh X forwarding, but that would not give us more than the previous solution.

Client has to use Host Emacs config, again.  The setup is also slightly more
involved with Host.

But, sharing through tmux is useful beyond Emacs.  So there is that.  And this
solution should work well over the network (if you can ssh to Host).

There is even a wrapper around tmux called [[https://github.com/zolrath/wemux/][wemux]] which simplifies the setup and
provides relevant options for multiple peers.

*** Using floobits
A proprietary web service.  Use a Github account, create a workspace (?) and
share files.  Other users you have authorized can then access the workspace, and
you can see the changes in realtime in your editor if you are viewing the same
file.

Rather nice is that every peer is using his own machine and editor.

However, it goes through the Floobits server, thus it’s pretty slow compared to
the previous solutions.

And there is the requirement of going through a workspace.  It might make sense
for collaborative realtime editing of a project, though I’d rather use Git then.
But it’s cumbersome to setup when playing on a throwaway file.

The nail in the coffin is of course having to go through a third-party.  If the
server software was at least available as open source, I could run a local
instance and that would be a pretty good solution.  Alas, that does not appear
to be the case.

*** Using rudel
[[http://rudel.sourceforge.net/][Rudel]] is an Emacs package which share functionality with Floobits.

One Emacs must host a rudel session.  Others can join.  The host does not take
part in collaborative editing.  The host passes editing data from one peer to
another using an open protocol.  Other clients can join.

Users in a session can publish a buffer, and others can subscribe to it.  When
you subscribe to a buffer, Rudel opens a new window with the buffer text
inside.  You can then edit the text with your own cursor, and editor.  Changes
are highlighted with the color of each user (that can be disabled through the
menu option, thankfully).

Rudel is intended to work with menu-bar-mode on, it seems.

I don’t know what data Rudel sends, but from the project website, it seems it
can break the functionality of some modes like EShell.  This behavior can be
troubling.

I’m not sure what exactly is the buffer a client edits: does it have a local
copy?  Does it exist only temporarily?

Speed is alright, but slower than tmux and xhost.

Also, the setup is a bit more involved, and the package is in dire need of
maintenance.
* [2015-10-21 mer.]
** Explanations
In web apps, I find it would be useful to be able to ask why a value is 0, or
NaN.  E.g., why a DOM element has its ‘left’ property to ‘12px’.  I would like
to find the culprit code immediately.  Alas, there are no ‘conditional
breakpoints’ in Firefox or Chrome.

Wait, there are!  You can break on attribute modification by right-clicking a
DOM in the Elements panel in Chrome.  In FF, you can conditionally /stop/ a
breakpoint, but not break conditionally.

Anyway, jumping into the debugger when a value is modified is only one part of
the workflow.  That gives you the place where the value is set, but not how the
right-hand side was computed.  You have to backtrack through the call stack to
get this information.

Instead, if a value contains its history, the explanation is always available.
See [[file:javascript/explanation.js][explanation.js]] for a minimal proof of concept.

** Interactive value inspector in s3c                                   :s3c:
Trying to add interactive value inspectors into s3c.

*** Rationale
Instead of plain text, the editor should put an HTML element that represents the
full object, like in Firefox or Chrome consoles.  Each property can be
inspected.

- Why do you need that?  The current behavior of displaying serialized objects
  is good enough for small programs.  At least you have all the properties on
  display at once.  With an “interactive” object, you have to click to view
  further properties...

- The current behavior is nice and simple, true.  But for larger objects, it
  is unwieldy.  Also, an interactive value inspector opens the door for
  interactive “explanations” of values: backtrack through the code that created
  some value in order to understand why it’s a NaN, or 0, or ...

- Do you really need explanations?  I mean, in a full application it could be
  nice (provided a good signal-to-noise ratio), but s3c is for simple JavaScript
  code for beginners.  To find out why a value is NaN, just add more //: to
  track the flow.

*** Implementation
CodeMirror provides two functions: ~addWidget~ and ~addLineWidget~.  ~addWidget~
puts an HTML element on a line with absolute positioning.  So I can create HTML
to inspect an object, and put it after the delimiter.  It does not matter if the
element is larger than the line: with a positive z-index, it will appear as if
floating over the text.

To do that, in ~write~, instead of replacing, I can call:

: editor.addWidget({line: l}, p, false, "above")

The last argument is undocumented, but it puts the element /on/ the given line
rather than below (the default).

However, the element is absolutely positioned.  It does not move when the line
does, which breaks the illusion that it gives a view of the value to the left of
the delimiter.

To sync the widget, I would need to listen on changes on the document, and move
all markers that are potentially affected.  It is not sufficient to listen to
the ~change~ event of a line, as when a line is moved as a side-effect of
inserting a new line above, no change event is fired.

The ~addLineWidget~ is quite different, as it inserts the element below the line
and appears to be inset /in/ the text.  The lines it takes are not numbered, and
are skipped by the cursor.  It behaves correctly when inserting new lines.  Bit
of a space hog currently, as it eats vertical space rather than making use of
the usually empty space at the right of the screen.

Hacking the DOM created by CodeMirror sounds like a bad idea, if only for
forward compatibility.

* [2015-12-02 mer.]
** Free monad for interpreters
Reading up on free monads.  Again.  And discussing them with Ronan.

Beyond [[http://programmers.stackexchange.com/questions/242795/what-is-the-free-monad-interpreter-pattern][this blog post]], [[http://programmers.stackexchange.com/questions/242795/what-is-the-free-monad-interpreter-pattern][this SO answer]] is particularly helpful.

On a related note, even setting up a Free monad can be seen as boilerplate.
[[http://okmij.org/ftp/Computation/free-monad.html][Okmij shows]] how to eliminate the noise.

* [2015-12-09 mer.]
** GameBoy Sound player                                                 :gbs:
The sound component of Boyo is a mess.  It sort-of works, but there are weird
artifacts coming out after a while.  And it’s eating at least 20% CPU.  And it
doesn’t even pass blargg’s tests!

I want to start from a clean state, and understand how the damn thing works.
Maybe writing a player for GBS files would be a more appropriate target?  I’m
curious as to what these files store anyway.  Can’t be samples, or they would
directly be in a sound format.  So they must be instructions directly from the
ROM, but probably only the instructions relevant to the audio?

Found a [[http://ocremix.org/info/GBS_Format_Specification][spec]] for GBS files.  At that point, eww does not seem capable of
downloading a sample GBS from Zophar.

Got some GBS.  They are indeed smaller than the ROM file from which they are
extracted.  Pokemon Red ROM is 376K while the GBS is 48K for instance.

Looking at the source for gbsplay, it seems indeed that playing the files means
emulating the CPU and the audio unit.

Maybe what would be nice is if we could compile the output from a GBS into audio
instructions only.  To get an output similar to what MOD file looks like for
trackers.  GBS to MOD converter.

* [2015-12-11 ven.]
** GameBoy Sound player                                            :gbs:rust:
Will try to go with rust-lang.  Why not make it harder on myself?  At least if I
don’t complete the project, I’ll have learned the basics of a new language.

Someone already did a library for [[https://github.com/emu-rs/spc][reading spc]] in Rust!  This will help.

* [2015-12-12 sam.]
** Learning Rust                                                       :rust:
The proof of concept code I wrote yesterday worked, but some pieces went over my
head.  Today I went over the [[https://doc.rust-lang.org/stable/book/][Rust book]] to RTFM.

Now, I know how I should use result types to avoid deconstructing with match so
much.  And also how to put my utility functions in a module for better
organization in the long term.

* [2015-12-19 sam.]
** Filling instruction is boooring                                      :gbs:
Revamped the instructions macros a bit.  Leaner, and now matching the order of
[[https://code.google.com/p/game-music-emu/source/browse/trunk/gme/Gb_Cpu.cpp?r=40&spec=svn40][Blargg’s emulator]].  Though I don’t really know if there is a performance payoff
for that, since it could be optimized by the compiler as a jump table anyway.

Not sure what I want to do with flags tests after operations.  Seems like lot of
duplicate code.  Unless I use a ~test_flags~ macro...

* [2015-12-20 dim.]
** Overflow are safe in Rust                                       :gbs:rust:
Which means ... that 0xFF + 1 triggers a panic!  But only in debug builds, since
these checks are removed on release builds.  However, the right way to go about
that is to use ~wrapping_add~ instead to /explicitly/ signal overflow is
intended.

* [2015-12-23 mer.]
** Improving s3c                                                        :s3c:
Was looking to improve the error feedback of s3c.  But I realized that I could
fix the O(n^2) complexity of code evaluation.

Since we have only one worker when evaluating the whole file, and since the
worker evaluates all its code in the global context, we don’t need to
re-evaluate the previous blocks.  We can just send each block of code to the
worker by resetting the current code string.

So, evaluation is back O(n) with a one-line change.  D’oh.  And this also fixes
the multiple console.log calls!

But, it also changes the behavior of error output.  Previously, the first error
encountered in the evaluation would propagate as the result to all the following
evaluation markers.

: throw 1 //: 1
: 1 + 1   //: 1

Now, even a syntax error will affect only the next marker.

: throw 1 //: 1
: 1 + 1   //: 2

Is this ... better?  I’m not sure.  On the one hand, errors don’t propagate
anymore.  So you can go on with your code and still get feedback, even if a
previous definition triggers an error.

On the other hand, it’s now easy to miss an error up in the file and continue
working, and then wonder why something doesn’t work down the road.  Syntax
errors are signaled by the linter.  But other errors, like:

: fn f(a) { return a.b(a) }
: f(12) //: TypeError: a.b is not a function

are not.

For beginners, it might be a good idea to make runtime error more noticeable.

Okay, marked the lines in inverted red.  Can’t miss them now.

-----

Also added visual feedback for triggering evaluation.  Just erase the text after
//: at the time of sending the code to the worker is enough to /see/ that the
editor is doing something even when the results are the same.

-----

Made console calls to not trigger any linting error or warning, since they can
be used to step through a block.

-----

Maybe using a forEach on each /block/ rather than line would be faster than the
current way.  Another time.

* [2016-01-06 mer.]
** Decoding opcodes in GBS                                              :gbs:
The decoding opcode part of GBS is a bit redundant:

#+BEGIN_SRC
0x41 => ld!(b, c),
0x42 => ld!(b, d),
0x43 => ld!(b, e),
0x44 => ld!(b, h),
0x45 => ld!(b, l),
0x47 => ld!(b, a),
#+END_SRC

There is a way to factor that by just looking at how the opcode is composed.
For the ‘ld’ instruction, there is a pattern:

: ld r,q = 01rrrqqq
: ld r,n = 00rrr110 nnnnnnnn

With r and q being one of:

| Register | Code |
|----------+------|
| B        |  000 |
| C        |  001 |
| D        |  010 |
| E        |  011 |
| H        |  100 |
| L        |  101 |
| HL       |  110 |
| A        |  111 |

So, we already have the register information from the opcodes.  No need to spell
it out.  But this means additional work at runtime (decoding the opcode), and
decreased legibility of source code.  As of now, the code is very
straightforward, save for the organization of the opcodes.

We could decode the opcode at compile time using a macro, but I’m not sure we
would gain in legibility.

And unfortunately, the pattern breaks down for other opcodes:

: ld A,BC = 0000 1010

At least the tedious way to spell it out is homogeneous.

* [2016-01-07 jeu.]
** Dragging boxes around                                           :visualjs:
For a prototype visualizer of the JS heap.  I need to move boxes, representing
objects, around, and link them with arcs.

Started with a simple div box absolutely positioned and a homebrew drag’n’drop.
Works.

** Cloning SVG in a template tag                                   :visualjs:
But for arcs, I need to switch to SVG.  First suprise: using HTML templates to
clone SVG elements needs namespacing.  So I wrap the elements (like ~rect~) in a
~svg~ tag with explicit namespacing.  Works!

** Slow drag in Firefox                                            :visualjs:
Chrome is perfectly happy using the CSS transform property for dragging the
SVG boxes around.  Firefox is choppy.

[[https://jakearchibald.com/2013/solving-rendering-perf-puzzles/][This post]] is helpful on the subject.  Changing the x and y attribute of the rect
is definitely worse.  Using the transform property of the SVG (rather than CSS
transform) seems okay.  Certainly not as fast as Chrome, but looking at the
numerous bug report on SVG performance on Bugzilla, I’m gonna assume that SVG
animations in Firefox are just slower.

Hmm, closing the DevTools /is/ a definite improvement however.  Good thing to
keep in mind.

* [2016-01-08 ven.]
** Switching to d3                                                 :visualjs:
Managing SVG and interactivity is tedious.  D3 seems a good fit for what I want
to do.  I get browser compatibility, selectors, the join model of handling data,
and even animations.

Drag and drop is built-in, and I might need things like force layouts.

Also, it’s one of the most-used JS library, which means it probably won’t
disappear for at least a few years.

** Heisendrag                                                      :visualjs:
I was curious as to why the drag and drop example of D3 in Firefox was fluid,
while mine was choppy.  Turns out, dragging the browser tab in the other window
fixed the slowness ಠ_ಠ

* [2016-01-12 mar.]
** Mastering D3 and event propagation                              :visualjs:
In order to better understand how event propagation works in the DOM, and to
experiment with D3 animations, I made a simple visualization based on [[http://www.quirksmode.org/js/events_order.html][this
helpful page]], and using [[http://bl.ocks.org/mbostock/3943967][this block]] as a model for chaining transitions, and [[http://bl.ocks.org/mbostock/9631744][this
block]] for the visual language.

* [2016-01-15 ven.]
** Mouseenter event fired only when going to the right in FF       :visualjs:
At least I thought that, maybe it was a bug in Firefox.  The behavior puzzled me
and then I noticed that the SVG rect I was hovering my mouse onto was /not/ the
only element around: the temporary line I drew on top of everything was there
too!

So, #notabug.  Standard PEBKAC.  The line should not be interact with the cursor
in this case, and that is what the CSS property ~pointer-events: none~ is for.

And hey!  As a bonus, it fixed the behavior I was seeing in Chrome: since the
cursor was just above the line, whenever I clicked on it to validate, I was
clicking on the line, which had only the SVG container as a parent, and thus the
SVG registered the click while the node did not.  In Firefox, for some reason,
the cursor always clicked the node below the line.  Maybe the calculations were
off a pixel...

** The self-perpetuating task of explaining code with code         :visualjs:
I want to visualize JS code to better understand it, and be able to explain it.
For that, I build a program.  I write more code, /different/ code, code that the
visualization might not suffice to explain.  The visualization if for heap
objects, but for that I’m writing an automaton, and we already have a good
visual language for those.  But!  If I want this automaton visualization to be
interactive, I again need to write more code.

Either at some point I have visualizations for the first kind of code, and also
for the code of the visualizations, etc.—I converge—or I just throw up my arms
in the air and leave some code unexplained, or self-evident.

Will only know if I try.

** Declarative automaton for linking nodes interactively           :visualjs:
The linking nodes code is /clearly/ an automaton, and /clearly/ is spaghetti
code at the moment.  Dealing with listeners that should only exist on one state
is especially nasty, since we have to register them, then toggle them off, and
this is a repeating pattern that surely could be taken care of by a declarative
automaton.

As it stands, here is the description of the functionality needed to make the
linking:

#+BEGIN_EXAMPLE
Complete (functional description of) automaton

ready --click on circle--> select-dst
       |
       +- create temp line from circle to mouse

select-dst --move mouse-> select-dst
            |
            +- set end point of temp line to mouse position

select-dst --click on a free node-> ready
            |
            +- remove temp line
            +- add link between src and dst to model
            +- add link to view (update view)

select-dst --click elsewhere-> ready
            |
            + remove temp line

Animations and highlights:

ready --enter circle-> ready
       |
       +- grow circle

ready --leave circle-> ready
       |
       +- reduce circle to original size

select-dst --enter node-> select-dst
            |
            + stroke node in green

select-dst --leave node-> select-dst
            |
            + stroke node in default color (black)
#+END_EXAMPLE

I’m pretty sure there is a fluent API there that can take care of the
administrative details of entering a state, and setting up/destroying events
listeners as it goes through a transition.  Anything that need to be done on a
transition can be passed as a function.

Transitions, for my case, are always events happening on some element.  Then 4
things happen, in order:
1. We execute whatever needs to be done when leaving the state (cleaning up
   event listeners)
2. We execute the transition function
3. We change the state, internally
4. We execute whatever needs to be done when entering the new state (setting up
   new listeners)

If the transition is a loop (to and from the state), then only step 2 is needed.

That’s it!  Initially I don’t think any more control is needed for my use case.

Here is how I would sketch the API:

#+BEGIN_SRC js
var link_automaton = automaton()

var ready = link_automaton.state('ready')
      .on('circle.mouseenter', grow)
      .on('circle.mouseleave', shrink)
      .to('select-dst', 'circle.click', create_tmp_link)

link_automaton.init('ready')
#+END_SRC

Need to prototype that to know if it works in practice, and make sure it is
composable (can add states and transitions in multiple steps, not just one
monolithic call).

* [2016-01-19 mar.]
** Declarative automaton API choices                               :visualjs:
Nearly done.  The code is much clearer using the automaton.  For now I’m just
declaring state objects and adding callbacks to their transition/enter/leave
events, and not using a fluent interface at all.

However, the fluent interface can come on top of that, to alleviate two problems
with the lower-level interface:
1. All the states must be declared beforehand.  If A refers to state B (in a
   transition, say), then B must be declared.

   Using a fluent interface, we can just give the name of the state rather than
   a reference to it, and let the interface build the actual state objects for
   us.

2. Adding a callback to a transition is done with ‘on’, but a callback to an
   enter/leave event of a state uses ‘addListener’.  The fluent interface can
   merge the two calls based on the arguments.

There remains a problem with the automaton that I would like solved before
moving forward: how to deal with state that is local to the automaton.  The link
automaton needs to keep a reference to the first element selected, in the ready
state, for use in the select-dst state.

I elected to add an empty ‘data’ object to the automaton.  It’s basically the
same as closing over a variable, but at least it’s namespaced.  And in the
future, maybe I can provide a way to get a ref to the automaton from callback
calls.



An issue I encountered in this version is that I can’t add multiple callbacks to
one transition.  Or even add a callback after creating the transition without
any, at first.

To solve that, transitions should be first class, either through giving them a
name, or returning a new object.

As an added nicety, I think I know how to settle the dilemma of having to choose
whether transition callbacks happen after or before we leave the current state:
let the user choose.  Callbacks can be added either at the ‘debut’ of the
transition (before leaving the old state), or at the ‘end’ (after entering the
new state).  Maybe the ‘middle’ (after leaving the old state, but before
entering the new one) can also be useful.

* [2016-01-22 ven.]
** More design decisions                                           :visualjs:
I’ve pondered whether using the automaton as a pure event emitter.  When
entering a state, when a transition is made (3 stages), just emit custom events
and define the behavior only in the listeners to these custom events.

This is better for decoupling the code.  But the cost is that you lose track of
the control flow.  Some animation bugs are subtle, and require you to know
precisely what happens and in which order.  Animation is part of the
interaction, and the code should not be declared separately.

* [2016-01-29 ven.]
** Event binding troubles                                          :visualjs:
So, I was on the fence about binding listeners to elements themselves, rather
than on the containing SVG, fearing performance issues.  Since boxes can be
added/removed, and we add several listeners to different element of each box,
AND we add/remove listeners depending on the current state of the automaton.

The upside is code that is free of ~if~ statements, since the dispatching is
taken care of by the event dispatcher.

However, it has come to bite me back.  If I define the automaton only once (as I
should have from the start), then when a new box is created, no listeners are
bound to it.  Can’t be dragged.

Of course I could add the drag behavior to newly created boxes.  But, it might
not be correct if we are not in the ready state.  What we should do is add the
listeners for boxes (and sub-components, cell and circle) valid /in the current
state/.  That seems like it’s easy to forget, and it is.  Also, it seems
a bit wasteful, because I would select all boxes again, and reassign the
listeners for all.

Another solution is to catch all events at the container level, let them bubble
up and identify the original target.  But now the problem is that sometimes I
don’t want to just know the original target, but I need the path in the DOM that
the event took.  So now I need to walk up the tree, duplicating the bubbling
phase.

And, ultimately, the drag behavior from d3 need to be called on a selection, not
on the container.

The more pragmatic solution is just to call drag_box when a new box is created.
Since I know the user is in the ready state.  Even though it’s not correct, I
might find a better way to organize this stuff later down the road if need be.

* [2016-03-22 mar.]
** Comparing approaches to deal with state                         :visualjs:
Ronan has been using RxJS for an application that presents a GUI in the
browser.  I was wondering how the reactive programming approach would handle my
situation, for which I found that a state automaton was the best approximation.

But at the same time, it seems odd that I have to resort to an explicit state
automaton to handle my elementary interaction.  So, how do others deal with it?

Looking at RxJS docs, it seems that it is a complete algebra of events, meaning
I could use the basic operators to build richer ones, and eventually create
streams of predicates that would give me exactly the same information that a
state automaton gives.

But, would the complex operator be as clear, or clearer than the description of
an automaton?  And what about the performance of the thing, as this is always a
worrying concern when techniques from functional programming are naively ported
to JavaScript.

I need to find out:
1) the way ‘traditional’ GUI systems deal with this kind of interaction (Swing,
   GTK, Qt, Cocoa?)
2) if there is a ‘canonical’ way to handle this kind of interaction using RxJS
   (or in reactive programming)
3) if there is a standard, or well-known technique to bind listeners to DOM
   elements ‘lazily’, that is, whenever an element matches the given selector, it
   should trigger the listener.

For point 3, if I set up a single listener at the root of the document, I can
capture any click and match the given selector against event.target.  But what
if I want to match against a /parent/ of the target?  Knowing that clicks
bubble, I could walk up the DOM and test the selector against each element,
until I hit the root.

Except now I’m duplicating logic done by the browser, and it’s incompatible with
stuff like ~event.stopPropagation()~.



Okay, on 3, there is an [[https://developer.mozilla.org/en-US/docs/Web/API/element/matches][~Element.matches~]] predicate to know if the element would
have matched the given CSS selector.  Better than having to check the ~tagName~
and ~classList~.  But doesn’t solve the need to look up the parent.

The name of the technique is “event delegation”.  [[https://api.jquery.com/on/][Jquery]] has an argument for
that, but for some reason, it doesn’t work on SVG.  And indeed, it walks the
tree:

#+BEGIN_QUOTE
jQuery bubbles the event from the event target up to the element where the
handler is attached (i.e., innermost to outermost element) and runs the handler
for any elements along that path matching the selector.
#+END_QUOTE

On point 1, there are certainly a number of hits for “GUI state machine”, and
the pattern seems recognized.

* [2016-03-28 Mon]
** Trying out a Sparkets rust server                          :sparkets:rust:
Since server is in need of a rewrite, to be faster, cleaner and more robust.

Since we already compiled Coffeescript, that does not change the compilation
time much.

** Choosing a library                                         :sparkets:rust:
I’ve got a fast and simple [[https://github.com/housleyjk/ws-rs][websocket library]].

Now, I know I will want to benchmark binary messages vs. text messages.  So I
should design around this choice by presenting a common interface.

** Testing input latency                                      :sparkets:rust:
I want to test how the game feels with a moderately high latency (~50 to 100ms
roundtrip).  I thought Chromium was able to do that, but it seems the throttling
option of the network panel only works for initiating the connection, and is not
applied to all subsequent frames when the websocket is established.

But, there is an option to add latency directly on the loopback interface
through [[https://daniel.haxx.se/blog/2010/12/14/add-latency-to-localhost/][netem]]:

: tc qdisc add dev lo root handle 1:0 netem delay 50ms

this sets 50ms of delay.  It does affect ~ping~, and it visibly affects
websocket frames on my machine.

To reset:
: tc qdisc del dev lo root

It seems you need to reset before applying a different delay.

** Multi-threaded server or asynchronous?                     :sparkets:rust:
Building up a small prototype.  Not familiar at all with how to build a game
server in Rust.  And I have to deal with memory management explicitly.

The nodejs server was asynchronous, because nodejs.  One event loop where input
was collected, and one setTimeout to deal with game updates.

In Rust, I guess I could also do that, but I have to look up how.  Meanwhile, I
could also use a multi-threaded approach.  One thread per client might be
simpler to code, and since we are not expecting thousands of players, the
performance scaling of thread is not an issue.

In any case, I need to brush up on coding concurrency in Rust.

Been reading:

- [[http://fabiensanglard.net/quakeSource/quakeSourceNetWork.php][Network code review of Quake]]

  Yes, I know it uses UDP, and WebSocket is on TCP.  But I want to know how
  clients are handled.

  Well, it’s not clear from that article.

** What’s the ideal solution to input latency anyway?         :sparkets:rust:
I’ve always wondered if the treat input/update logic/render loop was optimal.
I’ve been doing that for ages.  I remember it bit me because updates were tied
to graphical frames, and lagging on frames made the game slow.

But this was an issue of handling time in the updates.  If the game updates by
doing ~player.x++~ each frame /and/ you assume the game runs at 60fps, then when
an old machine churns out 30fps, the game plays in slow motion.  Because what
you really wanted to say is ‘x increases by one each 16.66ms’; the simulation is
tied to continuous time.

A game is a simulation.  The simulation, to feel good, needs to be as responsive
as possible.  If I act on the real world, I expect an immediate feedback.  The
simulation, to feel real, must do the same.  It means that a player must be able
to react on input, and see his impact on the simulation in /realtime/.  Of
course, the computer cannot do realtime, only discrete.  But, the computer can
compute the simulation and redraw it much faster than the brain can notice.

25fps is good enough for our brain to believe that movies are real.  But when
you add interaction, you usually need to be a bit faster than that.  25fps means
40ms between two frames.

Let’s say it takes 10 ms to update the simulation, and another 10ms to draw the
scene and refresh the display.  Out of 40ms, the CPU is only busy for 20ms,
which is good.

#+BEGIN_EXAMPLE
   late input                            early input
   |                                     |
--UUUUUUUUUURRRRRRRRRR--------------------UUUUUUUUUURRRRRRRRRR----------------
  |  compute s        |                   |  compute s+1      |
 screen shows s-1     |  screen shows s                       | screen shows s+1
#+END_EXAMPLE

Already something is troubling.  The simulation should render things as they are
/right now/.  But as it /takes time/ doing so, the display is already outdated
as it is shown on the screen!

It’s like when I give you the time, by the time you hear it and process it, it’s
already false.  Now, luckily, the time is still useful to you because I only go
to the minutes.  Seconds are trickier.  Milliseconds are already hopeless.

Same thing for the simulation.  It’s in some state ‘s’, then at the scheduled
time (every 40ms), it starts updating to state s+1.  When the screen is
refreshed, we are already 20ms in.  What time does the simulation reflect?

If it reflects the time of the world at the /beginning/ of the update, then the
image on the screen is already 20ms outdated when it comes up.

That means that if a user action is made just before the update comes along, we
will see the result 20ms at the earliest.  Worst case, the input is made just
after the update component reads them, then we have to wait for the current
frame to draw, then the next: 60ms before our action impacts the world we see.

So, for any random button press, the screen might display the changed world
after a delay that is anywhere between 20ms and 60ms.

If that delay is long enough for the brain to have time to think “did I press
that button?”, for the brain to /notice/, then the simulation is not fluid, and
the illusion breaks.

The question is then, how long can this delay be before the brain starts to
notice?



Running some tests...

Typing a key (down key event) paints a square on the screen.  The square
alternate between pink and green colors to distinguish each key stroke.

Delays are chosen randomly, I just type to see if it feels responsive.
Delays are just lower bound on the actual perceived delay: the screen might take
some milliseconds longer to refresh.

I’ve noticed that typing just one key is vastly different than stringing a few
keys together.  If I type once, and wait to see if I notice the delay before the
square is painted, 100ms feels immediate.  But string 3 keys rapidly, and it
does not feel instant anymore.

400ms is definitely noticeable, and feels sluggish at all.

A delay of 200ms is noticeable, but can still feel responsive for one key.  Not
for 3 keys.

100ms feels immediate.  But I can feel the delay when stringing keys.

50ms feels immediate.  Stringing keys also.

10ms feels a bit faster than 50ms, but not really much.



Another test, on input speed this time.  Measuring time between key downs.

Double-tapping the same key: I can hit 87ms minimum reliably, but with effort.
Effortless is more 150ms.

Stringing two different keys: now there is an issue with measurement.  Tapping
two or more keys /at the same time/, I can never get below 8ms.

Since each key down is a separate call to the listener, I suspect that the time
is spent dispatching and cleaning up.  So, 8ms is the effective resolution of
the browser in this setup.  Sometimes I get a 3, or even 0.5, but quite
randomly.

Now, stringing two different keys: I can do 8ms (same time for the browser) and
16ms reliably (the earliest to distinguish between two key down), without
effort.

With 3 fingers, I can do <100ms for each successive tap, effortlessly.



What does this mean?  Well, if I am able to hit two keys with 20ms between them,
I can also hit them with a 60ms interval.  If I can feel the difference in
my fingers, the game should also reflect this difference.

But, if I sample the input every 40ms (by polling the keys at the beginning of
the update loop), keys hit with an interval <40ms are counted as being hit at
the same time.

It’s basic sampling.  The signal is 1 when the key is down, and 0 when the key
is up.

#+BEGIN_EXAMPLE
----------|----------|----------|----------
0000000111110000000000011111000000011110000
#+END_EXAMPLE

As long as the key is held down for longer than the polling interval, we are
sure to get every key.

And if we want to distinguish between two successive key pressed, we just have
to use a reasonably low polling.

On my browser, the lightest tap I can muster holds the key for 32ms.  Meaning
that if the polling was 40ms, I could miss that key down from time to time,
depending on how it falls with respect to the update.

In this case, 30ms would suffice.  Poll interval of 30ms, or you start losing
keys.



So I guess the morale of the story is: faster feedback is always better.  But
below 50ms of visual feedback, the gains are negligible.

Polling keys at the start of a monolithic update loop is okay, as long as the
polling interval is less than the time a key can be held down.  Should check on
target hardware how low the resolution can be (browser + keyboard is certainly
not the optimal setup).

** Carmack on movement prediction                             :sparkets:rust:
To alleviate server latency in QuakeWorld, Carmack tried to use prediction.  The
player movement is duplicated on the client, starting from the last known good
state received from the server.

The server works by directly answering to received packets: update only the
world around the player, and send the state back.  There is no global time
anymore.  But the player does not have to wait for the fixed update.

Carmack notes that simulating 300ms of player movement on the client is
hopeless.  But, for <100ms delays, client prediction helps smooth out the
movements.  Because server updates may not always arrive on time, we can keep
the framerate constant on the client with prediction.

* [2016-04-02 Sat]
** Setting the MTU on Archlinux                                        :arch:
I had issues connecting to wiki.archlinux.org, but other websites were fine.

Apparently, that was caused by a misconfigured MTU.  Under Windows, the MTU was
1480 for ipv6, and 1500 for ipv4, but in Linux it was 1500.

To find out the correct MTU, I used ping:

: $ ping -4 -l 1452 -M do www.dslreports.com

‘-M do’ tells ping to look for MTU discovery packets.  The host has to be
configured to send these packets back, which few of those I tested (8.8.8.8,
google.com, free.fr) did.

Setting the MTU temporarily:

: # ip link set eth0 mtu 1480

(replace ‘eth0’ by interface name)

Then wiki.archlinux.org loaded correctly.

To set the MTU permanently, the wiki advised to use an udev rule, but I could
not get it to match the interface name for some reason.  Too lazy to RTFM, turns
out there is an MTUBytes option for systemd-networkd.service.  In
/etc/systemd/network/my.network:

: [Link]
: MTUBytes=1480

Voilà.

** Mounting a WDTV Live Hub                                            :arch:
Did not want to install/configure Samba.

But luckily, only ~cifs-utils~ is required:

: # mount -t cifs //SERVER_IP/WDTVLiveHub/ /mnt/wdtv -o uid=USER,gid=USER

To find what shares are up on the network:

: $ smbclient -L //SERVER_NAME

To find the IP of the server:

: $ nmblookup SERVER_NAME

* [2016-04-03 Sun]
** Making progress                                            :sparkets:rust:
Spent a few hours trying to find a way to emulate a setInterval on the server.
Well, good old thread::sleep is still the state of the art, apparently.  It was
used by a [[https://github.com/mvdnes/rboy/blob/master/src/main.rs][gameboy emulator]], and measurements show it as accurate enough.

I ought to make a [[http://gafferongames.com/game-physics/fix-your-timestep/][“right” timestep]] this time around though.

And I’m sure I’ll run into all kind of ownership fun when I start accessing the
game state from the logic thread as well as from the websocket handler.

One thing I haven’t settled, is whether to send game updates to clients when we
receive a message, or broadcast in the logic thread.  I recall reading Carmack
switching to the former for Quake3.  Cuts time between updates for the client,
but every client will have a slightly different state (although the interval are
so small, it should not be noticeable).

Serialization was another issue.  I found a library, [[http://tyoverby.com/bincode/bincode/][bincode]], so I don’t have to
write a struct to [u8] function.  But on the JS side, I still need to write a
deserializer.  So I might end up writing the serializer by hand, to have more
control over endianness.  And for diffing snapshots to send updates.

And while I’m experimenting, maybe find a way to use the unreliable WebRTC data
channel, rather than websocket.  Should be quite faster especially out of the
LAN.

- http://www.html5rocks.com/en/tutorials/webrtc/datachannels/
- https://hacks.mozilla.org/2013/03/webrtc-data-channels-for-great-multiplayer/

But on the Rust side, it’s rather bleak:

- https://github.com/phsym/sctp-sys

** SCTP experiments                                           :sparkets:rust:
Tried to use the rust-sctp library.  For some reason it always returns an error
when I try to accept a connection.

Tried to bind the socket in C.  It gets past the accept and blocks.

So, I guess if I can chat with a JS web page over RTCDataChannel, it might be
worth to try to see how to integrate the C code into Rust?

* [2016-04-09 Sat]
** Understanding WebRTC                                       :sparkets:rust:
Found a pretty [[http://chimera.labs.oreilly.com/books/1230000000545/index.html][comprehensive book]] on WebRTC and browser networking.

Managed to build a minimal example of a client page using WebRTC to setup an
unreliable data channel to itself.

Now, the sad part of that is that setting up a WebRTC connection is /much more/
than just creating a socket.  You need an SDP, to setup ICE candidates, and then
let the browser establish the SCTP connection over DTLS over UDP under the hood.

I only found an SCTP library for Rust for now, so I’m missing a few components
to make a Rust binary talk to a WebRTC JS client.

Nodejs can talk to a WebRTC browser, right?  The goto library on npm seems to be
[[https://github.com/feross/simple-peer][simple-peer]].  To use it in node, they point to [[https://www.npmjs.com/package/wrtc][wrtc]].  Seems /they/ mostly wrap
around the WRTC implementation of Chromium, and export that to node bindings.

So using that with Rust seems... not fun, at all.

On the other hand, I /could/ use simple-peer and wrtc in Sparkets directly, and
have an UDP protocol for messages.  Less work, more benefits.

* [2016-04-19 Tue]
** One fat listener                                                :visualjs:
I like simple approaches.  Watching [[http://mollyrocket.com/861][Immediate-mode GUIs]], I want to try writing
a catch-all listener that will handle all the logic in one place.

I suspect that he had in mind to repaint the components in the single update
function.  I don’t need to do that here, as I deal with SVG elements inserted
into the DOM.

The single update function works.  But it made me realize I really ought to
decompose the ‘box’ functionality into independent behaviors, or traits:
- a movable behavior that adds a moveTo command for manual positioning
- a draggable behavior for mouse dragging
- the box is just a container, doesn’t need to know what’s inside to draw itself
- a snappable behavior for snapping to a grid

Properties are distinct components also.  And links too.

* [2016-04-29 ven.]
** Diving into V8 optimizations
Trying to find out if, in a simple ~for~ loop:

#+BEGIN_SRC js
var a = []
for (var i=0; i < a.length; ++i) {}
#+END_SRC

the ~i < a.length~ check is optimized as:

#+BEGIN_SRC js
var a = []
for (var i=0, l=a.length; i < l; ++i) {}
#+END_SRC

or not.

Via nodejs, we can pass a bunch of flags to V8 in order to obtain more
information about the optimization, GC calls, intermediate representations, and
generated code.

After putting the loop in a function that's called 10000 times, the function is
/hot/ and will be compiled and optimized.  We can see that with the --trace-opt
option.

#+BEGIN_EXAMPLE
[compiling method 0xad4d20bd9c1 <JS Function f (SharedFunctionInfo 0x187ace9573f1)> using Crankshaft OSR]
[optimizing 0xad4d20bd9c1 <JS Function f (SharedFunctionInfo 0x187ace9573f1)> - took 0.061, 0.151, 0.038 ms]
#+END_EXAMPLE

To find out the generated code, we can use --print-opt-code:

#+BEGIN_EXAMPLE
--- Optimized code ---
optimization_id = 1
source_position = 72
kind = OPTIMIZED_FUNCTION
name = f
stack_slots = 10
compiler = crankshaft
Instructions (size = 696)
0x2335adc58220     0  55             push rbp
0x2335adc58221     1  4889e5         REX.W movq rbp,rsp
0x2335adc58224     4  56             push rsi
0x2335adc58225     5  57             push rdi
0x2335adc58226     6  4883ec30       REX.W subq rsp,0x30
0x2335adc5822a    10  488b45f8       REX.W movq rax,[rbp-0x8]
0x2335adc5822e    14  488945d8       REX.W movq [rbp-0x28],rax
0x2335adc58232    18  488bf0         REX.W movq rsi,rax
...
#+END_EXAMPLE

Now, unfortunately, that's a bit low level.

I tried to generate the same code for the hand-optimized for loop, and diff the
outputs.  But there many random addresses that gets in the way of seeing if
instructions differ.  One thing that's easy to spot though is the Instructions
(size) line.

My guess is it's the size of the compiled function.  But the hand-optimized
version has size=812, which seems counter-intuitive.

Or maybe, the hand-optimized version actually /defeats/ optimization made on the
more common idiom by the compiler.

We can get a look at some of the optimization phases made on the high-level
representation (HIR) through the --trace-hydrogen flag.  My guess is Hydrogen is
responsible for high-level representation.

The file contains multiple control flow graph, with the helpful name of the pass
that generates it.

When ~f~ is optimized, it triggers a full compilation phase.  The graph is full
of "blocks" of code:

#+BEGIN_EXAMPLE
                               +----------+
                               v          |
B0 -> B1 -> B2 -> B4 -> B5 -> B6 -> B7 -> B8
             |          ^        -> B9 -> B10 (return)
             +--> B3 ---+
#+END_EXAMPLE

Clearly, the loop is B6 -> B7 -> B8, and B9 is the exit path.

If we look at B6, we can see our length check:

#+BEGIN_EXAMPLE
      0 0 v48 BlockEntry  type:Tagged <|@
      0 0 t52 CheckHeapObject t39 <|@
      0 1 t53 CheckMaps t39 [0x2a5dde306c51] <|@
      0 1 i54 LoadNamedField t39.%length@24 t53 type:Smi <|@
      0 0 i55 CompareNumericAndBranch LT i44 i54 goto (B7, B9) type:Tagged <|@
#+END_EXAMPLE

So, at this point, we are checking the ~length~ field of the array.

But, after the "H_Global value numbering" phase, all that's left of this block
is just the comparison:

#+BEGIN_EXAMPLE
      0 0 v48 BlockEntry  type:Tagged <|@
      0 0 i55 CompareNumericAndBranch LT i44 i54 goto (B7, B9) type:Tagged <|@
#+END_EXAMPLE

i54, the integer that holds the length value, has moved to block B5, which is
not part of the loop:

#+BEGIN_EXAMPLE
      0 0 v45 BlockEntry  type:Tagged <|@
      0 0 v46 Simulate id=30 type:Tagged <|@
      0 0 t52 CheckHeapObject t39 <|@
      0 3 t53 CheckMaps t39 [0x2a5dde306c51] <|@
      0 2 i54 LoadNamedField t39.%length@24 t53 type:Smi <|@
      0 2 t70 Constant 0x2ffe54fafc79 <JS Array[0]> [map 0x2a5dde306b49]  <|@
      0 0 t71 CheckMaps t70 [0x2a5dde306b49](stability-check) <|@
      0 2 t72 Constant 0x2ffe54facc81 <an Object with map 0x2a5dde306519> [map 0x2a5dde306519]  <|@
      0 0 t73 CheckMaps t72 [0x2a5dde306519](stability-check) <|@
      0 4 t74 LoadNamedField t53.%elements@16 type:Tagged <|@
      0 0 t75 CheckMaps t74 [0x2a5dde304209] <|@
      0 0 v47 Goto B6 type:Tagged <|@
#+END_EXAMPLE

So, it seems that the length check is indeed optimized by V8.  And that is done
in the "Global value numbering" phase on the HIR.

* [2016-05-02 lun.]
** Someone who actually knows V8 optimizations
already [[http://mrale.ph/blog/2014/12/24/array-length-caching.html][covered]] the ~array.length~ case in depth.

He also built a [[http://mrale.ph/irhydra/2/][tool]] to visualize V8 HIR, contron flow graph, and
deoptimizations output.  Much better than recreating the graph by hand.

He mentions that manually caching the ~array.length~ may actually be worse,
because it creates an additional variable that is assigned to a register.

The morale here is, again, to measure before optimizing.

The compiler does a good job a optimizing common idioms.  And it actually
produces less-efficient code if you are trying to optimize things yourself.

This was [[http://www.infoq.com/presentations/chrome-v8-optimization][reiterated]] by V8 engineer Ben Titzer for heap optimizations.  Someone
asked if using an object pool is a good idea when you have allocations
problems.  The answer: probably not, because V8 /assumes/ a usage pattern of
creating objects and throwing them away.  An object pool is an uncommon pattern,
and it might defeat optimizations.

Measure first, understand how the runtime works, formulate a strategy, implement
and measure again.

* [2016-05-06 ven.]
** Testing the GB CPU emulator                                          :gbs:
The [[http://blargg.8bitalley.com/parodius/gb-tests/][Blargg test suite]] is a good start.  But there is a slight bootstrapping
issue, as it needs a mostly-working CPU to actually start running the tests.

And the output requires minimal screen emulation, which I don't really wanted to
cover.

And the GB rom files are not the same format as GBS files... again, I don't want
to parse those.  On that front, since the assembly source is provided, I can
actually recompile the tests for GBS.

In shell.inc, you find:

#+BEGIN_EXAMPLE
; GBS music file
.ifdef BUILD_GBS
     .include "build_gbs.s"
.endif
#+END_EXAMPLE

The readme mentions that 'wla-dx' was used to compile and link those assembly
files.  The project is [[https://github.com/vhelin/wla-dx][still alive]], and also in [[https://aur.archlinux.org/packages/wla_dx/][AUR]] (gotta love Arch).

To compile a GBS file from an individual test file, you just need to define
~BUILD_GBS~ like so:

: wla-gb -o -DBUILD_GBS FILE test.o
: wlalink linkfile test.gbs

Two issues for the moment with that ROM.  The play address of the header is
0xC6D5, which is outside the 0x400--0x7FFF range of the GBS spec...  and if I
remove the checks there is an infinite loop (maybe because I haven't implemented
all flags for instructions yet).

Maybe a basic test harness in Rust is a better idea.

** Testing single instructions                                          :gbs:
Created a ~step~ function that goes through one instruction and returns the
number of cycles.  More useful for unit testing than ~run~.

Using macros for testing, since I have lot of repetitive code for each register.
But now, running into a strange SIGSEGV error when I have too many macro
calls... strange.

#+BEGIN_EXAMPLE
error: Process didn't exit successfully: `gbs-4725f7ba8db983e2`
(signal: 11, SIGSEGV: invalid memory reference)
#+END_EXAMPLE

Trying to debug by finding out what is generated after macro expansion.  Need an
(undocumented, of course!) option:

: rustc --test --pretty=expanded -Z unstable-options src/cpu.rs

~--test~ means compile the test module, I suppose.  And ~--pretty~ is the option
to output pretty printed code after macro expansion.

Ok, I have code like this:

#+BEGIN_SRC rust
#[test]
fn test() {
  ld!(b, c);
  ld!(b, d);
  ...
}
#+END_SRC

and the macro creates a new ~Cpu~ each time:

#+BEGIN_SRC rust
macro_rules ld! {
  ($r:ident, $r2:ident) => ({
    let mut cpu = Cpu::new();
    ...
    assert!(..)
  });
}
#+END_SRC

In the generated code, ~test~ contains as many blocks as there are ~ld!~ macro
calls.  I suppose that the code generator doesn't like code that has too many
blocks... Maybe I should split those into functions?

Ok, changed the tests to generate one function for each test case.  Only
slightly more verbose, but greatly increases my number of tests!

** Wait, was that a compiler bug?                                  :gbs:rust:
The SIGSEGV with too many macros... no unsafe code, but still an invalid memory
reference?  How come?

Building a minimal example now.

: rustc --test main.rs; and ./main
: fish: “and ./main” terminated by signal SIGSEGV (Address boundary error)

Ok, just a single test function that calls 32 ~Cpu::new~ does it, but 31 calls
does not SIGSEGV.  I emptied the ~Cpu~ struct to contain only the ~ram~ field,
which has 65536 u8, hence each Cpu eats 64K.

Let's see, 32*64K = 2048K = 2M.

That's a suspiciously round number.  <2M, no SIGSEGV, >=2M, SIGSEGV.

According to [[https://play.rust-lang.org/][play]], happens on stable, beta and nightly.  But only in debug mode
(release optimizes everything away probably).

Aaaand there we have it: [[https://github.com/rust-lang/rust/issues/31748][#31748]].  Rust has a default stack size of 2M, so we
overflow that.  But there should be a stack overflow message that's skipped for
some reasons, and the devs are aware of it.

* [2016-05-07 sam.]
** Fixing flycheck-rust                                            :flycheck:
flycheck-rust is confused when you have both a lib.rs and a main.rs in the same
folder.  Because cargo needs to know what target to build: the lib, or the
binary?

flycheck-rust does not specify the target, and spouts an error, and fails to
check the buffer (and any buffer in the project).  This has been [[https://github.com/flycheck/flycheck-rust/issues/23][reported]], but
not yet fixed.

Now, we can get the all targets from cargo itself, thanks to the ~read-manifest~
command:

: cargo read-manifest

returns a JSON with all targets.

Now, which one to chose?  I suppose the 'lib' target will start with the
'lib.rs' file, and compile all files that are included in it, recursively.  And
the 'main' target is the same, but starting from the 'main.rs' file.

Flycheck works per-buffer, so we should chose the target that will end up
compiling the current file.  Ideally we would compile only the current file, but
in larger projects, there are dependencies to keep track of.

So, which target to chose?  I don't think there is a way to get that information
directly from cargo right now, that is:

: cargo which-target src/a.rs

which would return the target name.

In my use case, the project is a library, that also contains a binary as an
example.  So, we should always build the 'lib' target (there's only one of
those), and build the 'bin' target only when looking at the 'main.rs' file.

If the current buffer is a match for the src file of any target, then chose the
according target.  Otherwise, chose 'lib' by default.

That seems to work locally.  Now, onto the PR!

** Making the pull request                                         :flycheck:
Forked flycheck.

Made the changes.  Tried to run the tests... fail!  Ah.

: make specs test

fails because it asks me for passphrase during the tests.  What?

Looking around the source, the passphrase is "spam with eggs".  Now it passes:
: Ran 71 out of 105 specs, 0 failed, in 10.0 seconds.

Some tests are canceled because they need Emacs 25.

Apply back my changes, there is a documentation failure.

I ~ag~ for the option above mine, to look where it appears in the source.  There
is a documentation entry in 'languages.rst'.  I document the new variable, test
passes.

Now, onto the integration tests:

: make LANGUAGE=rust integ

Okay, two tests fail: warning and multiline-error.  Actually, the second failed
without my patch.  Probably a change in the compiler output.  Fixed the test.

The first fails because there is no value for my new variable.  The test project
is a crate named "flycheck".  Put that, all tests pass.

Done.  Now, flycheck-rust!

** Finding the right build target                                  :flycheck:
Had to change the approach a little, because we cannot default to "lib" crate
type in a crate that contains only a 'main.rs'.  So instead of guessing, I just
look the targets up in ~cargo read-manifest~.  First one is the default, and if
we are looking at a file that is specified by the targets, this is the target we
pick.

Simple cases: only one target (lib or bin), that is the one chosen.  Works with
"simple" setups.

Multiple targets: lib, main.rs bin and multiples source files in src/bin.  If
looking at 'main.rs', or any of the 'src/bin' files, those are targets, so they
are chosen.  Any other file will default to the first target.

It's not ideal.  I think it might miss cases like:

: src/a.rs src/b.rs src/lib.rs src/main.rs
: src/lib.rs depends on 'a.rs'
: src/main.rs depends on 'b.rs'

If the default target is 'lib', then Looking at 'b.rs' will pick lib, even
though it's a dependency for the binary.  Converse is true for 'b' and a default
target of 'bin'.

Haven't encountered the issue, because I only have the case where 'main.rs'
depends solely on the lib, and every other file is part of the lib, and the lib
is the default target.

Anyway, unless there is a way to find the target for a file, this will do.  This
can always be overridden by setting the `flycheck-rust-binary-name` manually.

Reviewed the code and added a docstring.  No test suite this time (though it
would not be a bad idea to ensure we don't break any convoluted setups).

* [2016-05-10 mar.]
** Checking the state of Rust tool support                         :flycheck:
Error output seems to have changed in nightly: [[https://github.com/rust-lang/rust/pull/32756][PR#32756]].

That means Flycheck will soon break in parsing them.  Luckily, there is also a
new [[https://internals.rust-lang.org/t/rustcs-json-output-format/3446][unstable option for JSON output]].  The JSON format should hopefully stabilize
soon.

Speaking of which, using ~-Z no-trans~ for faster compilation is an unstable
flag, and currently outputs a warning.  [[https://github.com/rust-lang/rust/issues/31847][This]] is the issue to follow if we want
this flag to stabilize.

On the horizon, there is also the [[https://github.com/rust-lang/rust/issues/31548][Rust Language Server]], which aims to be a
direct interface for IDEs, providing error checking, completion candidates, find
definition, etc.  But this is only a RFC, awaiting for incremental compilation
progress in rustc.

A good place to check for news on all of this is the [[https://internals.rust-lang.org/c/tools-and-infrastructure][tools and infrastructure]]
forum.

* [2016-05-11 mer.]
** Checking that flycheck-rust works right for everyone's use case :flycheck:
I've tested the basic layouts of src/lib, src/main and src/bin/.  But cargo
allows for some fancy overrides, and I don't even have dependencies in my
projects for now.

[[https://github.com/flycheck/flycheck-rust/issues/7][I see]] that the cargo project itself is a corner case, and indeed it doesn't work
as intended when looking at the src/bin/cargo.rs file.

The cargo.toml of cargo sets the library path directly rather than relying on
the project layout:

: [lib]
: name = "cargo"
: path = "src/cargo/lib.rs"

Note that the path is relative.  And it still is in ~cargo read-manifest~:

#+BEGIN_EXAMPLE
  {
    "kind": [
      "lib"
    ],
    "name": "cargo",
    "src_path": "src/cargo/lib.rs"
  },
#+END_EXAMPLE

But it's an absolute path when ~path~ is not set in the TOML.  Which isn't
really helping as a machine-readable output.  The issue was raised in the [[https://github.com/rust-lang/cargo/pull/1434#issuecomment-94117884][original]]
[[https://github.com/rust-lang/cargo/pull/2196#issuecomment-171411921][pull requests]], but not picked upon.

Solution?  I guess either ensure that the ~src_path~ is always relative to the
crate root, or always absolute.  Leaning towards the latter, as it should be
easier to debug.

However, even if it does check the correct file, it takes several seconds for a
project as large as cargo.  Not sure if that's a good use case of flycheck.

*** metadata replaces read-manifest
In the future, it [[https://github.com/rust-lang/cargo/issues/2356][looks like]] ~read-manifest~ might be replaced by ~metadata~,
which gives much more information, especially on the dependencies.  For the
moment though, the targets section looks identical.

On surprising effect of the ~cargo metadata~ command is that it fetches
dependencies on first invocation before returning the JSON.  Which means that
the first invocation is slow, and the stdout is not a correct JSON, since you
have lines like:

: Updating registry

Though that can be skipped with the ~--no-deps~ flag.

~jq~ can be useful to wade through the metadata dump:

: cargo metadata | jq '.packages | .[] | select(.name == "cargo")'

*** subcrates
A use case of subcrates is the [[https://github.com/rust-lang-nursery/regex][regex crate]], which has regexp-syntax has a
"subcrate": a dependency crate hosted inside the same repository.

In this case, ~cargo read-manifest~ will report the targets for the current
crate.  So if we are in the main crate, or in the subcrate, it picks the right
target.

*** cargo declares mod at compile time
Using macros, which means that files that are part of the binary target are not
picked up by flycheck.

But even without macros, I don't think we would pick it up:

~src/bin/read-manifest.rs~ is a ~pub mod~ (via macro) in ~src/bin/cargo.rs~.
But there's no target corresponding to read-manifest, so how do we know that's
part of the ~cargo~ binary target?

* [2016-05-20 ven.]
** Toying with JITs                                                 :chipers:
Always wondered how you build one.  Another pretext to use more Rust.

Found a [[http://www.hydrocodedesign.com/2014/01/17/jit-just-in-time-compiler-rust/][couple]] [[http://www.jonathanturner.org/2015/12/building-a-simple-jit-in-rust.html][tutos]].  They showed how to create a memory region, mark it as
executable, write a few opcodes, and the magic ingredient: cast the memory
region as a function.  Then, invoke the function, and boum.

Technically, that's just injecting binary code at runtime.  A kind of "metal
eval"... meteval?  meval?

Anyway.

I wanted to know the order of magnitude difference between JITed code and
emulated code.

I wanted to JIT the GB emu.  But that's not done yet.  So, I thought about a
Chip8 emu.  But I didn't have that.  I do have a JS Chip8 emu.

If I code a Chip8 pure interpreter in Rust, then code a JIT interpreter in Rust,
I could compare the performance of each, and see how much a JIT would gain.

I'm also curious as to whether I can compile most of the ROM code directly to
native binary, without inspecting "hot loops" first.  So, technically, AOT.

Started converting that Chip8 emu by following the JS code and looking up how to
deal with slices, or build up an SDL screen as I went.

Works, although there is a strange display bug at the moment.  But didn't have
time for the JIT version tonight.

So I thought, if I want to compare JIT performance to pure interp, and I already
have a JIT for a fixed piece of x86 binary, why not quickly whip up a hackish
x86 pure interp, and see how /that/ fare?

My test program is a loop that counts down from 0xFF000000.  This takes 1.24
seconds to execute JITed.

The pure interpreter is hackish, but does minimal work on top of decoding and
executing opcodes.  It takes 120.96 seconds in debug mode, and 23 seconds in
release.

So, this preliminary test shows a 20 times improvement in performance for the
JITed version.  Quite impressive.

That's enough to entice me to try that on a real emulator!

* [2016-05-25 mer.]
** Gameboy JIT opportunities
Making a note here of the fact that, due to hardware quirks, the following
snippet is the recommended way to access the state of all the buttons in the
Gameboy:

#+BEGIN_SRC asm
LD A,$20       ; bit 5 = $20
LD ($FF00),A   ; select P14 by setting it low
LD A,($FF00)
LD A,($FF00)   ; wait a few cycles
CPL            ; complement A
AND $0F        ; get only first 4 bits
SWAP A         ; swap it
LD B,A         ; store A in B
LD A,$10
LD ($FF00),A   ; select P15 by setting it low
LD A,($FF00)
LD A,($FF00)
LD A,($FF00)
LD A,($FF00)
LD A,($FF00)
LD A,($FF00)   ; Wait a few MORE cycles
CPL            ; complement (invert)
AND $0F        ; get first 4 bits
OR B           ; put A and B together
#+END_SRC

Cycles are wasted with repeated instructions (/debouncing/), because the polling
is not instantaneous.

In an emulator, we don't have that hardware quirk.  So we could coalesce all
these ~LD A~ into one (but still add the cycles of all the ~LD~ calls).

In fact, if this whole sequence is frequent in ROMs, we could just emit binary
that constructs the full byte of button states directly.

Another hint of optimizations is to look for redundant operations, like the ~LD~
above, and systematically coalesce them into one.  These optimizations would be
useful for any piece of code, not just this snippet.

* [2016-06-07 mar.]
** The fastest Chip8 emulator                                       :chipers:
So, I ported my Chip8 emu to Rust.  To have a smaller code base to test a JIT
with.

I have two ways to recompile a rom. It might be possible to compile the rom when
loading it (AOT): just create a function that does as much as possible in native
code, and jumps back to Rust code for things I don't know how to code in
assembly (e.g., drawing).

I don't yet know how I would jump back to a Rust function.  Is calling the
pointer address enough?

Otherwise, I can watch the code for hot loops, and try to compile those.  So I
need to visualize hot paths, in order to understand what patterns I need to
match.  Which brings me to the second point.

** GUIs in Rust                                                     :chipers:
Been looking for a nice and minimalist way to view the rom disassembly that
updates in real time as the interpreter goes through each opcode.

There's nothing provided by SDL.  Nor OpenGL.  Even writing text in those is a
PITA, and I don't want to be writing code to align two lines of text, to detect
mouse clicks, etc.

There are Rust bindings for GTK, but that does not strike me as friendly nor
minimalist.  And I'm not sure about the portability.

Luckily, I found ImGui which seems to fit the bill.  It renders to vertex
buffers, which can be plugged into an OpenGL renderer, so it's as portable as
OpenGL.  It's certainly minimalist, but it's good enough to have been used in
games and emulators for... debuggers and disassemblers!

Now, the only trouble is: the Rust bindings are light on the documentation
(read: there is none).  The only code example uses Glium as a renderer.  But I
already have an SDL window.  I could launch two windows: one with a SDL backend,
and one with Glutin (the backend of Glium).  But do I have to use threads?  That
could degenerate quickly, and seems opposed to the way ImGui is supposed to be
used.

Maybe I can just keep one loop that polls SDL, draws the frame, then does the
same for the Glium window.

Otherwise, I could switch my SDL rendering to Glium, or any other GL binding,
replace the drawing code with OpenGL calls, then draw the ImGui on top of that.

[later]

Tried only one loop to handle the two windows: one SDL, one Glium.  The ImGui in
Glium works fine, but the SDL windows does not update anymore.  Console is full
of debug errors caught by /Glium/, but the backtrace indicates that the error
originate in SDL2 calls.  Craziest thing.

I can only guess that SDL2 uses a GL context under the hood for accelerated 2D
rendering and, /somehow/, Glium takes hold of that GL context, and that,
/somehow/, they do not like sharing.

The errors caught by Glium are things like "~glVertex2f~ or ~glEnd~ is
deprecated".  Maybe SDL2 uses the old OpenGL API, whereas Glium is only
compatible with 3.0+?  Who knows.

In any case, that means doing the right thing: sticking to OpenGL for drawing
the emu AND ImGui.

* [2016-06-20 lun.]
** Switching chipers to OpenGL                                      :chipers:
Went full glium/glutin.  Glium is the library for high-level OpenGL bindings.
As I understand, it takes care of allocating GL objects and disposing them for
you.  It also help avoid the unsafeness of the GL API.

Glutin deals with the display manager of your OS to give you keyboard and mouse
events, to create a window, etc.  SDL handled both.  As I understand, Glium is
not tied to Glutin, but both are from the same author, so...

Anyway, using Glium/Glutin is not the hard part.  The hard part is understanding
how to draw things in OpenGL, especially with shaders.

** Drawing colored squares with triangles                           :chipers:
With SDL I was just drawing a "point" for each pixel of the Chip8 screen (cixel
henceforth).  And since I only knew how to draw triangles in OpenGL, I thought:
"Hey, let's draw a quad for each cixel!"

And that was a few hours, just to get something on the screen.  Because I had to
allocate a vertex buffer and modify it each frame, figure out how to pass my
vertices to this VBO, how to setup shaders just to get something, how to use a
projection matrix in the vertex buffer so that cixel coordinates would translate
to screen coordinates...

After a copious amount of ddging ([[https://tomaka.github.io/glium/book/tuto-01-getting-started.html][helpful tutorial]] from Glium dev
notwithstanding), I managed to get a Chip8 screen back.  Albeit clipping when
resizing.  And ... with horrible FPS performance after a few seconds.  What?

** Switching to drawing on a texture                                :chipers:
I figured that, since I didn't know what I was doing in OpenGL, I must have done
something wrong there.

The SDL version was smooth in frame time (constant 16.666ms).  Since I hadn't
touched that in the conversion, my GL-fu was to blame.

Maybe I was allocating a new VBO needlessly every frame?  Surely that would cost
me.  I don't know how Glium is implemented, but that looked like a potential
inefficiency right there.

So I started to question my rendering solution.  I knew that drawing triangles
was not the only way to draw the Chip8 screen in OpenGL.  It was the only way I
knew /how/.  But what solution did other choose?

Turns out, there are at least 30 chip8 interpreters written in Rust on Github.
And a dozen that use glium for rendering.  As far as I can tell, /every one of
them/ elected to draw the screen to a 2D texture.

The texture is then drawn to a single quad that spans the entire output screen.
No VBO allocation after initialization.  Not even a new texture allocation.

That... seemed alright.  And maybe even simpler that my approach, considering.

Some re-create a new texture for the quad each frame.  I read somewhere on the
Glium API that rewriting the texture contents can cause a CPU/GPU
synchronization, which I guess is bad for performance.  Have not tried to
compare the two approaches in frame time.  I just followed the [[https://github.com/Gekkio/mooneye-gb/blob/master/src/frontend/renderer.rs][guy who wrote a
GB emulator in Rust]].  Good enough for GB, good enough for Chip8, right?

Anyway, I was thrilled to see that the texture approach solved the clipping
issue that drawing quads had.

But, the horrible performance drop after a few seconds was still present.

** Did I enable VSync?                                              :chipers:
Lots of fumbling around, trying things with timing and what not.

In the end, I /though/ I'd found the issue.  My Nvidia driver had "force VSync"
enabled.  It's weird, because Glutin has a vsync option, which was disabled by
default.  And based on the fact that, in the SDL version, disabling VSync
actually worked, I figured it would be the same for Glutin.  Apparently not.

Disabling this option made the performance drop disappear.. for a while.

But I did encounter it a few times after that.  I guess it's a timing issue,
like not meeting frame time and still going after it.  Then there must be a sort
of mad race of the CPU trying to catch up to a shorter and shorter frame
time...

Probably should fix the main loop next.

** Anyway, ImGui is great                                           :chipers:
Once rendering to Glium was done, integrating ImGui was a breeze.

Could had a FPS counter, a memory view, and register info.

The only downside of using the Rust binding imgui-rs, is that porting C++ ImGui
examples is not straightforward.

The [[https://github.com/ocornut/imgui/wiki/memory_editor_example][memory editor example]] has nice features, like editing.  But you cannot just
"port" its code imgui-rs, because the API is not at the same level.  ImGui has
~begin~ and ~end~ blocks, while imgui-rs has closures.  Inside Rust closures,
there are mutability issues: you cannot borrow ~self~ mutably more than once for
instance.  I might find a way around it, or I might implement the memory view
using imgui-sys, the low-level binding.

** And GLSL can be great, too!                                      :chipers:
After battling with GLSL just to get a single color on the screen, I at least
put them to good use.

In my JS version, I wanted a CRT-like effect, since straight big quads on LCD
screen were boring.  Unfortunately, scared of OpenGL ES, I was rendering on
canvas, which meant that the CRT effect was done in software.  JavaScript +
software rendering effects = 10 FPS fullscreen for an emulated 64*32 screen.
Rather sad.

So I was delighted to see that fullscreen CRT + phosphor trail effects were
easily achievable on my machine.  And since I was using GLSL, I figured
/someone/ had battled the language long enough to produce a nice-looking CRT
effect that I could re-use.

Turns out, there are dozens of CRT shaders (especially for retro emulation).
Some of them are in a defunct shader language for NVIDIA hardware, Cg.  Some of
them target the D3D shader language, HLSL.  Some of them use various versions of
GLSL (compatible with OpenGL 2 to 4.. with mystifying shader language versions).

Anyway.  I took one that was convincing enough, banged on it until it worked for
my setup, and voilà.  Convincing effect.

Though I also tested it on my work box (integrated intel chipset from '07), and
it is unbearably slow.  Will add a flag, and might look into optimizations later
on...

* [2016-07-11 lun.]
** Thinking about perspective in 2D games
For a moonshot project.  I was envisioning a side-scrolling view, but I knew
from games I'd played that a top-down view lent more to exploration.  It got me
thinking of perspective choices in classic games.

Zelda 1 is top down.  Top-down gives you two axes of freedom.  It's much more
"open" than a side-scroller like Mario.   In Mario, it is evident you have to go
to the right.  There's no choice.  The difficulty is in getting there.   The
contrast with Zelda is evident: as you start, there are already four choices of
directions: up, left, right, and a cave.  Most of the screens have two exits or
more.  This choice helps convey a real sense of an open world, left to explore.
There's no pressure to the player, even though there is an implicit progression
path.

Contrast that with Zelda 2.  Zelda 2 has top-down overworld, but side-scrolling
dungeons, towns, and encounters.  The towns feel empty and repetitive, even
though they have people moving around.  You are just passing by.  Contrast to
Kokoriko village in Zelda 3: the structures there hamper your movements, they
are real.

But the overworld of Zelda 2 is rather limited as well: there are obvious
paths you should take.  The map is too much gated: you cannot go there yet,
cannot go there yet, etc.

The dungeons in Zelda 2 mostly feel like corridors.  The side-scrolling make
combat harder than it should be.  There are strong Castlevania vibes, except
with a puny dagger instead of a satisfying flail.

Castlevania, Megaman, Duck Tales... the side-scrolling lends itself more to
action than exploration.

But Metroid shows you can still pull off exploration in a side-scroller.

Roguelikes have been predominently top-down.  Rogue, Nethack, and the like.
Although this might have been motivated by technical limitations, the choice has
been deliberate in modern variations: Isaac and Necrodancer.  Though Isaac was
clearly inspired by Zelda 1, and Necrodancer rhythm component might have left
only the top-down option.  Risk of Rain chose a side-scrolling view, and it
makes the level much less interesting.  But again, that might just be because
levels are mostly empty, rather than caused by the perspective choice.

One thing is certain: in a side-scroller, the character usually obeys gravity.
Jumping becomes the basic way to use the second axis of freedom.  Otherwise you
have the clunky stairs of Castlevania.  Now, a game with jumping will lend
itself more to platforming than pure exploration.  This opens opportunities for
combat design: the fights in Zelda 2 are more involved than in Zelda 1.  But
Isaac shows that a top-down perspective can also have deep combat: it's mostly
about constraining the space the player can move to.

* [2016-07-26 mar.]
** About DSLs
So when you build any application, at some point you realize that you want a DSL
for maximum expressivity.

But there are various needs for a DSL, and various ways to build them.

For instance, in JS, there's a common idiom called a fluent API:

#+BEGIN_SRC js
$('#a')
  .css('color', 'blue')
  .toggle()
  .on('click', ...)
#+END_SRC

jQuery and D3 make heavy use of it.  I like to think of it as a DSL: it really
is a different language than plain JS, with different composition rules.  When
you begin an expression with ~$()~, you mentally switch into jQuery mode, to
know what you can follow.

The jQuery language is actually rather simple, the usual pattern is:

: $(selector)
:     .more_selection()
:     .manipulation()

First you target the elements you want to manipulate, then you manipulate them.
Pretty simple.

It happens to like the builder pattern used in Rust to build objects:

#+BEGIN_SRC rust
let display = glium::glutin::WindowBuilder::new()
  .with_title("Chipers")
  .with_dimensions((screen::SCREEN_WIDTH * zoom) as u32,
                   (screen::SCREEN_HEIGHT * zoom) as u32)
  .build_glium()
#+END_SRC

Here we are just building a configuration object.  The grammar is also rather
simple:

: FrobinatorBuilder::new()
:          .with_a()
:          .with_b()
:          ...
:          .build()

Bonus: there are actual types to these functions so the compiler can complain if
you mess up the grammar, like ~build~ before ~new~, or two ~build~ in a row.

D3 also has a fluent API.  There, the grammar can be a little more complex, with
the select/join mechanism, and things like ~enter~.

A simple language is one that builds an AST, you just compose functions:

: seq(assign(var(x), plus(num(1), num(2))), print(deref(x)))

The grammar is simply:

: expr: seq | assign | var | plus | num | print | deref

I'm wondering what happens when you take object algebras, but you only really
need one interpreter, not many?

#+BEGIN_SRC js
/* eslint-disable */

var e1 = m => { with(m) {
  return plus(num(1), num(2))
}}

e1 //: function

var interp = {
  plus(a, b) { return a + b },
  num(n) { return n },
}

e1(interp) //: 3

// Might as well

var plus = (a, b) => a + b
var num = n => n

var e2 = plus(num(1), num(2))

e2 //: 3

// thunk it

var e2t = _ => plus(num(1), num(2))

e2t //: function
e2t() //: 3

// How about partial evaluation?

// Here is a program

var e3 = m => { with(m) {
  _def('rec', _ =>
       _if(_less(0, 2),
           _ => 1,
           _ => _call('rec')))
  return _call('rec')
}}

e3 //: function

var _eval = {
    _v(n) { return  },
    _def(f, b) {
      this[f] = b()
    },
    _if(c, t, e) {
      if (c) { return t() } else { return e() }
    },
    _less(a, b) { return a < b },
    _call(f, a) {
      return this[f]
    }
  }

e3(_eval) //: 1

// Well, that's not very interesting

// Thunk everything?

var ast = {
  plus(a, b) { return {
    eval() { return a.eval() + b.eval() }
  }},
  num(n) { return {
    eval() { return n }
  }},
}

e1(ast).eval() //: 3
#+END_SRC

Okay, that was crap.  Time to forget.

* [2016-07-29 ven.]
** Revisiting the Game Loop
All [[https://www.youtube.com/watch?v=fdAOPHgW7qM][these]] [[https://www.youtube.com/watch?v=jTzIDmjkLQo][talks]] helped me understand how a game loop should work.  But it also
applies to any simulation, including emulation.

As usual, I prefer to go from most straightforward solution, and understand
/why/ it's wrong, and /why/ the correct solution is not the first that pops into
my mind.

So, the first game loop I remember writing was an OpenGL Pong.

I lifted code from NeHe's OpenGL tutorials, and hacked it until I had a game
working.  The tutorial code already took care of pushing a triangle to the
screen.  It used OpenGL direct mode, which was easy to pick up, so I just
changed it to have two rectangles at the edges of the screen.

Then came input.  Here again, the tutorial had code for grabbing input from
Win32.  I just had to find the right place, the correct keycode, and move the
rectangles by a reasonable amount.  The code looked like so:

#+BEGIN_SRC c++
void handle_input(...) {
  ...

  if (is_keydown(VK_UP)) {
    player1 += 0.12f;
  }
  if (is_keydown(VK_DOWN)) {
    player1 -= 0.12f;
  }
  if (is_keydown(VK_A)) {
    player2 += 0.12f;
  }
  if (is_keydown(VK_X)) {
    player2 -= 0.12f;
  }

  ...
}
#+END_SRC

Now I had moving rectangles!  Then I moved to collision detection, which as I
remember was solved with a bunch of ~if~.  Anyway, it worked great!  Surely I
had to tweak the move values above until if felt right–not too slow, but not too
fast either.  At this point I was rather proud.

So I copied the game onto a floppy, and brought it into school.  It so happens
that we had a computer room, to which I had access at any time between classes
because I helped set it up, along with other students.  So I put the floppy in,
launch the executable and behold!

Oh wait, it's all going /much too fast/.  Even the slightest input will move the
paddle half a screen worth; it's barely playable.  And the ball just passed
right through the right paddle without hitting it!  What happened?  It was
working right on my machine.  Needless to say, my friends were only mildly
impressed.

Of course, now I understand perfectly why it happened, and why I made that
mistake.  The computers at my school were simply faster than the one I had at
home.  I don't remember if there was any syncing to a fixed framerate or to the
monitor refresh rate in the NeHe code.  If there was, it might be that I was not
hitting that framerate at home, but I doubt it as it was /OpenGL/ for rendering
two rectangles paddles and a square ball, not software rendering.  So maybe
there wasn't any framerate limit in place, and the computer at the school just
went as fast as possible.

Now, having only written a handful of programs, this was my first simulation.  I
had written interactive text-based games, but these were turn-based.  You print
something to the screen, wait for user input, then print something else.
Running it on different computers would get you the same results.  For other
programs that sort numbers or print something to the screen even without
interaction, you usually /want/ them to run faster on beefier computers.  So I
did not even think twice at how that would play out for a simulation.

In a game like Pong, you want it to behave the same from one computer to
another, regardless of the specific hardware that supports it.  If you think
that the ball moves at 1 pixel per frame, then the game will feel faster at a
lower resolution, or at a higher frame rate.  OpenGL already frees you from the
actual display resolution, by giving you a continuous space for positioning
objects: the paddle moves by ~0.12f~ each frame, not 1 pixel.  You have to think
of time as being continuous as well: say, the ball at ~0.3f~ each 60th of a
second.

Then you understand why you cannot write the game with a ~while(true)~ loop that
just simulates and renders as fast as possible.

** Sampling player input
One thing that I might have missed from my [[*What’s the ideal solution to input latency anyway?][previous discussion on input latency]].

Consider sampling a simple button press:

: __________----------__________
:  10ms        10ms      10ms

This is continuous from the player point of view.  But if we sample, say, every
20ms, depending on where the sampling begins, we might miss the button press
altogether:

: __________----------__________  signal
:    |   20ms            |        samples
: ______________________________  reconstructed

Because the game has to reconstruct the signal from the sampled points, and the
two samples are 0 (button up), the game never sees that the player has pressed
the button:

Now if have a 6ms sample rate:

: __________----------__________
:   |     |     |     |     |
: _________------____________
: _________-----------_______
: ______________------_______
: ____________-----__________

If the signal changes between two sample points, there is an issue.  You don't
know exactly when the signal changed, so you have many ways to interpret it.

Usually in the code I write, I just look if the button is pressed, then simulate
as if it was pressed for the duration of the frame.  So you end up with:

: __________----------__________
:   |     |     |     |     |
: ______________------_______

we see that are already losing information.

Now, if we are sampling every 4ms:

: __________----------__________
:   |   |   |   |   |   |    |
: __________------------_____

it does not matter if we are below the Nyquist frequency for sampling, because
the function is not continuous I guess?

Anyway, if we sample at a high enough rate, hopefully the user won't notice the
discrepancy between their input and the input synthesized at the screen.

* [2016-07-30 sam.]
** Revamping S3C for evaluation inside blocks                           :s3c:
See [[https://github.com/fmdkdd/s3c/issues/4][issue 4]].

Managed to make it work using esprima + estraverse + escodegen.

First: using those on the browser is kind of a shitty situation without modules.
I can install esprima with bower and use that directly.  Fine.  Then, estraverse
is also on bower, so I install that.  But the file is not browser compatible,
you have to use browserify.  Ok fine, I install browserify and run it, then get
something I can import in my HTML and it works.  Finally I need escodegen.
Surprise, the bower package does not work.  I try npm, I see that one can build
a browser version from that (not using browserify mind you, but another tool,
cjsify).  Does not build.  Ok, there's an issue and even a pull request for
that.  You can't build the browser version from the npm package; you have to
clone.  I clone, build, and now I have a browser build!

Three related modules, three ways to get the browser version.

So at the moment I have the basic functionality of evaluation markers working,
even in blocks.  There are changes from the previous evaluation model though.

Previously, we split the evaluation of the code everywhere there was a marker.
So if an expression evaluated to an error (even a syntax error), we would
evaluate the rest of the program without the error impacting us.

Now, we evaluate the whole program at once, and collect the values of the
expressions that have markers.  If there is an error at the start of the file,
it's less resilient.  Also, esprima will fail to produce an AST if there is a
single syntax error.

I don't have errors working yet, but we are already losing functionality I'm not
sure I can get back.

Cleaning up the logic.  I can't use the backlog method now because markers in
blocks may receive multiple results.

Cleaning up more, I have errors and timeouts working again.  For the moment one
error stops evaluation for the whole program.  Maybe I can capture them by
wrapping the expression statements in a try/catch...

Speaking of which, I tried to put a marker inside a try/catch and it did not
work.  Must investigate later.

Now I'm trying to see if the code I have from my PhD manuscript works with the
new logic.  And... SYNTAX ERROR AT LINE 2.  Esprima fails to parse ES6
syntax... sigh.  Wait, the README says it /does/ support ES6.  Latest version is
2.7.2, and ... the heck.  I have 2.0.0.  Well, thanks bower.  Guess I'll just
grab the latest version and manage it by hand then.

Ah, now that's funny.  Because ESLint also uses esprima, but an obsolete
version that's bundled inside the file.  That's at least three different parser
for the same project.

Anyway, updated Esprima, and the example works!  Except I have to try/catch the
one deliberate error.

Oookay.  Fixed evaluation markers in IIFEs.

Problem was twofold: first could have multiple markers associated with the same
evaluation comment.  But only one them would receive a result back from the
worker.  So ~undefined~.

I fixed this by using a map to keep track of comments already seen and the
marker we constructed for it.

Then we did not associate evaluation comments to the nearest parent expression
statement, but to all expression statements above.  Thus, in an IIFE like:

(function(x) {
  x //:
})(1)

there would be two ExpressionStatements: ~x~, and the IIFE.  Both would be
associated to the one evaluation comment, and receive a result from the worker.
And the second result would overwrite the first, so ~undefined~.

I fixed that by doing a first traversal of the AST to find evaluation comments
and associate them with the nearest parent expression statement.

IIFEs work.  Try/catch works.  Loops work.  ~with~ works.  Useless braces blocks
work.

I have slightly changed the semantics of the evaluation marker though.  Before,
it would give the result of the /last expression/.  Now it gives the result of
the nearest parent expression.

Okay, wrapping the expression in a try/catch allows me to prevent errors from
polluting the rest of the results.  I added an alternative syntax for this
behavior though, as it can be unexpected inside a try/catch.

* [2016-07-31 dim.]
** Updating ESLint                                                      :s3c:
So I want to update ESLint because the parser is out of date.  And the
browserified file is disgustingly huge (671K).  I get the latest version, well
they are still using browserify.  The output is now 2.7M.

Okay, been looking around.  It's a bit ridiculous to charge that 2.7M, but there
might not be an easier way to get an up to date version of ESLint.

I've noticed that ESLInt is using a fork of Esprima, espree, so I can't factor
that out.  It might make sense to use espree as well, or even Acorn.  Shouldn't
be too much a bother since the interface seems compatible with Esprima's.

Maybe I'll just try to uglify ESLint and see how that goes.

Making a note here that there's a way to get back the parsed AST from ESLint.
Should I want to reuse it.  But I'm not sure it would make a difference.

Using Uglifyjs compression and mangling slims down ESLint to 808K.  An
acceptable size bloat for the gained functionality.  Okay, let's minimize
everything while I'm at it.

aaand updated CodeMirror to latest version.

Done & uploaded.

* [2016-08-01 lun.]
** Performance issues                                                   :s3c:
It didn't feel like the new version of s3c was any slower than the previous
one.  On my home machine.  On my work machine there is perceptible delay.
Around 500ms I would say, but can't say exactly since profiling does not even
work under Firefox.

So on my machine a full eval cycle + rewrites takes 75ms:
- triggering the eval takes 45ms with 35ms spent in ~reval~ (15ms parsing, 8ms
  clearing the markers on the page) and 10ms lost in ~endOperation~.
- the remaining 30ms are spent in ~write~ calls.  Each write averages 1.5ms.

And that is /after/ doing a first optimization, which is fixing the size of the
editor.  Previously the editor had ~height: auto~.  But that meant that any
change to its content would be written back to the DOM, even if that content was
outside of view.  CodeMirror does not do a hit test to check if it's in view.
Instead, you should let CodeMirror handle the scrolling.  Doing that shaved 30ms
off.

Also of note is the time to evaluate the JS: 277ms, and 47ms to finish ~init~.

Reusing the AST from ESLint is a big improvement.  But, it's not equivalent.
Linting happens sporadically (debounce + 500ms), so Ctrl+enter just after an
edit will have an outdated AST.  Linting takes 121ms on the same buffer: 50ms
parsing and the rest applying rules and update the DOM.  121ms is the first
time, after I get around or below 50ms.  Maybe JIT optimizations kicking in?
Might be worthwhile to reduce the linting delay and have linting always happen
before we have time to trigger evaluation.  Then we reuse the AST.

Was trying to reuse the ESLint AST in this fashion, but hit a weird behavior
where after a first eval, the subsequent evals did not refresh the markers.
The markers are empty the second time around.  Not sure why.  But it negates the
visual feedback of clearing the markers.  Maybe I can get the visual feedback by
flashing the Run button instead?

Reusing the AST shaves 15ms off, but is not quite correct yet, since we have to
detect if the text has changed since before the last lint, otherwise triggering
eval reuses the obsolete AST and it does nothing.  I have to think through the
whole pipeline as:

user changed text -> debounce to 250ms -> reparse (ideally, with a parser that
does not start from scratch) -> give AST to linter

But if reval is triggered and we don't have a fresh AST, then reparse, eval, and
save the AST for linting afterwards.

In the meantime, I've got it down to spending only 10ms to reval and 10ms to
rewrite.

But, only now I finally find that the worker takes 25ms to actually eval the
code.  And from hitting Ctrl+Enter to seeing the eval results, it's around
350ms, mostly of waiting around for debouncing.

* [2016-08-02 mar.]
** Links on incremental parsing                                         :s3c:
Not sure it would be worth it for the scale of the code that s3c deals with, but
here are some resources on incremental parsing would I want to pursue it (or
just out of curiosity):

- [[http://harmonia.cs.berkeley.edu/papers/twagner-parsing.pdf][this paper]] from 1998 seems to cover the theory, and even provides the Java
  code for its algorithms for incremental parsing based on LR grammars.
- [[https://github.com/Eliah-Lakhin/papa-carlo][this project]] is an incremental parser in Scala using PEG grammars.

Intuitively, we might get good mileage out of a few heuristics like looking at
blocks: if I change a character inside function ~f~, then at worst we only need
to reparse the node for this function.  Given a change, walk up the tree to the
first block, throw the node, reparse and replace.  Now, 1) I don't know how
sound that actually is, and 2) now sure how it holds with larger changes (a find
and replace, or an undo).  The pathological example would be: erase everything.
Now parsing from scratch the empty string should be faster than walking the tree
checking if every node is still there.

The problem can also be entirely side-stepped with an editor that would only
allow actions that modify the AST without ever creating an invalid one.  Rather
than editing at the character level, you edit at the AST node level.  But I
don't know how practical that can be in the end.

Anyway, all of that might not even matter for speeding up s3c, since parsing
might not even be the biggest bottleneck.

* [2016-08-13 sam.]
** Using the JSON error format of rust for flycheck                :flycheck:
*** Restoring functionality
Previous message parser was rather straightforward: error appeared as errors,
warnings as warnings, and note or help lines appeared as info squiggles.

In the JSON output, we have multiple spans that corresponds to squiggles.  One
span is the primary (the root cause or main line of the error), and the others
seem to correspond to notes in the compiler human readable output.

*** Passing tests
The JSON output is the same format for stable and nightly, but the exact output
can change from version to version.

*** Changing flags triggers a rebuild?
There was a mention on a thread somewhere that using RUSTFLAGS to ask for
~--error-format~ in IDE can trigger a full rebuild of cargo.  Can't reproduce in
our setting; maybe because we don't use RUSTFLAGS but call ~cargo rustc~?

*** Flycheck does not use line or column end points
Squiggles only overlap the symbol at the given line/column, but rustc will
output the start and end position already.  Flycheck does extra calculation for
nothing, and it's less accurate than rustc's info.

Sebastian outlined the steps for accepting column pairs in flycheck ([[https://github.com/flycheck/flycheck/issues/89][issue 89]]),
but that might be outdated.

*** Looking up explanations from Emacs
rustc provides explanations, but I don't think that's flycheck's job to show
them to us.  I could write a function ~explain-rust-error~ that looks at the
code of the error under the cursor (when flycheck is loaded) and opens a
temporary help buffer with the explanation.  Without flycheck, it asks for an
error code interactively.

* [2016-08-15 lun.]
** Using column end points for rustc in flycheck                   :flycheck:
I started by using cons cell for columns instead of a number.  Then flycheck
complained the checker returned an error.  But since it caught the error, I
could not use the debugger to trace it.

There are multiple places where columns are used.  I managed to hack my way
through them until it worked.

I had assumed that just reusing the column value of rustc for the overlays would
work... but overlays only use a single coordinate for their start and end
points.  I had to convert the (line column) information to a single character by
piggy-backing on ~flycheck-error-column-region~.

And it works!

But it is at odds with the notion of flycheck highlighting modes.  I think the
behavior we want is: try to use the line/column info returned by the checker,
otherwise fallback on the selected mode: lines, columns, symbols, sexps.

We want to fallback because not all tools might give column end information.

* [2016-08-16 mar.]
** Imaginary property
This morning when coming over to work, I was having an internal debate about one
of my pet peeves: copyright.  Or, how I prefer to call it, /imaginary property/.

Note that I have no claim of originality on this moniker.  To the extent that
someone /can/ claim precedent on a juxtaposition of two words.  But after all,
since many companies do hold rights to such juxtapositions in the form of
slogans, brands, or product names, you never know.  I can however cast any doubt
that I thought of it first, as I encountered it years ago on the news site
Slashdot, where a user went by the asserting handle
"I_do_not_believe_in_imaginary_property".

I was having this internal debate.  Oh, an internal debate is basically what it
says on the cover: me having an argument in my head, with at least two voices
making their points in order.  These debates tend to play like a mix of chess
and golf.  Each side is carefully considering their next move to find the best
play.  They want to corner the opponent, and not leave him options to escape.
At the same time, I, as the observer, want to find arguments that have the most
weight, that raise the most interesting questions.  I try to take each argument
charitably, as the purpose is not so to that one side wins, but to better
understand each side's point of view.

Thus, this morning debate's was about imaginary property.  Now, I like this term
because it is not neutral at all; it's a moral statement.  Not unlike the word
"copyright" itself: the "rights of copying" is not an innocent denomination.  If
you accept the word, you accept its moral premise: that copying should be
regulated by rights.  The same happens In the french terminology, where our
copyright law is an "intellectual property law".  If you silently accept the
name, you tacitly agree that there is such a thing as an intellectual property.
The assumption here is that coining terms such as "intellectual property" is a
weasely way to conjoin your mental representations of both concepts.  With this
connection unconsciously made in your brain, you are eased into taking this
chimeric concept as a fact.  The choice of words here is truly Orwellian.

One of my mental orator disagrees with this premise, and counters with a loaded
term of his own: you speak of intellectual property, but I say it is imaginary.
The whole premise is refuted, so that any further arguments on the specifics of
copyright is moot.  It steers the debate to whether it is even /possible/ to own
thoughts in the first place.  It is powerful opening move.

The answer may seem obvious.  /Cogito ergo/ dibs.  Who is doing the thinking?
/I/ do, therefore the thoughts are mine.  Consequently, any product of these
thoughts is also mine.  Well, that may be tautological for some, but I do not
see how it follows.  We could again argue the premises: that there is an "I",
that there are thoughts to be had, that our experience of individuality is not
just an illusion, a side effect to the working of our brains.  However, at this
point in the debate most interlocutors would question my sanity and leave the
room (through my ears).

Fine, we'll take another route.  We can concede the reality of consciousness and
individuality.  These are convenient concepts after all—allowing me to use "I"
all along this text without eliciting existential conundrums.  But we can still
question the ownership of thoughts.  For me, ownership by the thinker is not
obvious.  Here's how I /think/ it works: thoughts are not created; they are not
elaborated by the sheer power of our will, they are merely witnessed as they
happen in the brain.  The brain is made of neurons; neurons stimulate each other
by chemistry and electricity; so much we know for a fact.  Now, to the best of
my knowledge there are no sound explanation of what a thought is in term of
neurons.  It might forever be an ill-defined notion, even if we someday crack
the brain's secrets.  I will make the reasonable assumption that if we have any
thoughts, they are caused by neuronal activity.  I like to picture the neurons
as a large and dense graph.  Millions of nodes, billions of edges.  A thought is
then a collection of /bounded walks/ along the graph.  Some neurons are excited,
they light up, thinking happens.  Due to the size of the graph, the number of
different walks in just one brain is practically infinite.  In this view, one
can have infinitely many different, unique thoughts.  But two exact same walks
would produce the exact same two thoughts.  All our thoughts thus depend on two
factors: the brain configuration, the way it is wired up; and the initial
stimuli, the start of the neuronal promenade.

If we accept this model, we must see that in order to claim ownership over these
thoughts, we must be in total control of these two factors.  But how can it be
the case?  The initial stimuli is clearly not entirely in our control.  We have
no way of forcing thoughts through some neuronal pathways.  It can /feel/ like
we are steering the boat, but there clearly is something happening at the
unconscious level that is doing the heavy lifting.  And the other factor is
mostly genetic and/or environmental, depending on your stance.  If you do not
believe in free will, then trivially you cannot say to be in control of your
thoughts.  If you do believe in free will then you can think your daily actions
may have an impact on your brain configuration.  But this impact is at best
indirect.  Your thoughts are what they are because you where brought up in
/that/ city, in /that/ neighborhood, in /that/ country, on /that/ planet, and
you grew up with /that/ family, /these/ friends, and you read /these/ books, and
listened to /that/ music, and visited /that/ place where you had all /these/
memories...  All of that shaped who you are, and what you think, and it
continually keeps doing so.  And you cannot reasonably claim ownership of all of
these factors.

-----

Most proponents of copyright conflate two topics: the regulation of copying
intellectual works, and the remuneration of the authors of said works.  A
simplified, but too common argument goes like this: "Well, copyright is a good
thing because that's how artists get paid."  To which one would answer: "No,
copyright is /wrong/, because it goes against our instincts to share".  Stop!
You are arguing different things!  One is for the remuneration of artists, while
the other is against the criminalization of sharing!

How I can conceive that we have these views:

- making your mark in imaginary space, obtaining a plot of intellectual land

That's by analogy to physical property.  But maybe this analogy is not
appropriate?

Intellectual colonists?  Who go and appropriate themselves a plot of
intellectual land.  We do seem to treat intellectual property as we do physical
property.  We can cede these lands: rights of exploitation.  We even have a word
for intellectual property trespassing: plagiarism.


The view of an untainted vision, the lone genius:

- seeing your work as optimal?  Then any deviation would invariably lessen it.

I stumble upon an indie gameboy color game.  The sources are given in a CC-NC
license, but the music strictly forbids /derivatives/.  How can anyone sustain
this position?

Here are the musicians in question:

#+BEGIN_QUOTE
The discussion and copyrights are mostly to protect the original score and its
original vision. I can't really give you much more info than that, mostly
because I wasn't the one who was negotiating all of this.

I had a lot of fun converting and worked really hard with the music translating
it to GBC though. It'd be a shame to hear it modified. So I believe the
negotiations were meant to protect our involvement as well.
#+END_QUOTE

#+BEGIN_QUOTE
The status of the game as of now is open source with special rights, music
cannot be used elsewhere/modified without my consent (Eric E. Hache) and no
commercial endeavours. For the rest of the licensing, please check Affinix’s
Github license file.
#+END_QUOTE

* [2016-08-17 mer.]
** Chasing a failing build under emacs snapshot                    :flycheck:
Trying to reproduce the Travis errors on my machine.

~./autogen.sh~ suggest I run ~./autogen.sh git~ after it.  This is not done in
the makefile.

Trying to run the tests with emacs 25, cannot find ~dash~.  ~make clean~ and
~make init~ fixes it, and now I have an error because warnings (same thing as
the Travis build):

#+BEGIN_EXAMPLE
In toplevel form:
flycheck.el:5443:1:Warning: Unused lexical variable ‘\.label’
flycheck.el:5443:1:Warning: Unused lexical variable ‘\.column_start’
flycheck.el:5443:1:Warning: Unused lexical variable ‘\.line_start’
flycheck.el:5443:1:Warning: Unused lexical variable ‘\.file_name’
flycheck.el:5443:1:Warning: Unused lexical variable ‘\.is_primary’
#+END_EXAMPLE

So just having warnings trigger a non-zero exit in Emacs 25?

As I suspected, the warnings are caused by nested ~let-alist~ calls.  With just
one ~let-alist~ the compiler does not complain, but when they are nested all the
~.name~ inside the nested calls are considered free variables.

Unnesting these calls make the warnings disappear.

But why are warnings appearing in the first place?  My understanding is that
~let-alist~ is a macro that adds syntactic sugar for looking up the alist.  This
is expanded at compile-time, and thus all ~.name~ should disappear.  But the
byte compiler still sees those that are in nested calls to ~let-alist~, so the
macro expansion is not recursively done?

#+BEGIN_SRC emacs-lisp
(cl-prettyexpand
 '(let-alist '((a . 1) (b . 2)) .a))

(let ((alist '((a . 1) (b . 2))))
  (let ((\.a (cdr (assq 'a alist))))
    \.a))
#+END_SRC

#+RESULTS:
: 1

#+BEGIN_SRC emacs-lisp
(cl-prettyexpand
 '(let-alist '((a . 1) (b . 2))
    (let-alist '((c . 3) (d . 4))
      .c)))

(let ((alist '((a . 1) (b . 2))))
  (let ((\.c (cdr (assq 'c alist))))
    (let ((alist '((c . 3) (d . 4))))
      (let ((\.c (cdr (assq 'c alist))))
        \.c))))
#+END_SRC


Ah!  The first ~let~ line triggers the warning.  This is because ~let-alist~
thinks every ~.name~ under it should apply to it, but this is false when nesting
calls.

If the expansion happened from the innermost ~let-alist~ first, I guess this
would work.  So it's a bug in ~let-alist~.

The docstring of ~let-alist~ acknowledges that you can nest it, with the
downside that you cannot access the variables of the outer ~let-alist~.  This is
obviously because the inner ones shadow the ~alist~ variable.  This is a hygiene
issue.

So, two bugs for nesting.  Thanks, ~let-alist~!

** Checking out the competition                                    :flycheck:
Saw a thread on users.rust about how IntelliJ-rust had great support for rust.
Struck by a sudden fear of missing out, I investigate.

IntelliJ does it own font aliasing, which has clearly gone wrong, because every
piece of text has a thin blue outline.  Subpixel aliasing problem?  If only use
"Greyscale" aliasing it's bearable.  But, I'm using OpenJDK, and they note that
it is unsupported, so let's not throw the stone here.

Well, first it complains that the project is using a virtual ~Cargo.toml~ file.
Ok, I'm using vulkano to test it out, and I just read that the rust plugin does
/not/ support this setup.  But it works with flycheck, so I assumed it was fair
game!

Okay, switching to the vulkano library inside the meta project.

I can get feedback on parse errors rather quickly.  I suppose that's a plus of
using their own parser.  On the other hand, I can't seem to get errors from the
compiler.  I can't seem to build from the 'Build' menu, as it requires an SDK,
but I see only Java options in there.

Okay, I can use cargo commands in the 'Run' menu.  Let's try ~cargo build~.  It
opens up a lower panel with the command output.  There are two errors (that I
inserted), but no visual feedback in the file itself.

But maybe this just a work in progress.  It does notify when a constructor field
is missing.  So I guess they are just using their own sauce to give error
feedback, rather than using what the compiler tell them.  That's a waste.

Okay, not impressed on this front.  I thought I would at least parse the errors
and put them in the current buffer.  Especially as there is a cool fringe
preview: to the right of the buffer is the fringe, that shows points of
interest.

The fringe is a mix between the overview map of Sublime Text and the left margin
of Eclipse.  The fringe always represent the whole file, not just the current
view.  You have lines with different colors in the fringe that give different
information.  For starts, it highlights all the places where there is a ~TODO~
comment.  The nice thing is that if you just mouse over the fringe line, you get
an instant preview of that place in the code.  You don't have to jump there.
Similarly, when the cursor is on a symbol, it highlights all instances of this
symbol in the buffer, and places line in the fringe for all of them.

But, I see that the highlighting only works for symbols that are defined in the
file.  The upshot is that it's not just a text search, it's really trying to
give you the occurrences of /this/ symbol, and avoid false positives.  The
downside is that sometimes it does not work at all.

The find usage is the same thing, but can also report the usage across different
files.  That's definitely a useful feature.  I wonder if it's something ~racer~
could provide.  Having a text search with ~ag~ is useful regardless of the
language, but having no false positives is also great.

There is a block selection thing like ~expand-region~.  It is more fine grained
than ~expand-region~ does for me in Rust, which reminds that ~expand-region~ is
extensible and that it may be worthwhile to make it work a bit better with Rust.

Automatically matching of braces when editing.  Well, this is basically
~electric-insert~, except that:

: Cpu {}

deleting the closing brace in IntelliJ does not delete the opening one.  So it's
not matched anymore.  But funnily enough, electric has the complementary quirk
where deleting the /opening/ brace does not work when they are on different
lines:

: Cpu {
: }

I'm always fighting these modes anyway.

Go to definition works, but mostly on definitions from the project.  It can go
to structs from the stdlib, but not inside crates.  I think racer does it for
stdlib, not sure for crates.  Curiously enough, the "Find symbol" feature can
find those functions in crates.  Maybe it cannot determine the definition place?
Again, no false positives, which is good.

Then there are snippets.  One thing I'm not sure ~yasnippet~ provides is
surrounding a piece of code with a snippet: start with a line, then surround by
a loop for instance.

So:

- check if racer can find definitions and usages, and how to leverage that in
  Emacs

(for a quasi-correct solution that's also fast, check ~dumb-jump~ which seem to
support rust)

Other minor features:
- see how to teach ~expand-region~ about Rust
- check if we can surround code with a snippet
- see how a whole-buffer fringe and buffer previews would work

Currently, when doing a symbol search with ~ag~ in Spacemacs, it opens up a Helm
window with multiple candidates.  Since there can be false positives, I need to
to quickly glance at each line to see it's the file/location I'm interested in.
Unfortunately, I can't seem to get Helm to open the current line in a preview
buffer, /while keeping the list of candidates open/.  I can recall the list of
candidates, and keep going, but that's not as fast as just glancing.

I'm pretty sure that having a preview like the fringe from IntelliJ would be
difficult to add without hacking emacs itself.  And I'm also pretty sure it has
zero chances of being adopted.  But, we'll see what we can do.

** Preview in helm-ag
Oh, I just looked up the bindings for Helm, and hitting ~TAB~ on a candidate
does what I want.  Even faster is ~helm-swoop~, but this works preferably on
open buffers.

Good news!

** Testing dumb-jump
Er... it works.  Sometimes.  And it's slow.  Maybe something can be done to
improve the functionality there.  But really, I think racer covers it and more.

* [2016-08-18 jeu.]
** Workarounds for let-alist                                       :flycheck:
The nesting bug has been bugging me.

Looking at the [[https://lists.gnu.org/archive/html/emacs-devel/2014-12/msg00231.html][original discussion]] for introducing ~let-alist~ to Emacs, there
a couple alternatives are mentioned.

Inline macro for reducing the ~cdr assq~ noise:

#+BEGIN_SRC emacs-lisp
(cl-macrolet ((a (field) `(cdr (assq ,field '((c . 1) (d . 2))))))
  (a 'c))
#+END_SRC

#+RESULTS:
: 1

And using ~pcase~:

#+BEGIN_SRC emacs-lisp
(pcase (alist-get-keys alist key1 key2 key3)
  (`(,val1 ,val2 ,val3) body))
#+END_SRC

but this one requires ~alist-get-keys~, which presumably is in Emacs 25.  But
Emacs 25 also includes ~alist-get~, which already reduces the noise a bit.

* [2016-08-22 lun.]
** Testing C# under Linux
To see if it's bearable, and whether there are no obvious discrepancies between
platforms when running the same app.

First I installed 'dotnet-cli' from AUR.  Took forever to build.  It had a
dependency (lttng-ust) that was in AUR also, and cower does not handle that.
Luckily, that was the only one.

Then the example of:

: dotnet new
: dotnet restore
: dotnet run

works as advertised.  Though the notice to dotnet is chilling:

#+BEGIN_QUOTE
Telemetry
--------------
The .NET Core tools collect usage data in order to improve your experience. The
data is anonymous and does not include commandline arguments. The data is
collected by Microsoft and shared with the community.  You can opt out of
telemetry by setting a DOTNET_CLI_TELEMETRY_OPTOUT environment variable to 1
using your favorite shell.  You can read more about .NET Core tools telemetry @
https://aka.ms/dotnet-cli-telemetry.
-------------------
#+END_QUOTE

Now, onto a more serious app, one from [[https://github.com/merwaaan/shader-study/][merwaaan]].  Let's build that.

Wait, it does not have a 'package.json' file?  Only a 'csproj' you say?  Hmm.

Do I need visual studio as well?  Ah, [[https://blogs.msdn.microsoft.com/dotnet/2015/03/18/msbuild-engine-is-now-open-source-on-github/][maybe not]], just 'msbuild.exe' should do
it.  Let's build that.  Again, it's in AUR.  Waiting.

Now let's build it.

#+BEGIN_EXAMPLE
> msbuild.exe Shaders.csproj
Microsoft (R) Build Engine version 14.1.0.0
Copyright (C) Microsoft Corporation. All rights reserved.

...

 /tmp/shader-study/Shaders/Shaders.csproj(229,5): error : This project
references NuGet package(s) that are missing on this computer. Use NuGet Package
Restore to download them.  For more information, see
http://go.microsoft.com/fwlink/?LinkID=322105. The missing file is
..\packages\AssimpNet.3.3.1\build\AssimpNet.targets.
#+END_EXAMPLE

Oh.  I need to install dependencies.  Fair enough.  Let's get this nuget thing.
This time it's in Arch.

#+BEGIN_EXAMPLE
> nuget install
Installing 'AssimpNet 3.3.1'.

...

The 'System.Runtime.InteropServices 4.1.0' package requires NuGet client version
'2.12' or above, but the current NuGet version is '2.11.0.0'.
#+END_EXAMPLE

Hmm, okay.  Let's get nuget3 from AUR then.

Once more:

#+BEGIN_EXAMPLE
> nuget install
Feeds used:
  /home/fmdkdd/.local/share/NuGet/Cache
  /home/fmdkdd/.nuget/packages/
  https://api.nuget.org/v3/index.json

Restoring NuGet package System.Runtime.InteropServices.4.1.0.
Adding package 'System.Runtime.InteropServices.4.1.0' to folder '/tmp/shader-study/Shaders'
Added package 'System.Runtime.InteropServices.4.1.0' to folder '/tmp/shader-study/Shaders'
#+END_EXAMPLE

Smooth.  Ah, but wait, it doesn't build.  msbuild is still confused.

Hmm, let's try that again.

: rm -rf shader-study
: git clone --depth=1 ...
: cd shader-study
: nuget restore

And now...

#+BEGIN_EXAMPLE
> msbuild.exe Shaders.csproj
GUI.cs(18,23): error CS0227: Unsafe code may only appear if compiling with /unsafe [/tmp/shader-study/Shaders/Shaders.csproj]
GUI.cs(52,28): error CS0227: Unsafe code may only appear if compiling with /unsafe [/tmp/shader-study/Shaders/Shaders.csproj]
GUI.cs(102,29): error CS0227: Unsafe code may only appear if compiling with /unsafe [/tmp/shader-study/Shaders/Shaders.csproj]
#+END_EXAMPLE

Interesting.  Let's try this flag:

#+BEGIN_EXAMPLE
> msbuild.exe /unsafe Shaders.csproj
MSBUILD : error MSB1001: Unknown switch.
Switch: /unsafe
#+END_EXAMPLE

Kidding me.  Let me ddg that for you.  Hey, that's actually the "property"
"AllowUnsafeBlocks".

#+BEGIN_EXAMPLE
> msbuild.exe /p:AllowUnsafeBlocks="true" Shaders.csproj

GUI.cs(15,33): error CS1069: The type name 'Vector4' could not be found in the
namespace 'System.Numerics'. This type has been forwarded to assembly
'System.Numerics, Version=4.0.0.0, Culture=neutral,
PublicKeyToken=b77a5c561934e089' Consider adding a reference to that
assembly. [/tmp/shader-study/Shaders/Shaders.csproj]
#+END_EXAMPLE

Hmm that looks problematic.

I /do see/ a ~System.Numerics.Vectors~ package.  Maybe not quite the right
version?  Trying to change the version in the packages.config does not work, nor
does changing it in the (bloody XML!) csproj.

I'm puzzled.

And yet, surprised that it went that far.

* [2016-08-23 mar.]
** More on that C# error
#+BEGIN_EXAMPLE
> strings packages/System.Numerics.Vectors.4.1.1/lib/net46/System.Numerics.Vectors.dll
  | grep Vector4
Vector4
#+END_EXAMPLE

There is a trace of ~Vector4~ in the package.  Not sure if it's the class
needed, but maybe it's not loading the right thing?

In the sources I built dotnet with, I can find the class:

#+BEGIN_EXAMPLE
> find . -name 'Vector4.cs'
./src/corefx-1.0.0/src/System.Numerics.Vectors/src/System/Numerics/Vector4.cs
#+END_EXAMPLE

When calling ~msbuild.exe~, we can actually see the included libraries.  And
here is the relevant excerpt:

#+BEGIN_EXAMPLE
-reference:/usr/lib/mono/4.5/System.Numerics.dll
-reference:/tmp/shader-study/packages/System.Numerics.Vectors.4.1.1/lib/net46/System.Numerics.Vectors.dll
#+END_EXAMPLE

It loads ~System.Numerics~ from mono first, which is 4.5.  And then
~System.Numerics.Vectors~ from the local package.  But [[https://msdn.microsoft.com/en-us/library/dn877639(v=vs.110).aspx][MSDN lists]] ~Vector4~ as
"available since 4.6".

Now, it seems that whatever is defined in ~Vector4.cs~ from corefx is not what's
known as ~System.Numerics.Vector4~ in 4.6.

But crucially, it means that even though the .NET runtime was open sourced, it
still relies on Mono, the free implementation.  And Mono is lagging behind on
versions.  What's the point?
* [2016-08-26 ven.]
** More tries at let-alist                                         :flycheck:
Ronan gave me a couple of tips that may help.

- https://www.reddit.com/r/emacs/comments/2u5uzq/i_wrote_a_somewhat_useful_elisp_macro/
- http://www.greghendershott.com/fear-of-macros/

*** Can ~eval~ help?
The [[https://www.reddit.com/r/emacs/comments/2u5uzq/i_wrote_a_somewhat_useful_elisp_macro/][first link]] highlights the use of ~eval~ around a macro call.

#+BEGIN_SRC elisp
(cl-prettyexpand
 '(let-alist '((a . 1) (b . 2))
  .a
  (let-alist '((a . 2) (c . 3))
    .c)))

(let ((alist '((a . 1) (b . 2))))
  (let ((\.a (cdr (assq 'a alist)))
        (\.c (cdr (assq 'c alist))))
    \.a
    (let ((alist '((a . 2) (c . 3))))
      (let ((\.c (cdr (assq 'c alist))))
        \.c))))


;; Trying to add `eval' to force evaluation of the inner let-alist.
(cl-prettyexpand
 '(let-alist '((a . 1) (b . 2))
    .a
    (eval '(let-alist '((a . 2) (c . 3))
             .c))))

(let ((alist '((a . 1) (b . 2))))
  (let ((\.a (cdr (assq 'a alist)))
        (\.c (cdr (assq 'c alist))))
    \.a
    (eval '(let-alist (quote ((a . 2) (c . 3))) \.c))))


;; Okay, maybe with backquotes?
(cl-prettyexpand
 '(let-alist '((a . 1) (b . 2))
    .a
    (eval `(let-alist '((a . 2) (c . 3))
             .c))))

(let ((alist '((a . 1) (b . 2))))
  (let ((\.a (cdr (assq 'a alist)))
        (\.c (cdr (assq 'c alist))))
    \.a
    (eval '(let-alist (quote ((a . 2) (c . 3))) \.c))))


;; Nah, backquotes are like quotes when there are no commas
#+END_SRC

So ~eval~ does not actually force the evaluation of the inner let-alist, but
rather delays the macro-expansion.  That's not what I want here.

*** Fixing let-alist
Failed to mention last time that I spent hours trying to come up with a correct
macro to do what let-alist does.

One fix that worked was to prevent ~let-alist--deep-dot-search~ from expanding
dot symbols ('.a.b') inside another ~let-alist~.  Actually, I even made it to
stop searching when a supplied predicate function would return true on the
current node.

(Which could have been made more generally into a tree recursing function
operating on a predicate, like ~-tree-map-nodes~ from dash)

So the first ~let~ did not generate unused bindings.  But we could still not
access outer let-alist bindings, because if you look at this expansion:

#+BEGIN_SRC elisp
(cl-prettyexpand
 '(let-alist '((a . 1) (b . 2))
   (let-alist '((a . 2) (c . 3))
    .b)))

(let ((alist '((a . 1) (b . 2))))
  (let ((\.b (cdr (assq 'b alist))))
    (let ((alist '((a . 2) (c . 3))))
      (let ((\.b (cdr (assq 'b alist))))
        \.b))))
#+END_SRC

The second let will always bind all dotted symbols under it, shadowing the outer
bindings.  Even though 'b' is not a key in the inner alist, it still tries to
get that key.

Now, let-alist supports looking up deeply into nested alists:

#+BEGIN_SRC elisp
(let-alist '((a . 1) (b . ((a . 2) (b . 3))))
    .b.a)
#+END_SRC

#+RESULTS:
: 2

But in our case the JSON objects has arrays, so that's why we need a second
let-alist call.

I tried to define a macro, ~alist-let~ that would have worked like so:

#+BEGIN_SRC elisp
(alist-let (a. '((a . 1) (b . 2)))
   (a. 'a))
;; => 1
#+END_SRC

The plan was for that to expand to:

#+BEGIN_SRC elisp
(let ((alist-a '((a . 1) (b . 2))))
  (cl-macrolet  ((a. (field) `(cdr (assq ,field alist-a))))
    (a. 'a)))
#+END_SRC

which in turn would expand to:

#+BEGIN_SRC elisp
(let ((alist-a '((a . 1) (b . 2))))
   (cdr (assq 'a alist-a)))
#+END_SRC

But since ~alist-let~ was a macro that invoked ~cl-macrolet~, I never got it to
work correctly.  The tricky part was to pass ~alist-a~ to ~cl-macrolet~ even
though the binding inside ~cl-macrolet~ is inside a backquote.

Maybe I should have used two macros?

Also, it's not zero-cost still, since all calls to ~a.~ would expand to ~cdr
assq~.  With ~let-alist~, the looking up is done once in a surround ~let~.

So the expansion of ~alist-let~ that you want is:

#+BEGIN_SRC elisp
(let* ((alist-a '((a . 1) (b . 2)))
       (alist-a-0 (cdr (assq 'a alist-a))))
   alist-a-0)
#+END_SRC

*** Gensym trouble
Version 1 of my ~alist-let~ macro:

#+BEGIN_SRC elisp
(defmacro alist-let (getter alist &rest body)
  (declare (indent 2))
  `(let ((alist-a ,alist))
     (cl-macrolet ((,getter (field) `(cdr (assq ,field alist-a))))
       ,@body)))

(cl-prettyexpand
 '(alist-let a. '((a . 1) (b . 2))
    (a. 'a)))

(let ((alist-a '((a . 1) (b . 2))))
  (progn
    (cdr (assq 'a alist-a))))
#+END_SRC

Works, but ~alist-a~ is not hygienic:

#+BEGIN_SRC elisp
(defmacro alist-let (getter alist &rest body)
  (declare (indent 2))
  `(let ((alist-a ,alist))
     (cl-macrolet ((,getter (field) `(cdr (assq ,field alist-a))))
       ,@body)))

(alist-let a. '((a . 1) (b . 2))
  alist-a)
#+END_SRC

#+RESULTS:
: ((a . 1) (b . 2))

So you want to generate a symbol to use instead of ~alist-a~:

#+BEGIN_SRC elisp
(defmacro alist-let (getter alist &rest body)
  (declare (indent 2))
  (let ((alist-a (gensym)))
    `(let ((,alist-a ,alist))
       (cl-macrolet ((,getter (field) `(cdr (assq ,field ,alist-a))))
         ,@body))))
#+END_SRC

Now, as I understand it, ~alist-a~ is a symbol that's generated at expansion
time by ~gensym~.  The macro expands to the same let as before, except now the
binding ~alist-a~ is variable, that's why there is a comma in front.  Inside
~cl-macrolet~, ~alist-a~ must also refer to the generated symbol, hence the
comma.

The problem is that the expansion of ~cl-macrolet~ fails to find ~alist-a~.

We can check that binding the gensym at expansion works:

#+BEGIN_SRC elisp
(defmacro alist-let (getter alist &rest body)
  (declare (indent 2))
  (let ((alist-a (gensym)))
    `(let ((,alist-a ,alist))
         ,@body)))

(cl-prettyexpand
 '(alist-let a. '((a . 1) (b . 2))
    (a. 'a)))

(let ((G23147 '((a . 1) (b . 2))))
  (a\. 'a))
#+END_SRC

Using ~pp-macroexpand~, we can see that indeed after expanding ~alist-let~, but
not ~cl-macrolet~, we get:

#+BEGIN_SRC elisp
(pp-macroexpand-expression
 '(alist-let a. '((a . 1) (b . 2))
    (a. 'a)))

(let ((G23158 '((a . 1) (b . 2))))
  (cl-macrolet
      ((a\. (field) `(cdr (assq ,field ,alist-a))))
    (a\. 'a)))
#+END_SRC

~alist-a~ is not expanded, and the binding is lost.  So that's why it fails.

Is it because of the second backquote?

#+BEGIN_SRC elisp
(defmacro test ()
  (let ((var "somethin"))
    `(,var `(,var))))

(cl-prettyexpand
 '(test))

("somethin" (list var))
#+END_SRC

#+BEGIN_SRC elisp
(defmacro test ()
  (let ((var "somethin"))
    `(,var (,var))))

(cl-prettyexpand
 '(test))
("somethin" ("somethin"))
#+END_SRC

Ah, indeed.

Another way to see why it's wrong is to look at the line of the macrolet:

: (cl-macrolet ((,getter (field) `(cdr (assq ,field ,alist-a))))

See, both ~field~ and ~alist-a~ have a comma in front.  But clearly, we want
~alist-a~ to be expanded when ~alist-let~ expands, and ~field~ to be expanded
only when the macrolet ~getter~ expands.

So what if we build the binding form of ~cl-macrolet~ beforehand?

#+BEGIN_SRC elisp
(defmacro alist-let (getter alist &rest body)
  (declare (indent 2))
  (let* ((alist-a (gensym))
         (str (read (format "`(cdr (assq ,field %s))" alist-a))))
    `(let ((,alist-a ,alist))
       (cl-macrolet ((,getter (field) ,str))
         ,@body))))

(cl-prettyexpand
 '(alist-let a. '((a . 1) (b . 2))
    (a. 'a)))

(let ((G23159 '((a . 1) (b . 2))))
  (progn
    (cdr (assq 'a G23159))))
#+END_SRC

Ah!  It works.  Gosh.  I spent hours trying to workaround that, and even tried
the string route with ~eval~.  I was so tired that I did not bother taking notes
as I went along, but taking notes would have forced me to work out what was
wrong in the approach.

Anyway, there is still the downside of not saving all these lookups into a let.

But elisp has one last surprise in store for me!  When I try to nest ~alist-let~
calls:

#+BEGIN_SRC elisp
(alist-let a. '((a . 1) (b . 2))
  (alist-let b. '((c . 3) (d . 4))
    (b. 'c)))
;; => Symbol's value as a variable is void: G23170
#+END_SRC

Damned!  How does the expansion looks like?

#+BEGIN_SRC elisp
(cl-prettyexpand
'(alist-let a. '((a . 1) (b . 2))
  (alist-let b. '((c . 3) (d . 4))
   (b. 'c))))

(let ((G23198 '((a . 1) (b . 2))))
  (progn
    (let ((G23199 '((c . 3) (d . 4))))
      (progn
        (cdr (assq 'c G23199))))))
#+END_SRC

#+RESULTS:
: 3

Wait, it works?  What the hell?  Expansion works, but not evaluation?

Actually, it also fails without nesting:

#+BEGIN_SRC elisp
(defmacro alist-let (getter alist &rest body)
  (declare (indent 2))
  (let* ((alist-a (gensym))
         (str (read (format "`(cdr (assq ,field %s))" alist-a))))
    `(let ((,alist-a ,alist))
       (cl-macrolet ((,getter (field) ,str))
         ,@body))))

(alist-let a. '((a . 1) (b . 2))
  (a. 'b))
;; => Symbol's value as a variable is void: G23199
#+END_SRC

Now, a clue might be that even a simple ~macroexpand~ also fails:

#+BEGIN_SRC elisp
(macroexpand
 (alist-let a. '((a . 1) (b . 2))
     (a. 'b)))
;; => Symbol's value as a variable is void: G23200
#+END_SRC

Whereas ~cl-prettyexpand~ does not.  I've read somewhere that CommonLisp has
different macro expansion semantics than Elisp.  The ~cl-~ prefix stands for
CommonLisp.  Coincidence?

Well, macrostep-mode seems to agree with me:

#+BEGIN_SRC elisp
(let
    ((G24180 '((a . 1) (b . 2))))
  (cl-macrolet
      ((a\. (field) `(cdr (assq ,field G24180))))
    (a\. 'b)))
#+END_SRC

then:

#+BEGIN_SRC lisp
(let
    ((G24180 '((a . 1) (b . 2))))
  (progn
    (cdr (assq 'b G24180))))
#+END_SRC

So if the expansion under CommonLisp rules is not the same as under the Elisp
rules, I get a working expression but evaluating the expression without
expanding it first fails.  Still, it's weird that macrostep concurs with
~cl-prettyexpand~ then.

But the debugger reveals that is not the correct explanation.  If I 'C-x C-e'
the expression:

#+BEGIN_SRC elisp
(alist-let a. '((a . 1) (b . 2))
  (a. 'b))
#+END_SRC

Here is what the debugger says:

#+BEGIN_SRC elisp
Debugger entered--Lisp error: (void-variable G56132)
  (assq (quote b) G56132)
  (cdr (assq (quote b) G56132))
  (progn (cdr (assq (quote b) G56132)))
  (let ((G56132 (quote ((a . 1) (b . 2))))) (progn (cdr (assq (quote b) G56132))))
  eval((let ((G56132 (quote ((a . 1) (b . 2))))) (progn (cdr (assq (quote b) G56132)))) nil)
#+END_SRC

So actually, the debugger sees exactly what ~cl-prettyexpand~ gives me.  But for
some reason, it claims to fail evaluating that?

If I execute myself:

#+BEGIN_SRC elisp
(let ((G56132 (quote ((a . 1) (b . 2))))) (progn (cdr (assq (quote b) G56132))))
#+END_SRC

#+RESULTS:
: 2

It works.  Grumble.

I think I need to consult an expert.

Trying one more thing.  I read on the emacs-devel thread announcing ~let-alist~
that ~make-symbol~ is to be preferred to ~gensym~.  Don't know why.  Does it
make a difference here?

#+BEGIN_SRC elisp
(defmacro alist-let (getter alist &rest body)
  (declare (indent 2))
  (let* ((alist-a (make-symbol "alist"))
         (str (read (format "`(cdr (assq ,field %s))" alist-a))))
    `(let ((,alist-a ,alist))
       (cl-macrolet ((,getter (field) ,str))
         ,@body))))

(cl-prettyexpand
 '(alist-let a. '((a . 1) (b . 2))
   (a. 'b)))

(let ((alist '((a . 1) (b . 2))))
  (progn
    (cdr (assq 'b alist))))


(alist-let a. '((a . 1) (b . 2))
           (a. 'b))
;; => Error
#+END_SRC

Nope.

I want to get to the bottom of this.  Let's make a minimal test case.

This still fails, but executing the expansion does not:

#+BEGIN_SRC elisp
(defmacro test-gensym ()
  (let* ((sym (gensym))
         (sexp (read (format "%s" sym))))
    `(let ((,sym 12))
       ,sexp)))

(cl-prettyexpand
 '(test-gensym))

(let ((G57457 12))
  G57457) ; => 12

(test-gensym) ; => Error
#+END_SRC

While the very similar:

#+BEGIN_SRC elisp
(defmacro test-gensym ()
  (let* ((sym (gensym))
         (sexp `,sym))
    `(let ((,sym 12))
       ,sexp)))
#+END_SRC

works.

So I'm assuming that reading a symbol makes it different somehow?

#+BEGIN_SRC elisp
(let (sym (gensym))
  (eq sym `,sym)) ; => t

(let (sym (gensym))
  (eq sym (read (format "%s" sym)))) ; => t
#+END_SRC

Nope.  Weird.

Still:

#+BEGIN_SRC elisp
(defmacro test-gensym ()
  (let* ((sym (gensym))
         (read-sym (read (format "%s" sym))))
    `(let ((,sym 42))
       ,sym)))

(cl-prettyexpand
 '(test-gensym))

(let ((G57812 42))
  G57812) ; => 42

(test-gensym) ; => 42
#+END_SRC

Reading about gensym in the manual, I find a related gentemp that creates an
interned symbol.  With gentemp, it works:

#+BEGIN_SRC elisp
(defmacro test-gensym ()
  (let* ((sym (gentemp))
         (read-sym (read (format "%s" sym))))
    `(let ((,sym 42))
       ,read-sym)))

(test-gensym) ; => 42
#+END_SRC

Does interning means we can still have name clashes?  If I know G57833 to be the
next generated symbol?

#+BEGIN_SRC elisp
(defmacro test-gensym (&rest body)
  (let* ((sym (gentemp)))
    `(let ((,sym 42))
       ,@body)))

(test-gensym G57833) ; => error G57833 not found
#+END_SRC

Hmm.  Actually, gentemp keeps increasing when the symbol exists.  So it's
guaranteed to be fresh.

Does this mean...?

#+BEGIN_SRC elisp :results verbatim
(defmacro alist-let (getter alist &rest body)
  (declare (indent 2))
  (let* ((alist-name (gentemp))
         (str (read (format "`(cdr (assq ,field %s))" alist-name))))
    `(let ((,alist-name ,alist))
       (cl-macrolet ((,getter (field) ,str))
         ,@body))))

(alist-let a. '((a . 1) (b . 2))
  (alist-let b. '((c . 3) (d . 4))
    (list (a. 'a) (b. 'c))))
#+END_SRC

#+RESULTS:
: (1 3)

Yes!  YES!

So it:
- provides a shortcut for getting values out of alists
- can be nested
- is hygienic

The only downside is that each call to ~(a. 'a)~ expands to ~(cdr (assq~, which
maybe you want to avoid.  But, the good news is, if you want to save the result,
you can do it YOURSELF:

#+BEGIN_SRC elisp :results verbatim
(defmacro alist-let (getter alist &rest body)
  (declare (indent 2))
  (let* ((alist-name (gentemp))
         (str (read (format "`(cdr (assq ,field %s))" alist-name))))
    `(let ((,alist-name ,alist))
       (cl-macrolet ((,getter (field) ,str))
         ,@body))))

(cl-prettyexpand
'(alist-let a. '((a . 1) (b . 2))
  (alist-let b. '((c . 3) (d . 4))
    (let ((val (a. 'a)))
     (list val val (b. 'c))))))

(let ((G57854 '((a . 1) (b . 2))))
  (progn
    (let ((G57855 '((c . 3) (d . 4))))
      (progn
        (let ((val (cdr (assq 'a G57854))))
          (list val val (cdr (assq 'c G57855))))))))
#+END_SRC

#+RESULTS:
(1 1 3)

Considering that to have results auto-memoize you would need to do a tree
recursion when macro expanding... which led to one of the (fixable) issue with
~let-alist~... I'd say it's not worth it.  I prefer to be explicit anyway.

*** Another alternative to let-alist
The [[http://www.greghendershott.com/fear-of-macros/pattern-matching.html#%2528part._hash..refs%2529][second link]] Ronan gave me was about a Racket macro with a very similar goal.
Given a parsed JSON 'js' (in Racket, these are parsed to hashmaps), we can get a
value out of it using dot notation:

: (hash.refs js.a.b.c)

which is just syntactic sugar for:

: (hash-refs js '(a b c))

which is just a function.

Maybe following this route would be easier for an alternative to ~let-alist~
work.  But you really want a zero-cost abstraction, so using a macro to provide
syntactic sugar for a function call is a no go.  You need to generate the code
for lookups at compile time.

*** Destructuring using dash
Ronan also found that there is alist destructuring in the latest dash (2.13).

#+BEGIN_SRC elisp
(-let [(&alist 'a a) '((a . 1) (b . 2))]
  a)
#+END_SRC

#+RESULTS:
: 1

And to get values from nested alists:

#+BEGIN_SRC elisp
(-let [(&alist
        'a a
        'c (&alist 'ca ca))
       '((a . 1) (b . 2) (c . ((ca . 3))))]
  ca)
#+END_SRC

#+RESULTS:
: 3

So this would definitely work.  You just have to destructure in advance.

*** Silence the warnings
Otherwise, since the issue is that nested ~let-alist~ calls issue a warning when
byte-compiling, but the expanded code is actually harmless, why not just silence
the warnings?  ~with-no-warnings~ silence warnings in its body.  The problem is
it disables /all/ warnings, and not just the unused variables.

* [2016-08-28 dim.]
** Compiling chipers on Windows                                     :chipers:
Following the instructions on rust-lang, `cargo update` to update the
dependencies, and it failed to build in my code.

Turns out imgui updated to use glium 0.15 now, and I was using 0.14, which
caused hairy "unsatisfied trait bound" errors since we weren't targeting the
same code... sigh.

Anyway, after that and a trivial arguments update, it built.

** Compiling rust windows binaries from linux
Can I cross-compile easily?

[[https://github.com/rust-lang-nursery/rustup.rs#cross-compilation][Let's see]].

: rustup target add x86_64-pc-windows-msvc
: rustup run stable cargo build --release --target=x86_64-pc-windows-msvc

Argh, an error because std was not compiled with the correct version.  Hmm, this
looks like a deep rabbit hole I don't want to go into right now.  Here is [[#+BEGIN_EXAMPLE][a
guide]] for the moment.

* [2016-08-29 lun.]
** Low-resolution rendering in OpenGL
To achieve a more low-tech look.  [[https://stackoverflow.com/questions/7071090/low-resolution-in-opengl-to-mimic-older-games][This SO answer]] seems to be it.  Just have to
find out how to do the same thing in glium.

* [2016-08-31 mer.]
** Reading up on how modern (>1) OpenGL works
My knowledge of OpenGL is largely based on direct mode.  Pre-shaders.

The r/opengl subreddit has a few links to get started.

Here is [[http://duriansoftware.com/joe/An-intro-to-modern-OpenGL.-Table-of-Contents.html][the one]] I'm reading right now.

It confirms that framebuffer objects are just target to render to.  I could
render to several different FBOs without directly rendering to the screen.
But how to render an FBO to the screen?  By using it as texture and drawing it
on a quad?

Also, I did not understand how to combine shaders or do "multiple pass" of
rendering in chipers.  I just baked two fragment shaders in one.  But it seems
we can actually have multiple draw calls, with potentially different programs
(hence, different shaders, or even buffer objects).  How do the multiple draw
calls compose however?

* [2016-09-03 sam.]
** Experimenting with multiple draw calls                     :spacebangbang:
So if I understand the pipeline correctly, a single Frame.draw call takes a
vertex buffer and a shader program.  I get that a vertex shader will only work
with the vertices from the vertex buffer.  Presumably, if the vertex buffer has
4 vertices, there will be 4 instances of the vertex shader running in parallel
to produce a ~gl_Position~.  Then, using the index buffer, it constructs
triangles, rasterizes them, and now the fragment shader is called for every
pixel in these triangles.

We can use a fragment shader like this to show that is the case:

: color = vec4(gl_FragCoord.x / 2000, gl_FragCoord.y / 2000, 0.0, 1.0);

every pixel of the triangle has a different color, depending on its position on
the screen.

** Tools for browsing documentation locally
Discovered [[https://zealdocs.org/download.html][Zeal]] to browse documentation à la Devdocs, but Devdocs did not have
OpenGL documentation :(

Zeal actually uses the same documentation format than Dash.  There are plenty of
frontends to read these formats.  I tried a terminal-based one (dasht), did not
get anything inside the terminal when looking for ~gl_FragCoord~, and the
browser opening did not work either.  I was enthusiast for the Helm-based one,
but only the search works correctly from inside Emacs, the viewing should happen
in the browser (using eww does not work for XML file apparently).  Zeal is a
dedicated GUI for local docs, and it's fast.  Good enough.

** A potential rotation bug                                   :spacebangbang:
By keeping the current heading in a float, we can potentially grow to very large
value by holding one direction, and then hitting float inaccuracies.

Testing, after 2^20 you cannot turn left anymore.  Admittedly, you would take a
rather long time to get there, but hey.  Still incorrect.

Using a small integer that wraps around you are guaranteed to avoid rounding
errors.

** Vsync on my machine                                        :spacebangbang:
Ah!  I did not enable vsync in the application, but I still obviously got
60fps.  Adding the frame period histogram confirmed it.

So I double-check my nvidia settings to confirm I had disabled vsync, yes I did.
But hey, after quitting the nvidia settings application, now when I launch my
glium window vsync is indeed off (avg frame period: 0.2 ms, nice).

So on my machine somehow my nvidia settings are not taken into account until I
launch the application once.

Still, better enable vsync for this application until I make the logic
independent of frame rate.

** Low-resolution render on framebuffer                       :spacebangbang:
So that's what I had in mind [[*Low-resolution rendering in OpenGL][the other day]].  A low-resolution effect.  Now that
I understand how this ties together a bit better, I can explain how it works.

Instead of rendering directly to the framebuffer that is presented to the
screen, we draw the scene to a framebuffer object of a lower resolution.  The
framebuffer tied to the screen has as many pixels as the window contains, but
the framebuffer object has the resolution we want.  Creating a framebuffer that
renders to a texture is rather simple in Glium:

: SimpleFrameBuffer::new(&display, &texture);

Of course we need a texture, so I reused the code from chipers:

#+BEGIN_EXAMPLE
  let texture = Texture2d::empty_with_format(&display,
                                             UncompressedFloatFormat::U8,
                                             MipmapsOption::NoMipmap,
                                             256, 256).unwrap();
#+END_EXAMPLE

Here we draw on a 256*256 virtual screen, the same resolution as the original
Macintosh.

Then it's just a matter of drawing the ship on this virtual framebuffer, then
drawing the texture on a quad to the screen framebuffer.

Of course we need different shaders for the quad, a vertex buffer, index
buffer...  It's a bit verbose, but it works!

Hmm... why is the ship red?  Shouldn't it be white?

Ah, it's the ~UncompressedFloatFormat::U8~: it stores only the first color
component, which is red.  I used a single u8 for chipers because the texture
there as a boolean: either the pixel is on, or it is off.  Switching to an
U8U8U8U8 fixes the redness.

** TODO make simulation independent of frame rate             :spacebangbang:
** DONE import ship model from Blender                        :spacebangbang:
CLOSED: [2016-09-11 dim. 15:10]

* [2016-09-04 dim.]
*** DONE Maintain aspect ratio                                :spacebangbang:
CLOSED: [2016-09-04 dim. 15:33]
I always have trouble will all these matrix multiplications that pile onto each
other.  Anyway, the strategy here has two part:

First, we adjust the model coordinates for the aspect ratio of the virtual
framebuffer.  The intent is that, regardless of the dimensions of the
framebuffer, the ship is always the same size/shape.

But that's not all, because when drawing the framebuffer to the quad, the quad
is still stretched out to fill the window.  So there also we have to stretch the
quad so that it fills the window, while maintaining its aspect ratio.  And
that's another matrix multiplication.

*** DONE Add tweakable gameplay values to GUI                 :spacebangbang:
CLOSED: [2016-09-04 dim. 16:43]

* [2016-09-05 lun.]
** Making a note of a nice way to deal with opcodes in Rust             :gbs:
As done in [[https://github.com/yupferris/rustendo64/blob/master/src/n64/cpu/opcode.rs][Rustendo]], a Nintendo 64 emulator in Rust.  Opcodes are transformed
into an enum:

#+BEGIN_SRC rust
pub enum Opcode {
        Special = 0b000000,
        RegImm =  0b000001,

        Addi =    0b001000,
Addiu = 0b001001,
#+END_SRC

so the code that executes these opcodes can match on enum variants, rather than
binary:

#+BEGIN_SRC rust
match instr.opcode() {
  RegImm =>
  Addi =>
  Addiu =>
#+END_SRC

I'm sure this emulator has other Rust tricks as well.  Good source.

* [2016-09-22 jeu.]
** Trying to use the ~keyboard-layout~ layer of spacemacs             :emacs:
As suggested by [[https://github.com/syl20bnr/spacemacs/issues/6631][issue 6631]].

I tried to add a simple Colemak substitution, JKHL instead of HJKL.  It works
for the normal evil mode and Helm, but for some reason not in magit.  Actually
the code for magit does not look up to date, since there is no
~evil-magit-map~.  Also, it's macros all the way down, and there are no
docstrings :(

** Finding the keymap where a key is bound                            :emacs:
~describe-key~ seems to take care of it.

* [2016-09-23 ven.]
** Diving into a smartparens bug for rust-mode                  :smartparens:
Namely [[https://github.com/Fuco1/smartparens/issues/642][issue 642]].

Maybe this line?

: (sp--do-action-p (sp-get active-sexp :op) 'autoskip)

Instrumenting the function with edebug, when I insert the closing bracket ">", I
would expect this expression to be ~t~, but it's nil.

Can I change the return value of something in Edebug?  Hmm looks like I can only
inspect.

Well, returning ~t~ here indeed fixes the issue.  So why doesn't
~sp--do-action-p~ return ~t~ here?

Okay it seems that the fault lies with the predicate that determines whether we
should consider the character as a pair, ~sp-rust-could-be-parameterized~:

#+BEGIN_SRC elisp
(defun sp-rust-could-be-parameterized (&rest args)
  "Return t if we could add a <T> in this position.
If nil, the user is probably using < for something else."
  (and (apply #'sp-in-code-p args)
       (looking-back (rx (or letter (seq letter "<") (seq letter "::<"))))))
#+END_SRC

Hmm, ~rx~ is a macro to make readable regexps.  Yeah, another DSL!

Okay so if I read that correctly,

: (rx (or letter (seq letter "<") (seq letter "::<"))))))

this corresponds to the following cases:

: letter -> A|
: seq letter "<" -> A<|
: seq letter "::<" -> A::<|

In all these cases, when the cursor at | inserts an opening bracket "<", this
will insert a closing bracket ">".

But!  The same predicate is also used for auto-skipping the closing bracket, and
in that case the regexp fails.

Hmm wait, actually the first case will match:

: <T|>

there's a letter, 'T'.

So what's happening?

Ah! That's because autoskip let the user input the closing bracket, then try to
determine if it should remove it, thus auto-skipping transparently for the user.
But when testing for removal, this is the current code:

: <T>|>

and there are no regexp cases that match.

One way to fix that is to add a ">" case to the regexp.

** Writing an ERT test for this smartparens bug                 :smartparens:
Okay, now that it's fixed, it might be good idea to leave a test there to ensure
this does not pop up again.

Hmm running `make test` fails because of ruby tests... not my problem.  How do I
run only rust tests?

: cake exec ert-runner -p rust

Great.  Now, reading the existing tests, this looks pretty straightforward.
Done.

* [2016-09-26 lun.]
** A Github burndown chart                                         :burndown:
Motivated by answering a simple question: how is a project catching up with its
maintenance load?  Specifically, I always see that Spacemacs has >1000 open
issues and that scares me a bit.

Github has a [[https://github.com/syl20bnr/spacemacs/pulse][pulse page]] that shows how many pull requests were created/merged
in the last day/week/month.  Same for number of closed issues versus new ones.

That's one data point for the burndown chart.  But it's not the whole picture,
since you only see as far as one month back.  Also, you can't see the four weeks
of the month separately without to see the trends.

So at the very least I would like to see: how many issues were created and
closed in any given week from the birth of the project.  Same with PR.  I see
that PR are issues in the Github API, so I don't even have to duplicate the work
here!

For that, I just need to get the list of issues, their creation date and closed
date.

Do I need authentication to the Github API?  Spacemacs has 7200 total issues/PR.
We can get a max of 100 issues per call, so 72 calls to get everything, but the
rate limit is 60 calls per hour.  So I think I need an access.

Okay so I just need to get a personal authorization token from the settings
page.  Then I can pass it as a header to the request like so:

: curl -H "Authorization: token 1234..." -I https://api.github.com/users/fmdkdd

: X-RateLimit-Limit: 5000
: X-RateLimit-Remaining: 4999

That should be enough.

Also, I should include my username as user agent as [[https://developer.github.com/v3/#rate-limiting][per the docs]].

So I need something to get these numbers from a given repository.  That involves
going through each page of results and extracting the info I need.  And probably
do some caching to avoid hammering the Github API.

Then I need to do a visualization using these results.  Leaning towards D3.

Okay as a proof of concept I got all the issues for Spacemacs as a JSON file.
Now I can try a D3 visual.

Hmm D3 has finally landed v4, does that change anything important?  Well OK,
according to [[https://medium.com/@mbostock/what-makes-software-good-943557f8a488#.494ksjbbg][this post]], I only need to be aware of selection.merge.

I think I need to massage the data a bit.  I want to draw two areas: one for the
total number of open issues as a function of time, and another for the total
number of closed issues through time as well.  So, I need to sort the array by
creation date, go through each issue and emit a point for this date with the
total number of open and closed issues at this date.

* [2016-09-27 mar.]
** Trying to extract text from a bunch of game screenshots
Apparently [[https://github.com/tesseract-ocr/tesseract][Tesseract]] is good.

It automatically does image treatment, meaning I don't have to fiddle with gimp.
I mostly need to crop, and since this is always the same area, this can be done
with imagemagick in one fell swoop.

One issue though is that the screenshots are quite low-res, especially on the
text.  Tesseract seems more used to 300 dpi texts (paper scans).

The output is okay, but there are characters like 'j' it has trouble with.
Also, the text in the screenshot has a low line-height, so it occasionally
misses diacritics or capitals.

One thing to try is to train it on the specific font used.  Apparently, this
game uses Arial Narrow.

Okay, training was not very successful.  Maybe if I add a word list?  Hmm,
extracting data from the fra set was only slightly better.  But using the fra
set directly yields the best results.

Page segmentation method 6 seems to yield the best results as well.  Now I will
try to find how to best massage the original image.

Cropping + scaling with cubic interpolation to 400% seems good enough.

Using ImageMagick, the Catmull-Rom interpolation has better contrast.  Toying
with image size now.  Interestingly, smaller images are not always faster to
process by tesseract.  I'm assuming because Leptonica has a harder time finding
a good threshold value.  However, larger images will not automatically result in
better OCR recognition.

400% and 600% are both quite accurate.

However, I failed to filter out specific lines based on their text colors.  I
think I would need more control over the image, maybe by using OpenCV or
assorted tools.

** Going back to the burndown chart                                :burndown:
Outputting an SVG circle for every (7192) issue is clearly not the right way to
go about it.  I wanted to use SVG paths.  d3.area handles that nicely; I just
had to find an example with the updated v4 syntax.

Also, adding axes is a breeze.

Now, I guess I could add a text input for the repo name it could be a website on
its own.  But I would need to add caching for the results in the backend.

Meaning, I need to host the backend somewhere.  But I don't want to pay for a
server.  Are there any free hosting for apps anymore?

The graphs are interesting to look at.  You can clearly see Spacemacs is doomed
if the current trend is maintained.  A high number of open issues may just
indicate activity, but if the number of open issues keeps growing, you might
call that maintenance bankruptcy.

I mean, I just ran the same viz on flycheck, and there you can see a trend of
unclosed issues picking up early 2016, but reversing around july.  Also, the
number of open issues never went above 60.

Oh yes!  I also need to maybe separate issues and pull requests.  Same graphs,
but different colors.

* [2016-09-28 mer.]
** Finding a host provider for burndown chart                      :burndown:
Hmm, seems Heroku is not as gracious as it once was.  Can't seem to find a
decent free service for small applications that are not also utterly useless.

I can't splurge for a 4€/month commitment, especially for small demo.
Otherwise, hetzner.de looks good.  Or OVH has a very nice VPS at 3.6€/month.

But first things first, adding local caching.  I suppose the nodeJS part could
act as a simple fetcher of issue data for a given repo.  Given the user and repo
names, it would fetch all issue data since the latest sync, and merge that into
a DB.

Then this DB can be queried directly by the D3 page to generate the graphs.

Ultimately, the page will be the one to initiate the sync.

Also, why use a DB, when I can use perfectly reasonable JSON files?

** Caching version done                                            :burndown:
I've now got a nice little tool that fetches issues from Github and saves them
to a file.  When the file already exists, it only gets the newest issues.

I found a good argument for a DB: for dealing with lock and concurrent accesses
to a file.  Clearly, I've thought of the program as a command-line tool, not as
a web server.

Well, I prefer the CLI approach anyway.  I guess that means I don't need all
these callbacks.  Sync all the things!

Well, actually, since I need to deal with the errors anyway, I prefer handling
them as callbacks than exceptions.  This way the code stays asynchronous if need
be.  Although I will try to see if promises would make it nicer.

** Using promises                                                  :burndown:
Okaaaay.  Using promises was not straightforward.  I clearly don't grasp the
idioms yet.  I might need to implement the Promises/A+ or look at an
implementation to understand what's going on.

But I managed to make it work.  Is the resulting code clearer?  It got rid of
~if (err) bail~ calls, and now all errors are caught in one place, which is a
plus.  It does make the control flow a bit awkward, with ~P.join~ in one place.
But maybe there's a better way to write it.

** Making an app                                                   :burndown:
So now the good thing would be to add a text input to the web page, and fetch
the corresponding issues.  Or a file selector, and drag and drop.

* [2016-10-03 lun.]
** Fixing a bug with macro errors in the JSON parser for flycheck errors :flycheck:
Seems macro errors are not captured by the JSON parser actually.

See flycheck/flycheck-rust/issues/36.

With macro errors, like forgetting an argument to println:

: println!("{}")

the JSON output is pretty big, and contains multiple nested expansion errors,
like so:

#+BEGIN_EXAMPLE
{
  "message": "invalid reference to argument `0` (no arguments given)",
  "code": null,
  "level": "error",
  "spans": [
    {
      "file_name": "<std macros>",
      "is_primary": true,
      "text": [{
          "text": "( $ fmt : expr ) => ( print ! ( concat ! ( $ fmt , \"\\n\" ) ) ) ; (",
        }],
      "expansion": {
        "span": {
          "file_name": "<std macros>",
          "text": [{
              "text": "( $ fmt : expr ) => ( print ! ( concat ! ( $ fmt , \"\\n\" ) ) ) ; (",
            }],
          "expansion": {
            "span": {
              "file_name": "<std macros>",
              "text": [{
                  "text": "$ crate :: io :: _print ( format_args ! ( $ ( $ arg ) * ) ) ) ;",
                }],
              "expansion": {
                "span": {
                  "file_name": "<std macros>",
                  "text": [{
                      "text": "( $ fmt : expr ) => ( print ! ( concat ! ( $ fmt , \"\\n\" ) ) ) ; (",
                    }],
                  "expansion": {
                    "span": {
                      "file_name": "lib.rs",
                      "text": [{
                          "text": "    println!(\"{}\");",
                        }],
                      "expansion": null
                    },
                    "macro_decl_name": "println!",
                    "def_site_span": {
                      "file_name": "<std macros>",
                      "text": [{
                          "text": "( $ fmt : expr ) => ( print ! ( concat ! ( $ fmt , \"\\n\" ) ) ) ; (",
                        }, {
                          "text": "$ fmt : expr , $ ( $ arg : tt ) * ) => (",
                        }, {
                          "text": "print ! ( concat ! ( $ fmt , \"\\n\" ) , $ ( $ arg ) * ) ) ;",
                        }],
                      "expansion": null
                    }
                  }
                },
                "macro_decl_name": "print!",
                "def_site_span": {
                  "file_name": "<std macros>",
                  "text": [{
                      "text": "( $ ( $ arg : tt ) * ) => (",
                    }, {
                      "text": "$ crate :: io :: _print ( format_args ! ( $ ( $ arg ) * ) ) ) ;",
                    }
                  ],
                  "expansion": null
                }
              }
            },
            "macro_decl_name": "format_args!",
            "def_site_span": null
          }
        },
        "macro_decl_name": "concat!",
        "def_site_span": null
#+END_EXAMPLE

But most of it is tossed away in the pretty compiler output:

#+BEGIN_EXAMPLE
error: invalid reference to argument `0` (no arguments given)
 --> <std macros>:1:33
  |
1 | ( $ fmt : expr ) => ( print ! ( concat ! ( $ fmt , "\n" ) ) ) ; (
  |                                 ^^^^^^^^^^^^^^^^^^^^^^^^^
<std macros>:1:33: 1:58 note: in this expansion of concat!
<std macros>:2:27: 2:58 note: in this expansion of format_args!
<std macros>:1:23: 1:60 note: in this expansion of print! (defined in <std macros>)
lib.rs:6:5: 6:20 note: in this expansion of println! (defined in <std macros>)
#+END_EXAMPLE

So hmm, two things:

- ~file_name~ is not always a file name... it can be "<std macros>"; we should
  probably avoid creating flycheck-error objects for these

- a span can have an ~expansion~ field which can contain a span, which can
  contain an expansion...

So we should get all these spans, discard the ones originating in "<std macros>"
files, and produce flycheck-errors for the others.

Argh.  So I got a workaround up.  But macro errors basically use the JSON error
output differently.  They do not use "label" (a string) but "text" (an array of
objects, of which "text", which is a string).  The spans in expansions are not
primary but they actually contain the expansion failures in a form of stack
trace.

So when walking the JSON error recursively, we need to know if we are in an
"expansion span" or not, to know what to extract in each case.  Might be
worthwhile to write different parsing functions for these cases.

* [2016-10-04 mar.]
** Fixing the parsing bug for macro errors in flycheck (cont.)     :flycheck:
To simplify the logic, it might be best to collect the "causes" (filename,
line/column info) first, then build the flycheck error objects afterwards.

* [2016-10-06 jeu.]
** Revamping flycheck-rust                                         :flycheck:
The goal of flycheck-rust is to set the flycheck variables used by the rust and
rust-cargo checkers automatically.

That is, the flycheck checkers' job is to run a command (rustc, or cargo), to
generate errors, parse them, and then let flycheck handle presenting them to the
user.  Importantly, flycheck checks /files/, not /projects/.  Flycheck has no
knowledge of a project hierarchy.  When visiting a file, it determines which
checkers it should enable, and when they should run.  For rust, variables can be
used to tell flycheck whether ~rust~ or ~rust-cargo~ should be enabled, and
pieces of the command to run.

The job of flycheck-rust is to set these variables automatically, based on the
currently visited file.  And for that, we need, for each rust file, to determine
which variables to set, what values they should have, in order to communicate
with the checker.

There are two checkers, ~rust~ and ~rust-cargo~.  These are their predicates:

For rust:

#+BEGIN_SRC elisp
  :predicate (lambda ()
               (and (not flycheck-rust-crate-root) (flycheck-buffer-saved-p))))
#+END_SRC

it kicks in when the current buffer has no crate root set.  Implicitly, it means
that whenever we find a cargo file, we assume the rust-cargo checker is a better
fit.

The rust-cargo predicate is:

#+BEGIN_SRC elisp
  :predicate (lambda ()
               (and (flycheck-buffer-saved-p)
                    (locate-dominating-file (buffer-file-name) "Cargo.toml"))))
#+END_SRC

Curiously, they do not use the same variable.  So, amusingly, if you set
~flycheck-rust-crate-root~ to nil, you can actually enable both checkers at the
same time.

But with ~flycheck-rust~ enabled, the variable should be non-nil when the
Cargo.toml file is present, so they amount to the same.  Still, weird that we
lookup the file manually.

One complication in flycheck-rust is that there may be many different files, not
just source files but tests, examples, benchmarks...

See http://doc.crates.io/guide.html#project-layout and
http://doc.crates.io/manifest.html#the-project-layout

But I think ~cargo read-manifest~ should now cover all these cases.  Building a
test crate now.  Yeah, it seems read-manifest has us covered when it comes to
finding actual build targets.

There are some added subtleties when it comes to additional source files.  The
convention is that every files in ~src/~ will contribute to the library target
(that is, be included by ~src/lib.rs~ directly or recursively), and the binary
targets (either ~src/main.rs~ or files in ~src/bin~) will import the library.
Clearly, the binary files could also import support files that are not part of
the library, but then as these files are imported by a build target, they should
report build errors.

The same goes for support files used by examples, benches, or test targets.
However, we can imagine dropping a rust file that is not imported by any
target.  This is unconventional, but flycheck's job is to check it.  We could
fallback on the rust checker here and it should work.  The problem is how do we
/know/ the target the file is associated with?

Cargo doesn't tell us.  In fact, there could be multiple targets associated to a
file.  For instance, ~src/lib.rs~ is needed by the ~lib~ target, but also by the
~bin~ target.  How do we know which target to build then?  To get errors, any
target would do, but the correct answer is to get the smallest target that
contains our file.

So that seems out of scope for flycheck.  I think we can safely guess
"conventional" targets:

- ~src/main.rs~ is for the main binary target
- ~src/bin/x.rs~ for the the 'x' binary target
- any other file under ~src/~ is for the library target (if it exists),
  otherwise the main binary target

- ~tests/x.rs~ is for the ~x~ test target
- ~benches/x.rs~ is for the ~x~ bench target
- ~examples/x.rs~ is for the ~x~ example target

Now, any files in subdirectories of tests, benches and examples are not picked
up as targets, but can be used by them.  Problem: if there's a file
~tests/common/a.rs~, and multiple test targets, which target do we choose?

Hmm, seems we still want an answer to that question from cargo.

Okay, can we still get meaningful errors from the file even if we don't know the
target it will be used for?  After all, the target is required when /building/,
but to get compilation errors maybe just starting from the file is okay?

It seems we /can/ use plain ~rustc~ on files to get compilation errors, but
troubles arise when there are dependencies on external crates.  Rustc alone
won't fetch the dependencies, because that's cargo's job.

So I'm in favor of embracing the way cargo works, rather than working around it.
That means: either cargo gives us a way to get compilation errors for a specific
file, managing dependencies, or we use cargo to build targets rather than files,
and deal with it.

In the second option, we could use flycheck variables to set the target in some
edge cases if none can be found.

I'll try the second option first.

** Using cargo to build targets                                    :flycheck:
There is one canonical way to build things with cargo: ~cargo build~.

We can determine the current target automatically for some files, using
heuristics for others, and using buffer-local variables for the rest.

Once we have the target, it's a matter of passing it to ~cargo build~ and we
will get errors.

BUT, to get errors in the JSON format with ~cargo build~ we need to pass the
option to ~rustc~ via the environment variable ~RUSTFLAGS~.  The problem is,
changing ~RUSTFLAGS~ will re-trigger a full recompilation, even if it's
unnecessary in this case since ~--error-format~ does not change the code.

That's not an issue in successive calls by flycheck, but if it's intermingled
with calls by the user to ~cargo run~ or ~cargo test~, then it will trigger a
full rebuild of the crate.

Another option is to wait for [[https://github.com/rust-lang/cargo/pull/3000][cargo#3000]] to land, where we can safely ask for
the JSON format without re-triggering compilation.  But we cannot use
~no-trans~, which speeds up the recompilation to get error feedback.

Yet another option, that we currently use, is to use ~cargo rustc~ directly.
There we can safely pass the ~--error-format~ option without triggering
recompilation, and we can specify targets in the same way as ~cargo build~.

One advantage of using ~cargo rustc~ is that the ~no-trans~ options seems to be
applied only to the target itself, whereas with RUSTFLAGS it seems to apply to
all invocations of ~rustc~ made by cargo, and it fails miserably to build a full
crate.

So the new plan is: use ~cargo rustc~ for now, try to match files files to build
targets exactly first, then using heuristics based on the conventional cargo
layout, then let the user use the buffer-local variables to specify the target.

* [2016-10-07 ven.]
** Adding tests to flycheck-rust                                   :flycheck:
Since we have many different crate types and targets, it makes sense to add
tests to catch them all and avoid regressions.

Should I use ERT or buttercup?  Let's try buttercup first, as it is presumably
easier to setup and use.

Yep, wasn't hard.

** Fallback strategy for non-exact file/target matches             :flycheck:
In the conventional cargo layout, it seems we can try to match the file by
stripping off directories:

'test/support/a.rs' won't match any target exactly, so try to match targets
beginning with 'test/support' (no match), then 'test/' (multiple matches);
assume the first one.  Stop at the project root.

** Cannot pass error-format to ~cargo rustc~                       :flycheck:
AAARGH.  Passing options to ~cargo rustc~ will only apply to the given target,
not to dependencies.  So if main depends on lib, and we build main, but lib has
an error, we will get errors as plain text, not in JSON...

Ok ok.  RUSTFLAGS it is then until ~--message-format~ stabilizes.  But RUSTFLAGS
will trigger recompilation.  Hmmm.

* [2016-10-12 mer.]
** Updating Spacemacs to 0.200                                        :emacs:
Especially dreadful, updating colemak-hjkl.

Seems the issues I was encountering with keyboard-layout are also present
there.  Hmm, maybe it would be worth it to complete the colemak support for
keyboard-layout rather than duplicating the work?

* [2016-10-12 mer.]
** Updating colemak-hjkl for Spacemacs 0.200                          :emacs:
Argh, the new transient maps with hydra are less easily redefined than the
micro-states.

Redefining the transient state with the ~spacemacs|define-transient-state~ macro
does not work.

Redefining the keys directly inside the keymap should work, but I need to find
the way to run the redefinition code after the keymap is defined.  Alas, the
hydra is defined in a ~spacemacs/defer-until-after-user-config~.  Which means
that spacemacs runs code after user config, although the docstring to
user-config implies otherwise.

Adding the redefinition code to the same ~defer~ hook does not work, because it
adds the hook at the front rather than at the end.  Does using the extra
argument to ~add-hook~ works?  Ok, it works.

One extra difficulty with the way this is setup is that the bindings also appear
in the docstring to Hydra, so we must also change the docstring.  Thankfully,
the docstring that is used by hydra and displayed to the user is put inside a
~defvar~, so we can alter it at any point afterwards.

But at this point, since we know that the ~defhydra~ call is happening in the
~post-user-config~ hook, might as well redefine the call there.  That could get
messy fast though.

Hmm okay, managed to ~pcase~ it.

* [2016-10-13 jeu.]
** The simple fix that was surprisingly tricky                     :flycheck:
Trying to fix [[https://github.com/flycheck/flycheck-rust/issues/40][issue 40]] by adding a `user-error` call when cargo cannot be found.
It works, but a bit too much.  Most command interaction after that will trigger
the error, rendering Emacs unusable.

Actually, this will also happen if ~cargo~ cannot be found, without the
~user-error~.  The error is credited to ~global-flycheck-mode-check-buffers~:

: Error in post-command-hook (global-flycheck-mode-check-buffers)

This ~check-buffers~ function is created by ~define-globalized-minor-mode~ and
is run in ~post-command-hook~, and in turn will call
~flycheck-mode-enable-in-buffers~, which will turn flycheck-mode in the buffer
after the ~post-command-hook~.  And turning flycheck-mode will, in turn, call
the flycheck-rust hook.

I'm not sure there's a point to call ~flycheck-rust-setup~ in the flycheck-hook
anyway.  It should only be loaded when the rust and rust-cargo checkers
predicates are true?

In any case, silently doing nothing if the executable cannot be found is not
really better.  You get a suspicious checker error, but at least it lets you use
Emacs.

* [2016-10-19 mer.]
** Rust Language Server first alpha is here                    :flycheck:rls:
[[https://internals.rust-lang.org/t/introducing-rust-language-server-source-release/4209][Announcement]]

It seems it does much more than just checking errors, but advertises "errors as
you type".

So, there might be an overlap with flycheck, especially as I expect there to be
a dedicated Emacs package to communicate with the RLS, if it's not included in
rust-mode outright.

Hmm, can't build without the nightly compiler.  I still have rustup, don't I?

I do, just updated and run:

: env PATH=/home/fmdkdd/.cargo/bin:/usr/bin cargo build

to run the rustc and cargo executables from rustup for this command only,
without changing my PATH globally.

After which I can `cargo run`, and ... hmm.  Do what exactly?
It's supposed to be a server, but `lsof` reports no open ports.

The doc says to set the SYS_ROOT env var.  Let's do it.  Still no ports.  Ah ok,
the doc mentions that the language server protocol uses JSON over stdin/stdout.
The HTTP server is actually a separate option `--http`.

That's interesting.  How do I write to stdin interactively?  Writing anything
stops the program without any message.

Okay, let's try the HTTP protocol.  It listens on port 9000 and is responsive to
curl.  But I can't find a way to get compilation errors.

Not ~/on_build~.  Maybe ~/on_save~?.  What does it take?  This:

#+BEGIN_EXAMPLE
pub struct SaveInput {
    pub project_path: String,
    pub saved_file: String,
}
#+END_EXAMPLE

but as JSON.  What should the JSON look like?

#+BEGIN_EXAMPLE
{
  "project_path": "sample_project_2",
  "saved_file": "sample_project_2/src/main.rs"
}
#+END_EXAMPLE

Yes, but for some reason if the outer braces are eaten in the process, and serde
cannot parse it as JSON, hence we should double them:

: curl -v -H "Content-Type: application/json" -d '{{"project_path": "sample_project_2", "saved_file": "sample_project_2/src/main.rs"}}' 127.0.0.1:9000/on_save

Success!  It returns some JSON with errors.

#+BEGIN_EXAMPLE
{
  "Success": [
    "{\"message\":\"field is never used: `x`, #[warn(dead_code)] on by default\",\"code\":null,\"level\":\"warning\",\"spans\":[{\"file_name\":\"src/main.rs\",\"byte_start\":137,\"byte_end\":143,\"line_start\":10,\"line_end\":10,\"column_start\":5,\"column_end\":11,\"is_primary\":true,\"text\":[{\"text\":\"    x: u32,\",\"highlight_start\":5,\"highlight_end\":11}],\"label\":null,\"suggested_replacement\":null,\"expansion\":null}],\"children\":[],\"rendered\":null}",
#+END_EXAMPLE

It's curiously returned as a list of strings, rather than a list of objects, but
it seems to match the JSON error format of rustc alright.

So, it seems we could add a checker to flycheck that interacts with the RLS by
sending "on_change" or "on_save" messages, and parse the result, *without*
caring about build targets.  Here we just say "this file in this project
changed, give me compilation errors".

Now, let's see if we can get the build target information for a file from cargo
directly.

** Can cargo gives us a list of build targets for a given file?    :flycheck:
The read-manifest command seems to return a ~Package~.  Does it build a
dependency graph to find targets, or does it only reads the ~cargo.toml~?

The real work seems to happen [[file:~/proj/flycheck-rust-tests/cargo/src/cargo/util/toml.rs::fn%20to_real_manifest(][in cargo/util/toml.rs::to_real_manifest]], but as
far as I can tell, it only reads the manifest without actually checking any
files.

Let's check that with strace:

: strace -e trace=file cargo read-manifest

#+BEGIN_EXAMPLE
stat("/home/fmdkdd/proj/flycheck-rust/tests/test-crate/Cargo.toml", {st_mode=S_IFREG|0644, st_size=48, ...}) = 0
open("/home/fmdkdd/proj/flycheck-rust/tests/test-crate/Cargo.toml", O_RDONLY|O_CLOEXEC) = 3
stat("/home/fmdkdd/proj/flycheck-rust/tests/test-crate/src/lib.rs", {st_mode=S_IFREG|0644, st_size=7, ...}) = 0
stat("/home/fmdkdd/proj/flycheck-rust/tests/test-crate/src/main.rs", {st_mode=S_IFREG|0644, st_size=40, ...}) = 0
open("/home/fmdkdd/proj/flycheck-rust/tests/test-crate/src/bin", O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC) = 3
open("/home/fmdkdd/proj/flycheck-rust/tests/test-crate/examples", O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC) = 3
open("/home/fmdkdd/proj/flycheck-rust/tests/test-crate/tests", O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC) = 3
open("/home/fmdkdd/proj/flycheck-rust/tests/test-crate/benches", O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC) = 3
#+END_EXAMPLE

It looks for some conventional files and folders, but that seems to happen when
creating the layout in [[file:~/proj/flycheck-rust-tests/cargo/src/cargo/util/toml.rs::pub%20fn%20from_project_path(root_path:%20&Path)%20->%20Layout%20{][cargo/util/toml.rs::Layout::from_project_path]].  They are
only checked for existence, not read.

So I guess the compiler is the one that reads the files and resolves the
dependencies.  Hence, to add the command I want we would need to interact with
rustc directly.

*** Reading /etc/passwd
On an unrelated note, there's a read to /etc/passwd.  What's up with that?  The
context:

#+BEGIN_EXAMPLE
stat("/.cargo/config", 0x7ffdb20a8690)  = -1 ENOENT (No such file or directory)
open("/etc/passwd", O_RDONLY|O_CLOEXEC) = 3
stat("/home/fmdkdd/.cargo/config", 0x7ffdb20a8690) = -1 ENOENT (No such file or directory)
#+END_EXAMPLE

Hmm, it's probably reading /etc/passwd to determine my $HOME folder.  This is
most probably in cargo/util/config.rs::walk_tree, which in turn relies on
std::env::home_dir.  Which calls sys::os::home_dir, which reads passwd.

** Avoiding errors in flycheck-rust                                :flycheck:
As expected, the absence of cargo is not the only potential source of errors.  I
should really catch all errors to avoid breaking emacs.

Here, opening ~env.rs~ in the stdlib triggered an error.

After RTFM, I found ~with-demoted-errors~ to catch any error and report them as
messages, which is exactly what we want here.  That way, I can still have custom
messages for specific errors (like a missing cargo executable, which ought to be
signaled to the user).

The "proper" way would be to create custom errors with ~define-error~ and signal
them for each case.  But that's a bit heavy-handed for so little code here.

* [2016-10-21 ven.]
** Source diving into a solitaire bot
A [[https://gist.github.com/CyberShadow/218d1ac4033b5d67d99ba5ec4e433b46%20][couple]] of [[https://gist.github.com/BlaXpirit/7a032c0675b56a78d3d0518ac8e4997e][someones]] wrote bots for the solitaire game in Shenzhen I/O.  It
stumped me as something I didn't know how to build.  The Crisp (yet another
language!) solution is less than 500 lines of code.

The problems I didn't know how to solve: extracting the info from the game
screen, sending input back, and then of course solving.

Well, the Crisp solution uses ~import~ to get a single screenshot of the
starting point.  Then it recognizes the cards, computes the list of moves to the
solution, and play them with ~xdotool~.

The D solution uses ~scrot~ to get the screen and talks to ~X11~ directly to
move the mouse.

To recognize the cards, since the cards position is fixed, you could just look
at the corner of each card with hard-coded coordinates, and find pixels that
determine its value.

But what they do is a bit more resilient.  They take a sample screenshot of the
opening game screen, and write down in a text file the value of each card:

: r1 g9 b8 f  g4 r3 g7 b
: ...

Then they look at the corner area of each card, get the pixels there and
associate them with the correct value in a hashmap.

Then, they take the actual game screenshot, look at the corners again, get the
pixels, and lookup the hashmap to get the card values back.

Now they know exactly how the cards are laid out, and just need to solve it.
The solving is not that simple, but the gist of it is a breadth search in the
solution space, where the goal is to have no cards left in the lower area.

* [2016-11-22 mar.]
** Fixing my GBS emulator                                               :gbs:
So, after a full rewrite of the CPU, it /still/ doesn't pass Blargg's tests.
Now, I could carefully go over each instruction, /again/, and each opcode, to
see if I've messed up anywhere.  But doing this manually is prone to error.

Talking to Merwan about it, he wished for a way to compare the output of
different emulators, in order to find discrepancies automatically and quickly.

Now, I remember that testing the CPU for the NES emulator I wrote in JS was a
breeze, because some kind soul had written a ROM testing all the instructions
(like Blargg), but also provided a trace file containing the expected state of
the emulator before and after each instruction.  That way, you can pinpoint
exactly what failed.

So, for starters, I could take a working emulator or two, get them to generate a
trace for executing the cpu_instrs test ROM, and compare the output with mine.

** Running cpu_instr on Higan                                           :gbs:
Higan is one of the most accurate GB emulator out there.  So let's try that one
first.  It'll be interesting to compare its output to that of Boyo's.

The source is hosted on gitlab: https://gitlab.com/higan/higan.

To compile, I just had to install gtksourceview2 and tell make to use g++
instead of the hardcoded g++-4.9.  Version 4.9 was locked for linux builds;
there may be legitimate reasons for that, but they were not documented!

Running... Ah.  Higan needs BML files under ~/.local/share/higan/.  Okay, these
are in the source under higan/higan/systems.  Let's cp -r these.

Oh.  [[https://byuu.org/emulation/higan/game-paks][One does not simply run a ROM with Higan]].  I see.  Will creating a gamepak
folder manually suffice?  Hmm, creating a folder and putting a GB ROM inside
does not appear to be enough.

Okay, let's try icarus then.  First ~make~ it.  Then import a GB rom into a
dedicated "Game library" folder.  The structure is now:

#+BEGIN_EXAMPLE
.
└── Game Boy
    └── cpu_instrs.gb
        └── program.rom

2 directories, 1 file
#+END_EXAMPLE

Well, apparently I wasn't far off.  Maybe missing the ".gb" extension in the
folder name.

Trying to load that in Higan... Argh.  Missing manifest file.  Well, icarus
disabled the creation of a "manifest.bml" on the grounds of "backwards
compatibility".  Let's try that import again.

#+BEGIN_EXAMPLE
└── Game Boy
    └── cpu_instrs.gb
        ├── manifest.bml
        └── program.rom

2 directories, 2 files
#+END_EXAMPLE

What's in the manifest?  Not much:

#+BEGIN_EXAMPLE
board mapper=MBC1
  rom name=program.rom size=0x10000

information
  title:  cpu_instrs
  sha256: 8c5e12f41e0ba5bbca796944f92ffe6de28809198682c4332e38d1b3cf56fcf2
  note:   heuristically generated by icarus
#+END_EXAMPLE

Yes it loads!  And all tests pass.  Now to get a trace.

** Getting a trace out of Higan                                         :gbs:
For reference, here's how the traces looked like for the NES test ROM:

#+BEGIN_EXAMPLE
C000  4C F5 C5  JMP $C5F5                       A:00 X:00 Y:00 P:24 SP:FD CYC:  0 SL:241
C5F5  A2 00     LDX #$00                        A:00 X:00 Y:00 P:24 SP:FD CYC:  9 SL:241
C5F7  86 00     STX $00 = 00                    A:00 X:00 Y:00 P:26 SP:FD CYC: 15 SL:241
#+END_EXAMPLE

First column is the PC address, then the opcode and its arguments, then the
decoded opcode, then register values.  There's also the cycle count, and I can't
remember what SL stands for.

So let's try to get the current PC value on stdout from Higan.

Higan apparently has facilities for printing, maybe to be cross-platform.  So I
can just add:

: print(hex(r[PC]), "\n");

The ~auto LR35902::instruction() -> void~ method seems like a good place to get
a trace.  Let's add the whole line!

Wait, apparently this is already included in disassembler.cpp.  The disassemble
method returns a line with PC, decoded opcode, and CPU registers.

There is a bug though, as all the opcodes appear as "nop", and the emulator is
definitely not nopping around.

Ah, found it.  To read the memory, ~disassemble~ uses ~debuggerRead~, a virtual
method with a default implementation of ~return 0~.  The GameBoy CPU inherits
from LR35902 and defines a ... ~readDebugger~ method instead.  Correcting it to
~debuggerRead~ fixes this.

I could submit a patch, but the Gitlab repo appears to be a "unofficial mirror",
and even there I can't find a way to report an issue/submit a patch (it appears
to be disabled).

Anyway, now I have something I can compare with.  Just missing cycles.

Oh, cycles are counted in CPU, not LR35902.  No matter, I'll move the outputting
to CPU.  In fact, there is a very similar thing happening in the MegaDrive
emulator:

#+BEGIN_SRC c++
auto CPU::main() -> void {
  #if 0
  static file fp;
  if(!fp) fp.open({Path::user(), "Desktop/tracer.log"}, file::mode::write);
  fp.print(pad(disassemble(r.pc), -60, ' '), " ", disassembleRegisters().replace("\n", " "), "\n");
  #endif
#+END_SRC

But the disassemble methods in the GB emulator are public only when the DEBUGGER
flag is defined at compilation time.  I'll put the output print behind the flag
as well then.

Generating trace... SIGSEGV.  And here I was, thinking that C++ was not so
crappy after all!  The developer had written nice abstractions, and compiling
was a breeze (much faster than Rust).  And BAM.  Address boundary error.
Commenting the ~print()~ line makes it go away.

So it seems that ~disassemble~ is the cause.  Maybe some memory that's not
cleaned up properly.  In fact, without ~disassembleOpcode~ it does not SIGSEGV.

Hmm, let's try GDB.  Okayyy, the backtrace is huge, so it could be a stack
overflow.  But the stack is full of:

#+BEGIN_EXAMPLE
#92128 0x6666666666666666 in  ()
#92129 0x6666666666666666 in  ()
#92130 0x6666666666666666 in  ()
#92131 0x6666666666666666 in  ()
#92132 0x6666666666666666 in  ()
#92133 0x6666666666666666 in  ()
#92134 0x6666666666666666 in  ()
#92135 0x6666666666666666 in  ()
#92136 0x6666666666666666 in  ()
#92137 0x6666666666666666 in  ()
#92138 0x6666666666666666 in  ()
#92139 0x6666666666666666 in  ()
#92140 0x6666666666666666 in  ()
#+END_EXAMPLE

which is not particularly telling.  Maybe with -ggdb and without -O3?

Wow, 10FPS without -o#.  This time, I do have more information.  The backtrace
is the same, but I have the failing line:

#+BEGIN_EXAMPLE
Thread 1 "higan" received signal SIGSEGV, Segmentation fault.
0x00000000009aec94 in nall::hex<nall::Integer<8u> > (value=..., precision=4, padchar=48 '0') at ../nall/string/format.hpp:95
95	    p[size++] = n < 10 ? '0' + n : 'a' + n - 10;
#+END_EXAMPLE

Aha!  Found it.

The culprit is this loop:

#+BEGIN_SRC c++
  uint size = 0;
  do {
    uint n = value & 15;
    p[size++] = n < 10 ? '0' + n : 'a' + n - 10;
    value >>= 4;
  } while(value);
#+END_SRC

It constructs the hex representation of ~value~ by taking a nibble at a time,
and discarding it with ~>>= 4~.  When ~value~ is all zeroes, it cuts short.

But, some values are signed integers, and for signed integers ~>>=~ will
propagate the sign bit, meaning that a 0xFF value will stay at 0xFF infinitely.
Then the loop continues to write to ~p~, and ultimately writes outside the
program memory triggering the SIGSEGV.

Wait, according to [[https://stackoverflow.com/questions/7522346/right-shift-and-signed-integer][this SO thread]], the behavior of right shift on signed
integers is actually implementation defined!  That's terrible.  So at least
here, what happens is we get the arithmetic shift but wanted the logical one.
In fact, when constructing the hexadecimal representation of the argument, we
don't care about its sign at all.

Hmm okay, so a fix could be to bound the loop by the size of the argument rather
than taking shortcuts:

: while(size < buffer.length());

We allocated a buffer of ~sizeof(T) * 2~, the maximum number of nibbles, so use
that.

The correct fix would be use a proper logical shift rather than use the
unspecified right shift, but that will do for getting a trace.

Running all tests now... okay I have a trace!  And it's 2.1G!  No wonder no one
is hosting these kind of things.

But hey, it's 2016, I have free terabytes, and I can regenerate the trace in 30
seconds now.

I can cut the end a bit, as the tests end on a an infinite loop:

: 06f1  jp   $06f1

So I can keep only the first of such lines.  As long is I do the same in my own
emulator.

Now, I just need to generate a CPU trace from my end, then we diff!

** Getting a trace from my Rust GB emulator                             :gbs:
Hopefully the Rust stdlib will cover outputting padded hex values.  I can skip
writing a disassembler by cutting the second column.

Argh.  Forgot that Higan loads the GB BIOS ROM at first.  They actually
distribute it along the code source, hmm.

Wouldn't it be funny if starting with the BIOS ROM fixed, my CPU would work
fine?

Okaaaay.  Added a bit of code to load the BIOS ROM.  Got a trace.  Got a bit of
Awk to give me the first different line.  First error on line 24601, after an
~rl c~ instruction.

Tomorrow, I can start fixing.  Then it would be interesting to add a third
emulator (Boyo?) to the mix.

* [2016-11-23 mer.]
** Fixing my GBS emulator, one step at a time                           :gbs:
Now that I've got the trace set up, let's see where the errors are.

First error on ~rl c~ with:

: 0 11001110
: | |
: | c
: carry

Higan gives:

: 1 10011100

and GBS gives:

: 1 10011101

Well, obviously, the LSB of C should be 0.

The bug is here:

: let mut v = x.rotate_left(1);
: let c = v & 0x01 > 0;
: if self.f(CY) { v |= 1 }

We rotate x, now the LSB is the new carry value (c), and we erase the LSB with
the current carry value (CY).  But we only set the LSB if carry is set, and we
do not clear it when carry is clear.

The fix:

: if self.f(CY) { v |= 1 } else { v &= !1 }

I expect the same bug to happen with ~rr~.

Next bug... ~ld a,($ff44)~.  Ah, yes of course.  FF44 is LY, the current
vertical line being written to the LCD screen.  I don't emulate that, so no
wonder.

Strange things though, is that I can't seem to get the output of writing to the
link port anymore.  I guess there's something tricky with the boot rom that I
failed to understand.  How does it work in Higan?

There is definitely a flag ~bootromEnable~, which will give data from the boot
ROM when true, and data from the cartridge mapper otherwise.  Thing is, it is
disabled by writing to FF50 which does not appear to be documented anywhere.

Do I get a write to FF50? ... nope.  I guess what happens is that the boot rom
expect LY to work in order to time the Nintendo logo coming down and the chime.
Crap.

Skipping the boot ROm altogether does not make me closer to passing the tests.
At all.

So I guess I'll have to emulate at least part of the LCD.

* [2016-11-27 dim.]
** There's a language server protocol package for Emacs        :flycheck:rls:
[[https://github.com/sourcegraph/emacs-lsp][In development]].  Does it work with the RLS?

At the moment, it seems this mode only supports TCP.  It appears to work for the
Go language server, which has a ~--tcp~ option.  Last time I checked, the RLS
worked over stdio or HTTP, but I don't remember seeing an option for TCP.

The RLS looks like it supports only stdio now.  Shoot.

* [2016-12-06 mar.]
** This week's goal: improving Rust support for Emacs          :flycheck:rls:
Plan A: interface the RLS and Flycheck to get diagnostics support through the
language protocol.

Supposedly, the RLS works with VS Code.  There is already an implementation of
the LSP for Emacs, but it doesn't work over stdio yet.

So I need:
- to make the LSP Emacs plugin work over stdio, and
- to make a Flycheck plugin for the LSP

If that does not work, or if the RLS is still flaky, then I can fall back on
finishing my PR for flycheck-rust.

** Communicating with the RLS over stdio                       :flycheck:rls:
Last time I checked, I got nothing.  Only the HTTP server worked, but now it has
been removed.

First things first, update the repo, rebuild.

: rustup update
: env PATH=~/.cargo/bin cargo build

Oh, there's a cargo bug preventing me to update.  Hold on.

[[https://github.com/rust-lang/cargo/issues/3340][That's the one]].  Fix is another environment variable.

: env PATH=... SSL_CERT_FILE=/etc/ssl/certs/ca-certificates.crt cargo build

Great.

Running it, now I see that they added errors on stdout when you try to type in
junk.

#+BEGIN_EXAMPLE
> env [...] cargo run
test
Content-Length: 83

{"jsonrpc": "2.0", "error": {"code": -32700, "message": "Parse error"}, "id": null}
#+END_EXAMPLE

That's useful.  Also, [[https://github.com/jonathandturner/rls/issues/111][someone mentioned]] the RUST_LOG=debug env variable to get
more output.  In this case, we get an additional bit of info:

#+BEGIN_EXAMPLE
> env [...] RUST_LOG=debug cargo run
DEBUG:rls::server: Language Server Starting up
test
INFO:rls::server: Header is malformed
DEBUG:rls::server: response: "Content-Length: 83\r\n\r\n{\"jsonrpc\": \"2.0\", \"error\": {\"code\": -32700, \"message\": \"Parse error\"}, \"id\": null}"
Content-Length: 83

{"jsonrpc": "2.0", "error": {"code": -32700, "message": "Parse error"}, "id": null}DEBUG:rls::server: Server shutting down
#+END_EXAMPLE

"Header is malformed".  Well, yes of course.

Now, let's see if I can get the Emacs plugin to talk to you.

If Emacs runs the RLS, it can certainly interact with it as a subprocess.
That's not the intended use case though.  We should rather connect to an
existing RLS.  Can I attach to the stdin/stdout of a running process?

Ok, after tinkering around with pipes, it seems there is no easy way to attach
to a the stdin/stdout of a running process from Emacs.  I /can/ write to a
running process ([[https://serverfault.com/a/297095][thanks]]).  But elisp facilities assume talking to a child
process.

Also, there's an [[https://github.com/sourcegraph/emacs-lsp/issues/8][issue for emacs-lsp]] discussing this.  And it advocates running
an instance of the RLS for each project.

Okay, that should be easier.  Instead of opening a network connection, you use
~start-process~.  Let's see.

: Error: (ls-connection nil)

when trying to run ~lsp-mode-init-conn~.

Hmm'kay.  Turns out this fails there:

: (gethash ws-cache lsp-ws-connection-map)

lsp-mode maintains a hashmap of workspaces to lsp processes.  A workspace is
what is returned by ~projectile-project-root~.  To avoid calling this function
every time a message is sent, it saves the result in ~ws-cache~.  But, as far as
I can see, ~ws-cache~ is never set, only when the mode is ~require~'d.  So when
you activate ~lsp-mode~ the first time, the it saves the workspace of the
current buffer.

I added

: (setq ws-cache ws)

in ~lsp-mode-init-conn~ as a temporary workaround.

Now it runs the process!  I had to create a dumb sh file to run the RLS:

#+BEGIN_EXAMPLE
#!/bin/sh

cd ~/proj/rustls
env PATH=~/.cargo/bin:/usr/bin SSL_CERT_FILE=/etc/ssl/certs/ca-certificates.crt RUST_LOG=debug cargo run
#+END_EXAMPLE

Because I cannot point cargo to the RLS directory.  I could run the what's under
/target directly but... then I have to add dynamic libraries.

Okay then, now it dies when initializing:

#+BEGIN_EXAMPLE
DEBUG:rls::server: Language Server Starting up
thread '<unnamed>' panicked at 'called `Result::unwrap()` on an `Err` value: Syntax(ExpectedSomeValue, 1, 1)', ../src/libcore/result.rs:837
note: Run with `RUST_BACKTRACE=1` for a backtrace.
#+END_EXAMPLE

Let's see what is sent:

#+BEGIN_EXAMPLE
Content-Length: 163
Content-Type: application/vscode-jsonrpc; charset=utf-8

{"id":30541757336744412,"method":"initialize","params":{"capabilities":null,"processId":null,"rootPath":"/home/fmdkdd/proj/chipers/","initializationOptions":null}}
Content-Length: 136
Content-Type: application/vscode-jsonrpc; charset=utf-8

{"id":89837330512483255,"method":"textDocument/didOpen","params":{"textDocument":{"uri":"file:///home/fmdkdd/proj/chipers/src/cpu.rs"}}}
#+END_EXAMPLE

Okay, two messages are sent.  Which one is causing the error though?

From what I can tell, messages from the RLS are caught by the process filter
~lsp-filter~.  It looks like it waits for the "Content-Length" string, gets the
length, parses the message as JSON, and gives either passes it to an existing
callback or puts it in a hashmap (to be consumed later?).

It doesn't handle Rust error messages like the one above though.

Let's try to send only the first message.

No error so far, but no answer from the server either.  Which, [[https://github.com/Microsoft/language-server-protocol/blob/master/versions/protocol-1-x.md][according to the
protocol]], is unexpected.  Unless, I'm not /seeing/ the answer because
~lsp-filter~ eats it.

It seems it's the second message, didOpen, that triggers the parse error on the
RLS.  Good to know.

But I'm still not getting anything back from the first, the "initialize".

Is this getting through?  Trying to copy and paste the message in the terminal
when running the RLS there gives me:

#+BEGIN_EXAMPLE
Content-Length: 83

{"jsonrpc": "2.0", "error": {"code": -32700, "message": "Parse error"}, "id": null}thread '<unnamed>' panicked at 'called `Result::unwrap()` on an `Err` value: Syntax(ExpectedSomeValue, 1, 1)', ../src/libcore/result.rs:837
#+END_EXAMPLE

But, my message appears as:

#+BEGIN_EXAMPLE
Content-Length: 164

Content-Type: application/vscode-jsonrpc; charset=utf-8



{"id":376714719500194922,"method":"initialize","params":{"capabilities":null,"processId":null,"rootPath":"/home/fmdkdd/proj/chipers/","initializationOptions":null}}
#+END_EXAMPLE

No carriage returns (CR, \r).  Bloody typical.

Ok, let's try to send the message by opening the process in Python.  How many
yaks will I shave today.

Here's what I got:

#+BEGIN_SRC python
import subprocess as sp

initialize = b"""Content-Length: 133\r
Content-Type: application/vscode-jsonrpc; charset=utf8\r
{"jsonrpc":"2.0","id":12345,"method":"initialize","params":{"capabilities":{},"processId":1,"rootPath":"/home/fmdkdd/proj/chipers/"}}"""

print(initialize)

with sp.Popen(["/home/fmdkdd/proj/rustls/run-rls.sh"], stdin=sp.PIPE, stdout=sp.PIPE) as proc:
    out, err = proc.communicate(initialize)
    print(out)
#+END_SRC

Gosh.  What does it take to send a valid message here?  Okay, turns out the LSP
mode for Emacs seems to follow the 2.0 revision of the protocol.  I'm not sure
which version the RLS speaks, as I haven't got a non-error answer back.

Still trying to trace where the parsing fails over in the RLS...

So far, it seems to decode the header, get the content as a string, and
then... offloads the parsing to a thread.  But before that can happen, the main
process continues to read messages on stdin, and since there is nothing more to
read, it aborts prematurely.

Wait, I thought I had a pipe.  Does communicate closes the pipe?  Argh, it looks
like it waits for the process to terminate, so yes.  Hmm, can I just write to
stdin then?

Yes, is seems that is better:

#+BEGIN_SRC python
    proc.stdin.write(initialize)
    proc.stdin.flush()
    print(proc.stdout.read())
#+END_SRC

And here are the first answers from RLS:

#+BEGIN_EXAMPLE
DEBUG:rls::server: response: "Content-Length: 487\r\n\r\n{\"jsonrpc\":\"2.0\",\"id\":12345,\"result\":{\"capabilities\":{\"textDocumentSync\":2,\"hoverProvider\":true,\"completionProvider\":{\"resolveProvider\":true,\"triggerCharacters\":[\".\"]},\"signatureHelpProvider\":{\"triggerCharacters\":[]},\"definitionProvider\":true,\"referencesProvider\":true,\"documentHighlightProvider\":true,\"documentSymbolProvider\":true,\"workspaceSymbolProvider\":true,\"codeActionProvider\":false,\"documentFormattingProvider\":true,\"documentRangeFormattingProvider\":true,\"renameProvider\":true}}}"
DEBUG:rls::server: response: "Content-Length: 72\r\n\r\n{\"jsonrpc\":\"2.0\",\"method\":\"rustDocument/diagnosticsBegin\",\"params\":null}"
#+END_EXAMPLE

Strangely, without RUST_LOG=debug, these are not written to stdout.  What's the
point then?

Oh, it /should/ output:

#+BEGIN_SRC rust
        debug!("response: {:?}", o);

        print!("{}", o);
        io::stdout().flush().unwrap();
#+END_SRC

But it doesn't.  I get it through ~debug~, but the regular ~print~ does
nothing.  Maybe... maybe ~flush~ isn't flushing?  Maybe it's buffered somewhere
because it's too small?

Maybe if I print a bunch?

#+BEGIN_EXAMPLE
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
      print!("{}", o);
#+END_EXAMPLE

Ah.  The compiler crashed.

#+BEGIN_EXAMPLE
note: the compiler unexpectedly panicked. this is a bug.

note: we would appreciate a bug report: https://github.com/rust-lang/rust/blob/master/CONTRIBUTING.md#bug-reports

thread 'rustc' panicked at 'Box<Any>', ../src/librustc_errors/lib.rs:382
note: Run with `RUST_BACKTRACE=1` for a backtrace.
#+END_EXAMPLE

Weird.  Cannot reproduce.

Still not flushing the response.  Let's try... exiting.  Nope.

At this point, I'm turning to the Python wrapper script.  Maybe there's
something fishy in there again.

I'm not sure reading my proc.stdout.read() is right.  Let's just pipe that the
output to the stdout of the process:

#+BEGIN_SRC python:
with sp.Popen(["/home/fmdkdd/proj/rustls/run-rls.sh"], stdin=sp.PIPE, stdout=sys.stdout, stderr=sys.stderr) as proc:
    proc.stdin.write(initialize)
    proc.stdin.flush()
    while True:
        time.sleep(1)
#+END_SRC

And keep the pipe open by sleeping.

Ahhhh.  Much better:

#+BEGIN_EXAMPLE
Content-Length: 487

{"jsonrpc":"2.0","id":12345,"result":{"capabilities":{"textDocumentSync":2,"hoverProvider":true,"completionProvider":{"resolveProvider":true,"triggerCharacters":["."]},"signatureHelpProvider":{"triggerCharacters":[]},"definitionProvider":true,"referencesProvider":true,"documentHighlightProvider":true,"documentSymbolProvider":true,"workspaceSymbolProvider":true,"codeActionProvider":false,"documentFormattingProvider":true,"documentRangeFormattingProvider":true,"renameProvider":true}}}Content-Length: 72

{"jsonrpc":"2.0","method":"rustDocument/diagnosticsBegin","params":null}Content-Length: 70

{"jsonrpc":"2.0","method":"rustDocument/diagnosticsEnd","params":null}
#+END_EXAMPLE

I'm tempted to introduce an error to see if the diagnostics work.

Hm, does not seem to give me any diagnostics after the initialize, even though
it clearly says "diagnosticsBegon" and "diagnosticEnd".  Maybe I should trigger
the analysis?

Argh, it seems complicated for now.

Okay, I just wanted to know why I didn't get any response from the server when
communicating through LSP mode.  Now I know it will respond to the initialize
command, given an adequately formatted message:

#+BEGIN_EXAMPLE
Content-Length: 133\r
Content-Type: application/vscode-jsonrpc; charset=utf8\r
{"jsonrpc":"2.0","id":12345,"method":"initialize","params":{"capabilities":{},"processId":1,"rootPath":"/home/fmdkdd/proj/chipers/"}}
#+END_EXAMPLE

But the message sent by the LSP was:

#+BEGIN_EXAMPLE
Content-Length: 163\r
Content-Type: application/vscode-jsonrpc; charset=utf-8\r
\r
{"id":30541757336744412,"method":"initialize","params":{"capabilities":null,"processId":null,"rootPath":"/home/fmdkdd/proj/chipers/","initializationOptions":null}}
#+END_EXAMPLE

and this fails.  And the culprit is the empty line before the content.  There
/is/ code in the RLS to skip this line:

#+BEGIN_SRC rust
        // Skip the new lines
        let mut tmp = String::new();
        handle_err!(io::stdin().read_line(&mut tmp), "Could not read from stdin");
#+END_SRC

But for some reason it does not work.  Removing the empty line in the message
works.  Alternatively, adding the two bytes for the extra \r\n to Content-Length
also does the trick.

So, if I remove the empty line in LSP...

Not picking up any response.  But at least, the RLS process is not exiting.
That's progress.

Hmm hmm.  Seems RLS hangs there:

#+BEGIN_EXAMPLE
TRACE:rls::server: ["Content-Length:", "165\n"]
TRACE:rls::server: reading: 165 bytes
#+END_EXAMPLE

Probably not enough bytes to read on stdin?

In the Python test, I get:

#+BEGIN_EXAMPLE
TRACE:rls::server: ["Content-Length:", "165\r\n"]
TRACE:rls::server: reading: 165 bytes
TRACE:rls::server: content: "\r\n{\"id\":30541757336744412,\"method\":\"initialize\",\"params\":{\"capabilities\":null,\"processId\":null,\"rootPath\":\"/home/fmdkdd/proj/chipers/\",\"initializationOptions\":null}}"
#+END_EXAMPLE

notice the additional *\r*.  The \r\n is definitely present in the LSP code, but
it seems to be eaten before it arrives to RLS.  I had a bad feeling about CRLF
from the start.

If I run "cat" instead of the RLS, here is what is actually sent:

#+BEGIN_EXAMPLE
Content-Length: 164

Content-Type: application/vscode-jsonrpc; charset=utf-8

#+END_EXAMPLE

No body, even though the argument to ~process-send-string~ contains it.  Also no
\r.

Trying to mess the with the process coding system... no luck.  Is there any way
to send raw bytes to a process instead?  Doesn't seem so.

But even disregarding the missing carriage returns, ~cat~ doesn't even get the
body!  That's mystifying to me.

Even trying to hardcode it fails:

: (process-send-string net-proc "{\"id\":30541757336744412}")

nothing is seen by the child process ~cat~!  Madness.

Okay.  Adding \n at the end fixes it.  It's simply not flushing stdin without
it.  And I see no way of forcing flush.  So let's add this final \n.

Now I see that it's going through.  And I get a parse error, probably because of
the missing \r.  I guess if I cannot make Emacs behave, I can always use a
wrapper to insert carriage returns.

Again, trying to toy with coding-systems, to no avail.

Tomorrow I will try a wrapper around the RLS to insert carriage returns.

Unanswered question: which version of the LS protocol does RLS use?

* [2016-12-07 mer.]
** Making the LSP mode and the RLS talk to each other          :flycheck:rls:
Written a wrapper python script to add the damned carriage returns:

#+BEGIN_SRC python
#!/usr/bin/env python

import subprocess as sp
import sys
import time

def wrap(body):
    return "Content-Length: {}\r\nContent-Type: application/vscode-jsonrpc; charset=utf8\r\n{}".format(len(body), body).encode()

with sp.Popen(["/home/fmdkdd/proj/rustls/run-rls.sh"], stdin=sp.PIPE, stdout=sys.stdout, stderr=sp.DEVNULL) as proc:
    while True:
        # Read until \n
        line = sys.stdin.buffer.readline()
        # Turn the bytes into an UTF8 string
        line = line.decode()
        # Line should be a JSON object, we wrap it
        msg = wrap(line)

        # print(msg)

        # Pass it to the subprocess
        proc.stdin.write(msg)
        proc.stdin.flush()
#+END_SRC

In fact, it adds the whole header, since there's no point passing through a
botched header from LSP.

Additionally, it silences stderr as the LSP mode cannot handle it.  A better way
would be to open stderr on Emacs side in a separate buffer, and be ready to get
errors there.  But, I think in case of parse errors the RLS will answer with a
JSON message on stdout anyway, so we could still handle errors in LSP without
watching stderr.

And it works!  And it fails after the initialize, because RLS sends commands
that are not part of the protocol:

: error in process filter: apply: Invalid function: ((jsonrpc . "2.0") (method . "rustDocument/diagnosticsBegin") (params))
: error in process filter: Invalid function: ((jsonrpc . "2.0") (method . "rustDocument/diagnosticsBegin") (params))

Mysteriously, there are no diagnostics being printed out between these two
commands.  I suppose diagnostics are not implemented yet in the RLS.

So this approach works.  But it requires a wrapper, so that's not adequate for a
plugin.  I now remember that I wanted to try comint.

* [2016-12-08 jeu.]
** Comint                                                      :flycheck:rls:
Hmm reading the documentation for comint, it seems more suited for interacting
with REPLs.  I guess you can sort of see the RLS as a REPL, where you
communicate with JSON, but there's no interactive part at all.  Not sure this is
the right way.

** Another emacs-lsp in the wild                               :flycheck:rls:
That's hilarious.  A few hours ago, [[https://lists.gnu.org/archive/html/emacs-devel/2016-12/msg00263.html][someone]] asked on emacs-devel why did
"process-send-string" eat carriage returns, for the purpose of making an LSP
package to communicate with Rust.  Turns out, [[https://github.com/vibhavp/emacs-lsp][their implementation]] seems more
advanced than the one from @cmr.

No definite answer on the carriage return problem.

** Trying out the new emacs-lsp                                :flycheck:rls:
Seems more solid.  Works over stdout, I can see the messages going out to the
server and coming back.

They solved the carriage return issue.  The correct incantation was to use
make-process in order to set ~connection-type~ to ~pipe~, as suggested by the
answer in the emacs-devel thread:

#+BEGIN_SRC elisp
(make-process :name "lsp"
              :buffer bufname
              :command '("cat" "-A")
              :connection-type 'pipe)
#+END_SRC

(using ~cat -A~ to check for carriage returns here)

In addition, the mode sends the right messages when the document changes, or
when the cursor stays a while on a symbol (using eldoc).

But the answers from the RLS rarely provide any useful content.  On-hover only
worked on one variable, whereas ~racer-doc~ works on variables, functions...

And there seems to be code for sending out diagnostics, but it's never actually
triggered.

My conclusion at the moment if that the Emacs side of thing looks good.  We have
two plugins in the works, with at least one that works out of the box.

Now we just need the RLS to catch up.

That means that, for the rest of the week, I should probably focus on improving
the state of flycheck-rust using cargo and rustc directly.

** Flycheck issues                                                 :flycheck:
A few weeks ago, I was in the process of refactoring flycheck-rust, and adding
tests.  I didn't care much for the plain rust checker, since it seemed hackish
in the way it looked for dependencies.

Then one of the original contributors for the rust checker showed up for a PR,
and I looked up the history of this checker.  Initially, it had support for
highlighting errors as you type.  Then, when rust-cargo came along, this had to
be disabled because it came in conflict.

I just tried to restore this functionality.  It's really snappy for standalone
rust files.  It's better than working with the rust playground when testing
small snippets.

Now, this plain checker is also used for projects that do not make use of
cargo.  The rub here is that if you have external dependencies, you are on your
own to manage them and to tell flycheck where to find them.  That's currently
done through the ~flycheck-rust-library-path~ variable.

~flycheck-rust~ will try to fill this variable by looking around, but that's
best effort without any guarantees.

Something's bugging me though, since we already have ~flycheck-rust-args~ for
passing arbitrary arguments to rustc, why the extra
~flycheck-rust-library-path~?

While we are at digging history, it seems lunaryorn favored passing buffer on
standard input.  This can be done for rustc by passing "-" as the input
filename.  But now errors are reported with "<anon>" as source, and you also
need to change the error parser to not provide any filename in this case.
Otherwise, errors are filtered and do not appear in the buffer.

Also, there may be lingering flycheck issues over at Spacemacs that were never
reported upstream.  Might be worth to take a look.

* [2016-12-09 ven.]
** Finding the right target for a rust file                  :flycheck:cargo:
That's the sole goal of flycheck-rust, and I have seen that the RLS is not there
yet.  I suspect IntelliJ also requires you to specify which target to run, since
it gives you the results in a bottom window, and from there you can jump to the
incriminated files.

My heuristics method is sound, but does not cover all files adequately.  In [[https://github.com/rust-lang/cargo/issues/3211][my
ticket to cargo]], it was suggested that I look into racer for to determine the
DAG of dependencies between source files.

From a cursory glance, I cannot find this information in the CLI tool.  But
maybe this information can be given by the racer library.  But that means
depending on a third-party tool that is yet to be written.  Hmmm.

It was also suggested to use ~cargo rustc --emit dep-info~.  It can give us a
file with a dependency graph, with a syntax reminiscent of Makefiles:

#+BEGIN_EXAMPLE
> rustc --crate-type lib --emit dep-info=t -Z no-analysis src/lib.rs
> cat t
srclib: src/lib.rs src/a.rs

src/lib.rs:
src/a.rs:
#+END_EXAMPLE

From there, we can determine that ~src/a.rs~ will be checked by the compiler
when building the the requested target ~src/lib.rs~ for instance.  But that
requires three steps:

1. First find the list of targets by calling ~cargo metadata~
2. Generate a dep-info for each target, to get the graph of dependencies
3. Parse these files and hope to find a match with buffer-filename

With the following limitations:

1. Parse error will prevent the dependencies from being created
2. The dependencies might change as a result of editing buffers (so you'd want
   to rerun flycheck-setup)

Also, I cannot get ~cargo rustc~ to emit dependencies.  The trick I found is to
use:

: env RUSTFLAGS='--emit dep-info -Z no-analysis' cargo build --lib

But, I'm not sure calling cargo is necessary in order to get the dependency
graph, since using cargo is useful to manage external dependencies, not internal
ones.  So we should be able to get by with ~rustc~ directly.  But need to test
on real crate.

Ok so on the trust-dns crate, using ~rustc~ is not enough, since it chokes when
looking for external crates, even though we are just asking for dep-info.

With cargo?  Passing ~--emit dep-info~ in flags works ... for the first
invocation of rustc, which happens to be on an external crate, semver.  I get
dependencies for semver, and after that:

: error: An unknown error occurred

Hmm.  Using ~cargo rustc --lib -- --emit dep-info=bla~ now.  Doesn't write to
bla.

Okay then.  ~rustc --emit dep-info~ is not an option.  racer is third party
dependencies.  Then we'll stick to hackish heuristics then.

** On cargo metadata and workspaces                          :flycheck:cargo:
It the same [[https://github.com/rust-lang/cargo/issues/3211][PR]] was suggested to use ~cargo metadata~ rather than ~cargo
read-manifest~.  The reasons mentioned were that ~read-manifest~ was deprecated,
and didn't support workspaces (had to read up on what they are).

I think I used ~read-manifest~ because ~metadata~ will trigger a compilation,
which seems unacceptable for this use case.  But, turns out that ~metadata
--no-deps~ will output the JSON that we want without building.

There's just an additional complication: since it's compatible with workspaces,
we have to find our targets inside a list of packages now.  The question is, how
do we deal with multiple packages?

(A related question is: what's the difference between a crate and a package?  I
asked on #rust-tools, and ... no answer yet.  But [[So probably ][watch this space]])

So, workspaces solve the problem of having multiple crates in the same
repository, when all these crates are really parts of the same project.  [[https://github.com/rust-lang/rfcs/blob/master/text/1525-cargo-workspace.md][The RFC]]
does a good job of explaining why this is needed and how it works.

The point is to have only one Cargo.lock file, and only one target/ build
directory, to ensure that all dependencies are synchronized, and to save on
compilation time.

That's quite important for Flycheck.  At the moment, in a project with
workspaces, we will look for the nearest Cargo.toml and be able to build targets
alright.  But, we might not build in the right target folder, since we would
miss the workspace entirely, and this would cause long compilation times.

In any case, I think we are safe if we just aggregate all "targets" for all
"packages" when looking for a best match.

Testing against a project with workspaces... (looking for one on Github is
rather easy, just code search for workspace in TOML files).  Ok, [[https://github.com/bluejekyll/trust-dns%20][found one]].

cargo metadata --no-deps gives me two packages, and plenty of targets:

: > cargo metadata --no-deps | jq .packages[].targets[]

But you cannot build anything since it's the top-level Cargo.toml is a virtual
manifest: it has no associated targets.

: > cargo build
: error: manifest path `/home/fmdkdd/proj/flycheck-rust-tests/trust-dns/Cargo.toml` is a virtual manifest, but this command requires running against an actual package in this workspace

I would expect to be able to build the crate from the top level by passing
--package, but no:

: > cargo build --package client --lib
: <exact same error as above>

With or without --lib, it fails.

So, if I go into client/ and build, will it build in a target/ at the top level
or inside client/?

Building... oh, it outputs in the top level folder.  Hmm good then, because it
means we can invoke cargo on the first Cargo.toml we find, without messing
things up.

So: replace ~read-manifest~ by ~cargo metadata --no-deps~, gather all targets,
and build in the current directory is fine.

* [2016-12-12 lun.]
** Actually pushing PR                                       :flycheck:cargo:
The time for research is done.  Now is the time to actually code and push.

First things first: enhance the rust-cargo checker in flycheck proper, since
flycheck-rust is more tricky, but rust-cargo should work without flycheck-rust.

The thing we need to fix is to make the targets variable wider, to accommodate
test and benches targets.

And use the new ~--message-format=json~ flag to cargo rather than use the
RUSTFLAGS environment variable for two reasons: 1) currently compilation errors
in dependencies will not follow the JSON format since passing
~--error-format=json~ to rustc only applies to the final compilation, and 2)
using RUSTFLAGS will trigger a recompilation if the user manually runs ~cargo
build~ without the same RUSTFLAGS.  Using the new flag, cargo knows it does not
affect compilation output and does not recompile anything superfluous.

Remaining question: should ~-Z no-trans~ be passed in RUSTFLAGS?

On the topic of terminology: we can keep using ~flycheck-rust-crate-type~ even
for cargo targets, since according to [[https://github.com/rust-lang/cargo/issues/3380][this issue]], they are the same thing.

Argh, bug with --message-format in combination with -Z no-trans.  If I build
with:

: cargo rustc --message-format=json --lib -- -Z no-trans

I get:

: error: Could not compile `test-crate`.

but no errors, human or JSON on output.

If I do:

: cargo rustc --lib -- -Z no-trans --error-format=json

I get the error.

But!  If I remove the ~-Z no-trans~ and do:

: cargo rustc --message-format=json --lib

Then I get the error.

Hmm, weird, when I try:

: cargo rustc --message-format=json -- -Z no-trans

on chipers (which contain no errors), I also get:

: error: Could not compile `chipers`.

but no errors.  Running with ~--verbose~, as suggested by the compiler, yields:

: error: Could not compile `chipers`.
: Caused by: failed to parse output: `rustc src/main.rs --error-format=json <snip>`
: --stderr

#+BEGIN_EXAMPLE
error: Could not compile `chipers`.

Caused by:
  failed to parse process output: `rustc src/main.rs --error-format json <snip>`
--- stderr
warning: the option `Z` is unstable and should only be used on the nightly compiler, but it is currently accepted for backwards compatibility; this will soon change, see issue #31847 for more details

Caused by:
  compiler produced invalid json: `warning: the option `Z` is unstable and should only be used on the nightly compiler, but it is currently accepted for backwards compatibility; this will soon change, see issue #31847 for more details`
#+END_EXAMPLE

So it seems... cargo is parsing the JSON output of rustc (maybe to linearize the
output of parallel compiler invocations).  But having a Z flag writes on stder,
and if I interpret the last error correctly, it tries to parse the stderr output
as JSON.

Reading the source, it seems it expects the JSON output on stderr, and stdout to
be empty.

Running the ~rustc~ command manually given by --verbose, I see that the JSON
errors indeed appear on stderr, as well as the "warning" for Z options.  So it
seems cargo funnels the JSON messages to stdout, but rustc will write everything
to stderr.

I think I can patch it by skipping over lines from rustc which do not begin with
'{', same as we do in Flycheck.  Don't know if that's a long-term solution
though.  Let's try it.

Added the line:

: if line.starts_with("{") {

and now it compiles.  So I guess I can file an issue that with a tentative fix.
But that means it won't be fixed before ... a long time.  So I'll have to hold
off my PR for Flycheck until then.  Shoot.

Or we continue using --error-format on the latest target, with the current
caveats.  Or we skip -Z no-trans, since after all we are using a nightly feature
on stable rust, and since nightly does not raise the warning, the problem does
not arise there.  Or we /require/ nightly for Flycheck, but that's a bit steep.
Or we hold off for [[https://github.com/rust-lang/cargo/pull/3296][cargo check]] to land (but it's not merged yet).

I'd rather find a workaround for the current version of cargo, but I cannot find
any flag that would allow me to skip this.

Also, using --error-format without RUSTFLAGS quickly fails on the test-crate
when building a binary that requires the lib, since the lib is a dependency and
contains an error.  So at the moment I'm stuck, because RUSTFLAGS has the
downside of triggering recompilation.  As the status quo works, let's leave it
at that.

What I /can/ do though, is fast-track the clippy checker PR and integrate the
changes on top of it.  Since it requires nightly anyway, I will be able to use
--message-format without troubles.

** Fast-tracking the rust-cargo-clippy checker              :flycheck:clippy:
Downloading the PR locally to test.

Argh, cannot compile cargo-clippy with latest nightly.  Asking on IRC.  Oh, it's
a [[https://github.com/Manishearth/rust-clippy/issues/1381][bug]].  Installing the adequate nightly...  Yeah now it works.

Remember to ~rustup default nightly-2016-11-25~ to update the symlinks under
~/.cargo/bin.

Now I can run clippy with flycheck.  On the surface, it works.

Now what's that talk about clippy checking all the available targets?  I can't
seem to pass a ~--bin~ or ~--test~ flag, but if I have errors in a test binary
and in the lib crate, it only prints the error for the lib (even though the test
does not depend on the lib crate).

Removing the error though, it does pick up errors in examples/.  So it seems it
does run all targets, but one after the other, not concurrently.  So you cannot
have error feedback when there's an error in another target that's checked
before.

Gosh this is annoying, since in the case of Flycheck, it will run for /every/
target, even for a single buffer.

Well, at least it's opt-in.  But it means there's not much I can do to on it to
test nightly features.  Just ~--message-format~.

Also, we are not using ~-Z no-trans~ there.  Don't know if we should... maybe
~no-trans~ should be behind a flag for all rust checkers, that way we let users
choose between correctness and speed.

* [2016-12-14 mer.]
** Emulating the GameBoy screen                                         :gbs:
Trying to separate concerns a bit.

The background is 256*256 pixels, or 32*32 tiles, and tiles is 8*8 pixel.

256*256 = 65536 pixels
32*32 = 1024 tiles
32*32 * 8*8 = 65536

The tile map area is 0x1000 bytes long, and two bytes make 8 pixels.

0x1000 * 4 = 16384

0x1000 / 16 = 256

There can be 256 different tiles in the pattern table.

Tried to separate things... there's still a coupling between LCD and Screen.  I
think it's because Screen is the implementation of an abstract drawing surface,
and LCD tries to use it directly.  An alternative would be to declare a trait of
some kind on which I can draw, LCD would use that type, and Screen would
implement it.

Also, what would be really neat would be to have a mapping between memory places
and Rust structs for I/O registers and the like.  So you deal with mapping
to/from bits only once, and after that you deal with structs and fields that
mean something.  In C you can declare a large RAM, create a struct and map it to
some place in the RAM and that's it.  All fields now point to the correct
places.  Changing and accessing the RAM or the field is the same, no additional
work needed.

* [2016-12-16 ven.]
** Data-binding in Rust                                                 :gbs:
I did some tests yesterday.  What I can do in C, I can do in Rust using
mem::transmute at the very least.  Create a large RAM array, create a struct for
Tiles, and transmute a pointer to the RAM as a pointer to a Tile.

Of course, that's unsafe, and might even be undefined behavior.   And the struct
might not be densely packed in memory, so you could have holes that do not map
directly to the RAM.

Otherwise, the Tile struct can contain only /pointers/ to offsets in the RAM.  A
Tile is a certain view of the RAM, with friendlier field names.  That works, but
only when the pointers are non-mutable, otherwise you have a trouble of multiple
mutable borrows.  So that's only a one-way binding.  But actually, I realized
that's all I need realistically.  The ROM program will always access tile data
by reading from and writing to the RAM, not through the Tile struct.  The Tile
struct is useful as a more precise view of some RAM area, and as such can be
immutable.

In fact, if all the reads and writes go through the RAM first, then you can just
implement the redirection in the memory module to write in the tiles data rather
than in the RAM array.  That's what [[https://github.com/Gekkio/mooneye-gb][mooneye]] does.  One downside of this approach
though is that your (internal) RAM array is not a faithful representation of the
GB RAM, since parts are never read and written to.  So you cannot serialize it
by dumping the RAM array.  But, if you stick to the read method of the memory
module (its interface), then it is consistent.

It might even mirror the way the GB hardware was wired up.  Read/write access to
the tile pattern table probably was directly wired to VRAM that was held up by
the PPU chip.

So this approach is fine.

** flycheck-rust errors when browsing cargo                  :flycheck:cargo:
When fixing bug #3390 in cargo, I noticed flycheck-rust had trouble finding
the right build targets in some files.  Should probably investigate.

Ah ok, first error was just a fluke caused by Spacemacs STILL NOT PICKING UP THE
FLYCHECK THAT'S IN MY LOAD PATH.  Jebus.  I have to find out how to do that.

After losing a couple hours (and losing WIP in flycheck due to a hard link even
though I had used ~ln -s~... sigh) and getting help on the Spacemacs Gitter,
turns out the only reliable way is to ~load-file~ my local packages.  In another
case of issue resonance, someone [[https://github.com/syl20bnr/spacemacs/issues/4979][faced the exact same problem]], and for flycheck
even!

And the other error was caused by a relative path as a target file name given by
~cargo read-manifest~.  I could workaround it in flycheck-rust, but it seemed
more appropriate that ~cargo read-manifest~ (and ~cargo metadata~) gave
canonical file names throughout, so I reported an issue.  Might even send a PR.

** Looking at how mooneye is structured                                 :gbs:
Because Rust definitely favors a single-owner for structs, since having multiple
mutable references to things is a nightmare.

In mooneye, the GPU and PPU (called GPU) are all in a Hardware struct that
handles read and writes to them.  Then the CPU contains the Hardware, through
the declared type is a Bus trait:

#+BEGIN_SRC rust
pub trait Bus {
  fn write(&mut self, u16, u8);
  fn read(&self, u16) -> u8;
  fn emulate(&mut self);
  fn ack_interrupt(&mut self) -> Option<Interrupt>;
  fn has_interrupt(&self) -> bool;
  fn trigger_emu_events(&mut self, EmuEvents);
}
#+END_SRC

So the CPU "owns" the hardware in the end, but at least it goes through an
interface.

The two are assembled in a Machine struct:

#+BEGIN_SRC rust
pub struct Machine {
  cpu: Cpu<Hardware>
}

impl Machine {
  pub fn new(config: HardwareConfig) -> Machine {
    Machine {
      cpu: Cpu::new(Hardware::new(config))
    }
}
#+END_SRC

Disappointing.

rustendo64 is sparse.  It does not appear to have anything other than the CPU at
the moment.

sprocketnes goes for CPU owning the memory as well.

Weeell.  Turns out, I may be overthinking this.  If the modules interact with
each other through a Trait, that should be good enough for reuse.  Just have to
make sure that when you assemble them, you put them in the proper order.

* [2016-12-20 mar.]
** Investigating template parameters for traits                        :rust:
I saw the solution, but not why it was necessary.  After starting from the bits
I understand and expanding, I think I'm getting more familiar with how the
pieces work together.

* [2016-12-23 ven.]
** Installing ArchLinux on a VAIO z13                                  :arch:
Because I'm tired of Ubuntu.

Installing ArchLinux on my desktop was mostly a breeze.  Configuring took time,
but no hardware hitches.

There are a few additional gotchas for laptops, as usual.

*** Hybrid graphics
First of all, the z13 is a hybrid graphics machine: one integrated (i915) GPU
and one discrete nvidia card.  That was a nightmare to get working every time I
installed Linux on it, but for a while now I have flashed the BIOS to open up
hidden options, and disabled the nvidia GPU at boot.

*** Raid0
Second, there are two 64Gb SSDs striped in raid0.  To partition the drives the
first time (years ago), the only thing that worked out of the box was a Gentoo
live USB.  Now the ArchLinux live USB flawlessly picked up the raid0
configuration, but not after the installation.

After GRUB selection, I got "unable to find root UUID".  This was caused by not
loading the raid modules in the kernel, so the partitions could not be found.
Adding:

: MODULES="md_mod raid0"

and adding the ~mdadm_udev~ hook:

: HOOKS="base udev autodetect modconf mdadm_udev block filesystems keyboard fsck"

to /etc/mkinitcpio.conf, and running:

: # mdadm --examine --scan > /etc/mdadm.conf

(after installing mdadm), did the trick.

At first I thought it was a fstab issue with the UUIDs, but no.  Also, I tried
to add the ~mdadm~ hook and it did not work.  Neither did adding the ~block~
module before ~autodetect~ as suggested by a SO answer.  From a cursory reading
of ArchWiki, it seems not a good idea to do that either, since autodetect will
help in lazy loading modules, so it should come early in the hooks list.

*** Backlight
Since I'm using i3 directly on top of Xorg and xinit, my brightness keys are not
directly recognized.  Well, they are by ~xev~, but they do not alter the
backlight.

Though there is a /sys/class/backlight/intel_video/brightness that can be
altered by writing to it.  And after installing xf86-video-intel, xbacklight
picks it up and I can bind ~xbacklight -inc 5~ to the brightness keys in my i3
config.

On a related note, it seems the z13 uses PWM (around 200Hz at the moment), but I
haven't noticed any flickering in years of use.

*** Optical disk
That one is probably my fault.  After opening the z13 a couple of times to clean
it up and re-apply thermal paste, the optical disk tray opens up by itself,
probably because some sensor was misplaced when putting it back together.

Disabling the sr_mod and cdrom kernel modules did not fix it.  Some forum thread
suggested disabling in the BIOS.  I don't know if I can.  BRB.

Nope, no option for that.  Probably will have to fix the hardware fault, or
disconnect it.

*** CapsLock as ctrl + escape
Can't live without it.

That's built-in in my desktop keyboards.  At least the Ctrl part.  Here I have
to tell Xorg to do it with:

: localectl --no-convert set-x11-keymap us colemak colemak ctrl:nocaps

the last part.

I could setxkbmap that in my xinitrc, but I'd rather have it as a system
default.  Even though it means not having it in a dotfile somewhere.  But that's
system specific anyway.

~xcape~ takes care of turning taps into escape.  Just have to install it, as
it's in AUR.

Installing cower, missing a PGP key.  Solution is [[https://bbs.archlinux.org/viewtopic.php?id=152337][here]]:

: gpg --list-keys
: echo 'keyring /etc/pacman.d/gnupg/pubring.gpg' >> ~/.gnupg/gpg.conf

Or, run makepkg with --skippgpcheck.

xcape doesn't work when run from .xinitrc.  Hmm.

Ah no, it does work, but only after hitting the Ctrl key once.  After that, it
treats CapsLock as a Ctrl as well.  If I never hit the Ctrl_L key, it won't pick
up the CapsLock as Ctrl.  Annoying.  Maybe if I remap CapsLock through xmodmap
it will pick it up.  Might come back later to it, but for now the workaround is
good enough.

*** Touchpad
At first, the touchpad had the surprising behavior of resetting the pointer
position to the middle of the screen every time I put my finger on it.  Simply
installing libinput fixed it.

But, that's not all.  I want taps to register as clicks.  man libinput, and add
the adequate options to /etc/X11/xorg.conf.d.

There are a couple of lingering warnings in dmesg.  From a quick search, they
seem harmless.

*** Xorg tips
I used to set the keyboard delay and rate through startx directly because xset
settings could be reset.  But I can also put it in
/etc/X11/xorg.conf.d/00-keyboard.conf to avoid repeating it.

Wait no, it doesn't work.  WTH.  Oh, that option was actually removed.  Well,
sticking to aliases it is then.

*** Fonts
Fira Sans is nice, but it hints pretty badly on small sizes (8px).  And without
hinting, antialiased fonts are blurry.  Noto scales well.

* [2016-12-25 dim.]
** ArchLinux with z13 cont.                                            :arch:
*** systemd-backlight service
This is supposed to save and restore the brightness on sleep/reboot.  I never
had this working before, and always had the screen brightness set to
burn-my-retina level.  No more!

The service is enabled by default.  But without the proper kernel setting, it
saved the wrong backlight under /sys/class/backlight (there were two of those,
one that was ineffectual).  So, toying with the acpi_backlight kernel option,
one managed to leave only one folder under /sys/class/backlight, and then it
worked.

In /etc/default/grub:

: GRUB_CMDLINE_LINUX_DEFAULT="acpi_backlight=native"

that's the ticket.

*** Xmodmap
The ctrl:nocaps option of X11 is not enough in combination with xcape, since
apparently xcape does not pick up caps lock as an additional control after I hit
the original Ctrl_L key.

Maybe by remapping the key in xmodmap directly?

And while I'm at it, I should move my volume/brightness keys bindings to Xmodmap
rather than i3.

Hmm remapping in xmodmap is picked up by xcape, but not as a modifier.  Maybe I
should leave the ctrl:nocaps option after all.

Ah!  It works.  Great.

For the other keys, well it appears I have to use xbindkeys to make the config
i3 agnostic.  But since I'm using i3 for the moment, might as well leave them
there.

*** Fontconfig nightmare
Well, I can get Noto as a default sans and serif font, but installing Fira Mono
*will* fuck up the italic for Dina in Emacs.  That's weird.

Well okay, I don't really care about Fira Mono in Firefox.  So... installing
ttf-dejavu gives me a mono font in Firefox, but *does not* fuck up Dina.  Sold.

*** Auto-connect to known wifi networks
That's [[https://wiki.archlinux.org/index.php/Netctl#Automatic_switching_of_profiles][documented]].  Just enable the netctl-auto service and good to go.  I think
there's a slight delay before I get an IP adress, but maybe there's a way to get
feedback on that in i3status.

One issue though is that disabling and re-enabling the wifi can fail if the wlan
interface was already up.  The workaround is to add the Force-Connect=yes option
to the netctl profile, though that's not the preferred course of action.

* [2016-12-30 ven.]
** (Puzzle) game ideas                                              :tangled:
Untangling a graph.  Generate a random planar graph and shuffle the node
positions.  Player can move nodes around.  Goal is to have no edges overlapping
each other.

Variant: instead of total freedom, nodes can only go in predefined positions.

* [2017-01-04 mer.]
** Prototype puzzle game                                            :tangled:
I built a prototype.  It works on tablet, but not as fast as I would like it
to.  50fps on tablet and lower on the phone.  On top of that, there are hiccups
caused by GC pauses.  For just displaying four nodes... sigh.

I tried to use pixijs, since it is supposedly fast, and will autodetect which
renderer to use (WebGL or Canvas).  Well, it's slower than using the canvas
directly.  On the phone, it picks up WebGL and gets 10fps.  Also, it even with
the antialias option to true, circles are not as nice as using canvas.

I might get more mileage out of not redrawing everything every frame.

** Related game                                                     :tangled:
Looking around, there seems to be plenty of similar games:

http://johntantalo.com/wiki/Planarity/
https://www.jasondavies.com/planarity/planarity.js
https://github.com/JoyJing1/Planarity

Though they all perform poorly on mobile.

** Fixed failing tests in flycheck ERT suite                       :flycheck:
Making a note here: ERT failures are not very readable.  A simple diff would be
better.

** Writing an Emacs module in Rust                                    :emacs:
Should be possible with Emacs 25.

There is a [[https://github.com/janestreet/ecaml][library for OCaml]], and a [[http://diobla.info/blog-archive/modules-tut.html][tutorial for C]].

Problem is, native modules are disabled in the default Emacs build, so most
users would not benefit from them without going through the trouble of building
their own Emacs.

* [2017-01-05 jeu.]
** DONE Merge the flycheck/refactor-rust-cargo branch        :flycheck:cargo:
CLOSED: [2017-02-15 mer. 14:28]
Or find out why it was blocked.

Even if the flycheck-rust branch is not ready to automatically fill the
variables, the checkers should work with benches and tests targets.

*** [2017-02-03 ven.]
It was blocked by [[https://github.com/rust-lang/cargo/issues/3390][cargo#3390]].  The fix has landed in rust 1.15, so I should be
able to merge now.

** Finding a way to test Flycheck with multiple versions of external tools :flycheck:
I've updated the tests to pass with the latest GHC (8.0) for instance, but what
about support for versions < 8.0?

If we don't test those regularly, we will break them.

Historically, flycheck makes no guarantees to keep supporting tool versions (you
can always not update flycheck).  But while that is convenient for maintaining
flycheck (keeps from accumulating cruft), it might not be convenient for users.

If there's a way to keep maintaining multiple versions of major languages, we
should try.  We would need a clear story on deprecating language versions
though.

Investigate how to test multiple versions: Docker image?  CI?

As a first step, I opened an issue to know if best-effort backward-compatibility
was something we wanted.

** Finding out why help window does not behave the same as in stock Emacs :emacs:
Help windows are always tiny and on the bottom in Spacemacs.  This is annoying
since I usually want to read all of more than a few lines if I'm calling the
help.  It does the same thing for explain error buffers for flycheck-rust as
well.

The always-helpful Emacs manual has many things to tell me.

Apparently, help buffers activate the ~temp-buffer-resize-mode~, which /should/
resize itself to match the output, but that does not appear to have any effect.

Haha!  Looking through the Spacemacs source, it seems that the ~popwin~ package
is the culprit.  It's a package to manage pop-up windows, like the Help buffer.
Disabling this package in Spacemacs gives me larger help windows.

But, it's still not the stock Emacs behavior.  In Emacs, if I call
explain-error, it will split the window horizontally since I have a wide screen.
If there frame is too small, it will split vertically.  In Spacemacs, it
always splits vertically.

Hmm, seems ~(split-window-sensibly)~ is the cause.  It can be tweaked using
variables as stated in its help.

Ahh okay, even though the threshold values are the same from stock, I'm not
using the same font, so I have more lines on the screen.  In stock, calling
~split-window-sensibly~ repeatedly never split vertically, since I never had 80
lines available.  With the bitmap font, I have 89 lines, and it splits
vertically first, then horizontally.

But wait, popwin in Spacemacs was configured only for ~*Help*~ buffers, not
error explanations...  Ahh, loading the flycheck layer actually adds the
incriminating line:

: ("^\\*Flycheck.+\\*$" :regexp t :dedicated t :position bottom :stick t :noselect t)

so any buffer matching the regexp will be managed by popwin.  If I remove only
that line, it behaves as expected.

Also, turning on ~temp-buffer-resize-mode~ will fit the window to the buffer
content, which is especially helpful for error explanations.

Except, curiously, for the error list.  Calling manually
~resize-temp-buffer-window~ inside works, but it pops up taking half the
screen.

Ah, that stems from that fact the error list is not temporary.  It is created
using ~pop-to-buffer~.  I think I can customize ~display-buffer-alist~ to
autofit it.

Nope, it seems the list is not populated in one go.  Ah, but there's a hook
after it has finished refreshing.

The hook does not run /inside/ the error list window, but I can select it in the
hook.

Ahah!  Victory!

Time to call it quits.  I should timestamp my paragraph as well.  These
inquiries take /hours/.

* [2017-01-06 ven.]
** Displaying errors from other files in Flycheck                  :flycheck:
Mentoring someone who volunteered to pick up the work from the previous PR.

After reading the discussion in that PR, it seems there were potential lingering
issues, especially concerning the :buffer and :filename fields of the
flycheck-error struct.  @lunaryorn was concerned that the changes would
highlight all errors in the current buffer, regardless of the file they come
from.  @chrisdone claimed it worked for Haskell mode.

Testing with Rust... ok, I get a new column in the error list with the filename
for the error.  But trying to go to the errors in the other file will jump in
the current buffer, and syntax highlight errors that are not there (since they
are in the other file).  That's indeed what @lunaryorn reported.

Let's test this in stock Emacs to make sure Spacemacs is not interfering
somehow.  Same thing.

Now let's see the code.

Okay.  I don't know how the Haskell checker creates its errors, but the Rust
checker will associate errors to the buffer that invoked it.  That means, errors
from the whole project will be associated with the current buffer.  Though they
will have the different filenames.

Now, in ~flycheck-jump-to-error~, we will jump to the buffer associated with the
error if it exists.  That's why we end up jumping in the same buffer, instead of
opening up the file associated with the error.

Hmm, the haskell checker uses the :error-patterns to build its flycheck-errors.
What is the buffer value in this case?  Apparently, the error is created in
~flycheck-try-parse-error-with-pattern~, and it doesn't give any value for
:buffer.  But it uses the constructor ~flycheck-error-new-at~, which uses
~(current-buffer)~ as the default value.  So it should work the same as for
Rust... weird.

Anyway, the :buffer property of a flycheck error is the buffer that ran the
checker, not necessarily the buffer associated with the file where the error
resides.  It seems wrong to reuse this value to find the location of the error.

The filename is the more sensible choice.  But recall that an Emacs buffer is
not necessarily associated with a filename, and the same file could have
multiple buffers open.  Regardless, if we have one buffer associated with the
file, switch to it.  If not, open the file in a new buffer and switch to it.

When this works, there is the question of maybe not calling cargo for every
buffer if we already have errors ... but it may be an optimization for another
PR.

That's an interesting feature, but it may not sit well with the way Flycheck
works.  I'm especially worried about the interaction with flycheck instances in
other buffers.

* [2017-01-09 lun.]
** Cross-compiling rust binaries                                       :rust:
Now that rustup is the official way to get rust, it means I might be able to get
around the cross-compilation rust bug I encountered last time I tried.

So, removing rust and cargo from Arch packages... Ah, rustup /is/ in Arch now,
so better use that than ~curl | sh~.

Trying to build chipers with:

: rustup target add x86_64-pc-windows-msvc
: rustup run stable cargo build --release --target=x86_64-pc-windows-msvc

Nope:

#+BEGIN_EXAMPLE
running: "c++" "/nologo" "/MD" "/O2" "/Fo/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-msvc/release/build/imgui-sys-7f10381dd17cf63f/out/third-party/cimgui/cimgui/cimgui.o" "/c" "third-party/cimgui/cimgui/cimgui.cpp"
cargo:warning=c++: error: /nologo: No such file or directory
cargo:warning=c++: error: /MD: No such file or directory
cargo:warning=c++: error: /O2: No such file or directory
cargo:warning=c++: error: /Fo/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-msvc/release/build/imgui-sys-7f10381dd17cf63f/out/third-party/cimgui/cimgui/cimgui.o: No such file or directory
cargo:warning=c++: error: /c: No such file or directory
ExitStatus(ExitStatus(256))
#+END_EXAMPLE

Hmm, seems that cargo tries to pass windows-style arguments to ~c++~, and that
fails.

The error appears when trying to build imgui-sys, which has a custom build
script.

Okay, let's try the other win64 target using the GNU toolchain.

: rustup target add x86_64-pc-windows-gnu
: rustup run stable cargo build --release --target=x86_64-pc-windows-gnu

#+BEGIN
running: "x86_64-w64-mingw32-g++" "-O3" "-ffunction-sections" "-fdata-sections" "-m64" "-o" "/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/release/build/imgui-sys-7f10381dd17cf63f/out/third-party/cimgui/cimgui/cimgui.o" "-c" "third-party/cimgui/cimgui/cimgui.cpp"


failed to execute command: No such file or directory (os error 2)
Is `x86_64-w64-mingw32-g++` not installed?
#+END_EXAMPLE

According to archwiki, this is normal.  Just install mingw-64-gcc.

#+BEGIN_EXAMPLE
  = note: /usr/bin/ld: unrecognized option '--enable-long-section-names'
/usr/bin/ld: use the --help option for usage information
collect2: error: ld returned 1 exit status
#+END_EXAMPLE

Ah, this is unexpected.  Let's try to follow the archwiki again, which instructs
us to specify the linker in ~/.cargo/config.

#+BEGIN_EXAMPLE
/build/mingw-w64-crt/src/mingw-w64-v5.0.0/mingw-w64-crt/secapi/vsprintf_s.c:39: undefined reference to `__ms_vsnprintf'
/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/release/deps/libimgui_sys-09713921de9d394a.rlib(cimgui.o):cimgui.cpp:(.text$igGetColorU32+0x1): undefined reference to `ImGui::GetColorU32(int, float)'
/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/release/deps/libimgui_sys-09713921de9d394a.rlib(cimgui.o):cimgui.cpp:(.text$igGetColorU32Vec+0x1): undefined reference to `ImGui::GetColorU32(ImVec4 const&)'
/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/release/deps/libimgui_sys-09713921de9d394a.rlib(imgui.o):imgui.cpp:(.text$_ZL34ImeSetInputScreenPosFn_DefaultImplii+0x1e): undefined reference to `ImmGetContext'
/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/release/deps/libimgui_sys-09713921de9d394a.rlib(imgui.o):imgui.cpp:(.text$_ZL34ImeSetInputScreenPosFn_DefaultImplii+0x40): undefined reference to `ImmSetCompositionWindow'
#+END_EXAMPLE

Better, but not there yet.  Let's try... cargo update and rebuild?  Same thing.

Without ~--release~?  Maybe the symbols disappear because of an optimization.

#+BEGIN_EXAMPLE
/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libimgui_sys-09713921de9d394a.rlib(imgui.o): In function `ImeSetInputScreenPosFn_DefaultImpl':
/home/fmdkdd/.cargo/git/checkouts/imgui-rs-161fde41895667b9/e60e5161c5fd5142b6e776e37f57fc485b684ba7/imgui-sys/third-party/cimgui/imgui/imgui.cpp:9573: undefined reference to `ImmGetContext'
/home/fmdkdd/.cargo/git/checkouts/imgui-rs-161fde41895667b9/e60e5161c5fd5142b6e776e37f57fc485b684ba7/imgui-sys/third-party/cimgui/imgui/imgui.cpp:9579: undefined reference to `ImmSetCompositionWindow'
collect2: error: ld returned 1 exit status
#+END_EXAMPLE

Haha, it found GetColorU32 for some reason, but not the others.

So it looks like a hairy linking issues with missing or mismatched libraries.

Maybe it's not possible to build cimgui using mingw?  But that's only part of
the problem; the ~__ms_vsnprintf~ is also worrying since it's unrelated to the
compilation of Imgui.

Looking through the code and ImGui issues, [[https://github.com/ocornut/imgui/issues/738][this one might be related]].  How do I
pass that flag?

Trying out the i686 target... it's worse.  Now it fails to link pthreads.

Maybe I can set the flag directly in the source and recompile everything after
~cargo clean~.  Hopes it picks it up (and that it solves /that/ issue at
least).  Starting to doubt it's worth it...  But.  I have to train my grit.

Okay setting the flag in imconfig.h does not have effect.  Let's try commenting
the code out in imgui.cpp.  Ah, as I suspected, changing the source does not
affect the error.  It's still choking on an undefined reference to a symbol
that's not even in the source anymore!  So where are you getting your code,
cargo, hmm?

Let's see, the command that runs is this monstrosity:

#+BEGIN_EXAMPLE
"/usr/bin/x86_64-w64-mingw32-gcc"
"-Wl,--enable-long-section-names" "-fno-use-linker-plugin" "-Wl,--nxcompat" "-nostdlib" "-m64"
"/home/fmdkdd/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-pc-windows-gnu/lib/crt2.o"
"/home/fmdkdd/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-pc-windows-gnu/lib/rsbegin.o"
"-L" "/home/fmdkdd/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-pc-windows-gnu/lib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/chipers.0.o"
"-o" "/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/chipers.exe"
"-Wl,--gc-sections" "-nodefaultlibs"
"-L" "/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps"
"-L" "/home/fmdkdd/.cargo/registry/src/github.com-1ecc6299db9ec823/dbghelp-sys-0.2.0/x86_64"
"-L" "/home/fmdkdd/.cargo/registry/src/github.com-1ecc6299db9ec823/dwmapi-sys-0.1.0/x86_64"
"-L" "/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/build/imgui-sys-7f10381dd17cf63f/out"
"-L" "/home/fmdkdd/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-pc-windows-gnu/lib"
"-Wl,-Bstatic" "-Wl,-Bdynamic"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/librand-8ea7d489d4a383a0.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libtime-750bfdd52feafcb7.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libdocopt-664aa2a6d9ccf7ca.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libstrsim-5346333e54880be8.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/librustc_serialize-6b938435173797f7.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libimgui-918c9f0a49f6af9f.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libimgui_sys-09713921de9d394a.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libglium-daf79273501e0d39.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libsmallvec-cf4677c7857fc4a9.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libbitflags-0e272044714c8076.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libregex-36c8e259ac5ba542.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libutf8_ranges-5c6a6dacba3be7ce.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libregex_syntax-6602c4e3d91326a4.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libthread_local-a3c0092e9fb6507d.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libbacktrace-dffaf784d6265843.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/librustc_demangle-9f84838926c47318.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libcfg_if-72c1f992b13d5087.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libdbghelp-72843bd5c387f78b.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libaho_corasick-d1dfd931d7cac82f.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libmemchr-c555f740a543880f.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libglutin-e21168db28d54279.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libdwmapi-b7b4ef7bb14c9654.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libgdi32-37f11392e9ac4edd.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libshell32-1cd19799b8066c32.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libshared_library-94c5183073084fbf.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/liblibc-e1db4c5f3a4f3c2f.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/liblazy_static-7f1b96a3a3eb529d.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libthread_id-bcd46c79a620a618.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libkernel32-df86a08647459244.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libuser32-ab4e7be30af20d1b.rlib"
"/home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/debug/deps/libwinapi-0889532d327ff4e2.rlib"
"/home/fmdkdd/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-pc-windows-gnu/lib/libstd-f5a209a9.rlib"
"/home/fmdkdd/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-pc-windows-gnu/lib/libpanic_unwind-f5a209a9.rlib"
"/home/fmdkdd/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-pc-windows-gnu/lib/libunwind-f5a209a9.rlib"
"/home/fmdkdd/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-pc-windows-gnu/lib/liblibc-f5a209a9.rlib"
"/home/fmdkdd/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-pc-windows-gnu/lib/librand-f5a209a9.rlib"
"/home/fmdkdd/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-pc-windows-gnu/lib/libcollections-f5a209a9.rlib"
"/home/fmdkdd/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-pc-windows-gnu/lib/liballoc-f5a209a9.rlib"
"/home/fmdkdd/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-pc-windows-gnu/lib/liballoc_system-f5a209a9.rlib"
"/home/fmdkdd/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-pc-windows-gnu/lib/librustc_unicode-f5a209a9.rlib"
"/home/fmdkdd/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-pc-windows-gnu/lib/libcore-f5a209a9.rlib"
"/home/fmdkdd/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-pc-windows-gnu/lib/libcompiler_builtins-f5a209a9.rlib"
"-l" "advapi32" "-l" "stdc++" "-l" "dbghelp" "-l" "opengl32" "-l" "dwmapi" "-l" "gdi32" "-l" "shell32" "-l" "kernel32"
"-l" "user32" "-l" "ws2_32" "-l" "userenv" "-l" "shell32" "-l" "advapi32" "-l" "gcc_eh" "-lmingwex" "-lmingw32" "-lgcc"
"-lmsvcrt" "-luser32" "-lkernel32"
"/home/fmdkdd/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-pc-windows-gnu/lib/rsend.o"
#+END_EXAMPLE

(I broke it up for readability).

So I guess imgui-sys is compiled in target/pc/debug/deps, and
target/pc/debug/build/imgui-sys/out is also added on lib path.  What's in that?
The libcimgui.a static library.  But when is it built?  And from what sources?

It seems the ~output~ file in there is a log of the custom compilation for
imgui-sys.  It looks for imgui.cpp under... a relative path.  Damn.

I actually have two checkouts of imgui-rs under .cargo/git/checkouts.  The one
I've been modifying was the one given to me by ~locate~.  But I also updated the
Cargo.lock, so maybe the second checkout is the most recent one, not yet in the
locate db?

Haha yes!  That does it.  It's not pretty, since I have to toggle a flag inside
directly.  There may be a way to pass that flag from imgui-sys, but maybe that's
a bug for cimgui itself, since it doesn't appear to compile with mingw.

#+BEGIN_EXAMPLE
  = note: /usr/lib/gcc/x86_64-w64-mingw32/6.2.1/../../../../x86_64-w64-mingw32/lib/../lib/libmsvcrt.a(lib64_libmsvcrt_a-vsprintf_s.o): In function `_int_vsprintf_s':
/build/mingw-w64-crt/src/mingw-w64-v5.0.0/mingw-w64-crt/secapi/vsprintf_s.c:39: undefined reference to `__ms_vsnprintf'
#+END_EXAMPLE

Now only one error to go...

This one is worrying, because I'm not sure I will be able to fix it as easily,
unless rebuilding libmsvcrt from source, which at that point I really don't want
to do.

If it's a linking error, then I'm just not loading the right library.  Where is
that symbol?

That functions is declared in /usr/x86_64-w64-mingw32/include/stdio.h:

: $ rg ms_vsnprintf /usr/x86_64-w64-mingw32/include
: /usr/x86_64-w64-mingw32/include/stdio.h
: 553:  int __cdecl __ms_vsnprintf(char * __restrict__ d,size_t n,const char * __restrict__ format,va_list arg)
: 560:    return __ms_vsnprintf (__stream, __n, __format, __local_argv);
: 573:  __retval = __ms_vsnprintf (__stream, __n, __format, __local_argv);

In libmsvcrt, the symbol is undefined:

: $ x86_64-w64-mingw32-nm /usr/x86_64-w64-mingw32/lib/libmsvcrt.a | rg ms_vs
: 16415:                 U __ms_vsnprintf

Hmm okay, so it's coming from somewhere else.  I see that the linking command
above is disables default libs: "-nostdlibs", "-nodefaultlibs".  Maybe one is
missing there?

Removing ~-nodefaultlibs~ does not make a difference.  Removing ~-nostdlib~, I
have multiple definitions clashing.

So where is __ms_vsnprintf ultimately defined?

Turns out, I can use ~nm~ to look it up!

: x86_64-w64-mingw32-nm /usr/x86_64-w64-mingw32/lib/* | rg '(^lib)|(ms_vs)'

The symbol is defined in libmingwex.a.  Let's try that huge command again with
that library (fingers crossed)... wait.  There's already ~-lmingwex~ in there.

Actually, there are "user32" "shell32" and "kernel32" appear multiple times as
well...

So, swapping "lmingwex" at the end of the loaded libraries triggers many
undefined references... this is order dependent, apparently I forgot (or never
knew?).

Adding "lmingwex" at the end, but leaving the one before "lmingw32" gives me
another (different) error:

: /usr/lib/gcc/x86_64-w64-mingw32/6.2.1/../../../../x86_64-w64-mingw32/lib/../lib/libmingwex.a(lib64_libmingwex_a-vsnprintf.o): In function `__ms_vsnprintf':
: /build/mingw-w64-crt/src/mingw-w64-v5.0.0/mingw-w64-crt/stdio/vsnprintf.c:12: undefined reference to `_vsnprintf'

Haha.  Let me guess where _vsnprintf is defined... lmsvcrt?

: $ x86_64-w64-mingw32-nm /usr/x86_64-w64-mingw32/lib/libmsvcrt.a | rg vsn
: 1613:0000000000000000 T vsnprintf

Circular dependency.  But, apparently adding "-lmsvcrt" one more time does it.
So in the end I load:

: "-l" "advapi32" "-l" "stdc++" "-l" "dbghelp" "-l" "opengl32" "-l" "dwmapi" "-l" "gdi32" "-l" "shell32" "-l" "kernel32"
: "-l" "user32" "-l" "ws2_32" "-l" "userenv" "-l" "shell32" "-l" "advapi32" "-l" "gcc_eh" "-lmingwex" "-lmingw32" "-lgcc"
: "-luser32" "-lkernel32"  "-lmsvcrt" "-lmingwex" "-lmsvcrt"

That's bit ridiculous.  But also logical [[https://stackoverflow.com/questions/45135/why-does-the-order-in-which-libraries-are-linked-sometimes-cause-errors-in-gcc#409470][if you read up on how ld works]].  But IT
COMPILES.

I don't know how to tell cargo to actually use these flags.  Maybe worth
inquiring.  But now I have an exe.

Running on windows... it needs libstdc++6.dll.  WTF!  I thought that the
"nostdlib" flag was here on purpose, to avoid a runtime requirement.  Guess I
was wrong.

Okay, now to get that dll without going through a shady website...  The windows
mingw installer does not work on wine x_x.  Let's try something else.  Msys
bundles mingw, apparently.  Msys installer fails at 66%.  This is testing my
patience.

Trying with a DLL from QEmu, which seems to be libgcc, but not exactly named as
I want it to be.  Bah, as long as defines the symbols...

Oh wow it runs.  But it crashes with an undefined reference a bit later.  [[https://stackoverflow.com/questions/329059/what-is-gxx-personality-v0-for/329195#329195][This
ref]].  Hmm exceptions.

Wait a minute.  I dropped the ~--release~ flag when tinkering, so maybe I still
have the exception library shared, and that does not work when cross-compiling
right now.  Let's try a release binary.

F*ck:

: /home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/release/deps/libimgui_sys-09713921de9d394a.rlib(cimgui.o):cimgui.cpp:(.text$igGetColorU32+0x1): undefined reference to `ImGui::GetColorU32(int, float)'
: /home/fmdkdd/proj/chipers/target/x86_64-pc-windows-gnu/release/deps/libimgui_sys-09713921de9d394a.rlib(cimgui.o):cimgui.cpp:(.text$igGetColorU32Vec+0x1): undefined reference to `ImGui::GetColorU32(ImVec4 const&)'

That's why I dropped the release flag.  It's strange I have undefined references
in one instance but not the other.  Is an optimization kicking in?  Well anyway,
I'm seeing an "lstdc++" in the linking command, so there are chances it will
need libstdc++6 in the end.

Since the wine error is actually a missing reference, let's add it in imgui.cpp
(since I already have a C file).

: void *__gxx_personality_seh0;

It's dirty, since this error has nothing to do with imgui or cimgui, but if it
works...

: wine: Call from 0x7bc5f96c to unimplemented function libstdc++-6.dll.__gxx_personality_seh0, aborting

Weeeeeeeeeeeell.  It doesn't complain about that missing symbol anymore.  But it
still fails with a stack overflow.  Trying on windows instead of wine... worse,
it complains about another missing symbol, cxa_guard something.

So, still no success cross-compiling.  Might have been faster spinning a Windows
VM and building the thing from there (maybe even with wine).

* [2017-01-10 mar.]
** Cross-compiling Rust to Android                                     :rust:
Because yesterday's struggles were not enough to turn me trying crazy
experiments.  Well, not that crazy.  There are tutorials for what I'm trying to
do.

Anyway.  My puzzle game on JavaScript lags unacceptably on Android.  With the
hardware that my mobile devices possess, I wonder how much performance I can get
if I eschew the browser and launch a binary directly.

Hopefully I /can/ run a Rust binary in developer mode without having to root the
device first.  Let's see.

I'll try [[https://github.com/tomaka/android-rs-glue][cargo-apk]], as it seems promising.  Have to download and install a bunch
of stuff for building on Android...

Grmbl, trying to compile space-bang-bang, but for some reason I fails to load
the ship.stl file, even though the path is correct.  The only way to make it
load the file is to run cargo from the src directory.  Well, going back to
hardcoded meshes to test the APK.

Also, commenting out imgui because it requires string.h that the g++ does not
find...

: BUILD FAILED
: /opt/android-sdk/tools/ant/build.xml:538: Unable to resolve project target 'android-18'

Okay, I admit I did not follow the howto for cargo-apk to the letter, preferring
to follow the archwiki on Android in parallel because I don't want to pollute my
home folder with this stuff.

Anyway, it looks like I don't have the tools needed to build the 18 revision of
the Android API.  Maybe installing the android-platform-18 from AUR will
suffice.  Otherwise, I can do android update sdk -u, but it seems to fetch /all/
revisions.

Okay, that seems to do it.  What's next?

: [aapt] /home/fmdkdd/proj/asobiba/rust/space-bang-bang/target/android-artifacts/build/bin/AndroidManifest.xml:3: Tag <manifest> attribute package has invalid character '-'.

Hmmmmmmm.  Looking at the manifest, the culprit must be the project name:

: package="rust.space-bang-bang"

Okay.  If I remove these dashes from the package name in Cargo.toml... it works!

Now, to load it on the tablet.  After ~adb install~, I have a ~spacebangbang~
app I can run.

Black screen.

Okay that's not encouraging.  Maybe a debugger would help here.

: $ adb logcat
: RustAndroidGlueStdouterr: thread 'main' panicked at 'not yet implemented', /home/fmdkdd/.cargo/registry/src/github.com-1ecc6299db9ec823/glutin-0.6.1/src/api/egl/mod.rs:497

Oh.  Let's try updating the dependencies, maybe glutin will pick up the pace.
Otherwise I will try building a simpler app using gfx-rs, since that was
reported to work.

Updating does not change.  Looking at the source, this is still unimplemented in
master.  But what is that feature exactly?  It seems it tries to build an
unsupported OpenGLEs version.  It should work for versions 1, 2 and 3, but fail
otherwise.

Let's try to request a specific version.

Okayy, turns out OpenGL/ES does not exactly use the same shader language as
OpenGL.  There are subtle differences, and of course the version correspondence
is a mess ([[https://github.com/mattdesl/lwjgl-basics/wiki/GLSL-Versions][this]] is useful).  Am tempted to use an engine rather than deal with
this mess.  But, now that I've got the thing running on my desktop, with
OpenGL/ES specified, let's try on Android one more time.

Ahah! It works.  Well, Glium still triggers an error, but I've got a spaceship
on screen now.

So let's try to build that graph puzzle again, but maybe using gfx-rs this time.

** Rust tangled an Android                                          :tangled:
Actually, I may not need gfx-rs for tangled.  I just need to draw in 2D.  That
might be easier just using SDL2 directly.

Let's see.  Wow, the sdl2 crate compiles much faster than glium.  Nearly
instantaneous to have a window after ~cargo run~.

Now ~cargo apk~.

: error: cannot find -lSDL2

Duh.  [[https://github.com/AngryLawyer/rust-sdl2/issues/526][Have to]] compile it myself for the target, apparently.  Let's try!

: wget libsdl
: tar; cd
: ndk-build NDK_PROJECT_PATH=. APP_BUILD_SCRIPT=./Android.mk APP_PLATFORM=android-18

Now I've got the libSDL2.so for the android platforms.

: cp libs/armeabi/libSDL2.so ~/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/arm-linux-androideabi/lib/

It builds.

Now to run:

: RustAndroidGlueStdouterr: thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: "Application didn\'t initialize properly, did you include SDL_main.h in the file containing your main() function?"', ../src/libcore/result.rs:837

Looks like the android-glue might not work with SDL2 out of the box.  It looks
like SDL2 has support for Android though, and even provides an android project
template to wrap your C code in a Java app.

Seems the SDL template project implements a bunch of stuff in Java however.
Grmbl I don't see an easy way out of that.  Maybe I should try to gfx-rs after
all.

With gfx, it compiles without troubles.  But:

:  RustAndroidGlueStdouterr: thread 'main' panicked at 'not yet implemented', /home/fmdkdd/.cargo/registry/src/github.com-1ecc6299db9ec823/glutin-0.7.2/src/api/egl/mod.rs:497

We are running in circles here.

Trying to copy [[https://github.com/ozkriff/zoc][ZOC]], because reportedly it builds and runs on Android.  There are
gotchas with the shader version, but luckily he uses only basic shaders.

Also, passing the GlRequest::Specific to glutin seems to fail.  He uses
GlRequest::GlThenGles so at least it runs using OpenGL on my desktop.  And on
android it should use ES.

: RustAndroidGlueStdouterr: thread 'main' panicked at 'gl function was not loaded', /home/fmdkdd/proj/asobiba/rust/tangled/target/arm-linux-androideabi/debug/build/gfx_gl-f278bd537d4e476a/out/gl_bindings.rs:1479

Okayyy.  Well, gfx-rs is no better than glium then.  At least I /got/ glium to
work.  Let's use glium instead then.

Yes!  No errors!

* [2017-01-12 jeu.]
** Android app sometimes runs, sometimes doesn't                    :tangled:
When it doesn't, I just have a black screen.  Restarting the app seems to do it.
I'm suspecting that I should watch for 'resume' events, as launching an Android
app is not like running a program in the shell.  Or rather, one does not simply
terminate an Android app.

Okay so looking at the given example for NativeActivity, it seems I have to do
some cleanup of the EGL context depending on events.  But, even if I comment out
all the glium and glutin related code, the app will badly break if I run it,
exit, and run it again:

#+BEGIN_EXAMPLE
184:D/RustAndroidGlueStdouterr(13537): Creating application thread
196:D/RustAndroidGlueStdouterr(13537): thread 'main' panicked at 'assertion failed: (*ptr).is_none()', ../src/libstd/sys/unix/args.rs:83
197:D/RustAndroidGlueStdouterr(13537): note: Run with `RUST_BACKTRACE=1` for a backtrace.
198:D/RustAndroidGlueStdouterr(13537): fatal runtime error: failed to initiate panic, error 9
199:D/RustAndroidGlueStdouterr(13537): In mgmain JNI_OnLoad
#+END_EXAMPLE

which tells me that the Android target from Rust may not be very stable yet.

* [2017-01-13 ven.]
** MVP for Android puzzle game                                      :tangled:
I haven't managed to solve the crash on resume yet.  But, I want to see first if
I can get 60fps this way with a small graph.  If I don't, it's no use going
further in this route.

(Reminder: test debug and release performance)

Well, debug mode seems smooth enough to the eye.  Didn't time it, but it's fluid
and doesn't seem to suffer from hiccups.

Annoyingly, I get a glium error when trying to draw lines using the
PrimitiveType::LinesList.  It works in OpenGL, but not OpenGL/ES it seems.  Or
it a case not handled in Glium.

Anyway, it works, and it's rather fast.  Let's try some timings.

Yep, confirmed 60fps.  Not as steady as what I can get on the desktop though.
Sometimes 15, often 17.  But that's +- 1ms, so that's an acceptable variance.

Release mode is the same.

* [2017-01-18 mer.]
** Systemd and netctl are in a boat                                    :arch:
After a recent upgrade to systemd (I think it was to 232), I wasn't able to get
a working ethernet connection.  Fortunately, I could revert back to a previous
version using the pacman cache.

After a few weeks, I switched from systemd to netctl to manage the ethernet
connection.  This allowed me to upgrade systemd and everything was fine.

Except, my boot time went up.  Diagnosing with systemd-analyze revealed that
netctl took a few seconds at boot to setup the connection and get a dhcp lease
(presumably), while systemd did it asynchronously or something, and I never had
to wait.  This was annoying, but I had to suffer it once a day at most.

But then it hit me: I had had trouble with the MTU when setting up the ethernet
connection with systemd previously.  The default value of 1500 was not working
for some reason one day, and switching to 1480 fixed it.  Today, I tried to
switch back to systemd to manage the ethernet, and as before, it didn't work.
But, after removing the MTU override and using the default 1500, it went fine.

Booting is snappier now.  Well, except for pulseaudio taking a few seconds to
time out when trying to discover my USB midi keyboard when it's not plugged in.

But making a note here of the MTU trick.  When ethernet doesn't work, wiggle the
MTU.

* [2017-01-19 jeu.]
** Fixing pulseaudio slow startup                                      :arch:
So my midi keyboard /was/ plugged in all this time.  That's why pulseaudio
complained.  But, unplugging it unveiled that pulseaudio was just slow to start
up.

Now, I don't remember exactly why I installed pulseaudio in the first case.  It
might have been for running a Steam game.

Anyway, pulseaudio is able to start up on its own with autospawning.  That is
disabled by default in /etc/pulse/client.conf by Arch, but can be re-enabled
locally in .config/pulse/client.conf:

: autospawn=yes

Tested to work with mpd.  Now my login is below 1s.

Also, why did I use pulse with mpd?  Might as well use straight ALSA to avoid
running pulseaudio.

Yep, it works.

* [2017-01-22 dim.]
** Lifetimes, references and borrowing                                 :rust:
Having a hard time dealing with these for a seemingly straightforward use-case.

First, [[https://manishearth.github.io/blog/2015/05/17/the-problem-with-shared-mutability/][this post]] gives arguments as to why you still want a single mutable
reference in single-threaded code.  Iterator invalidation is the most common
counter-example.  Holding a mutable reference to a vec while iterating over it,
you can modify the vec while going through it and making things explode.

Reading the [[https://rust-lang.github.io/book/ch04-01-what-is-ownership.html][new book]] sections on ownership and lifetimes.  Ownership makes more
sense with the String example, where you can clearly see that copying the struct
part is only a shallow copy, and having multiple shallow copies around is a bad
idea.  That explains what 'moving' is: it's marking one shallow copy as owned,
and freezing the others.  From the example, I also get the sentiment that you
can safely make a struct Copy when it has no pointers to anything.  And indeed,
the documentation gives the advice to derive Copy whenever you could.

I don't think these sections have made entirely clear for me how lifetime
annotations interact with values.  For instance, [[https://internals.rust-lang.org/t/relaxing-the-borrow-checker-for-fn-mut-self-t/3256][someone suggested]] that the
following should pass borrow checking, since it's safe:

#+BEGIN_SRC rust
struct T {...}
impl T {
    pub fn mutate_and_return_immut_ref(&mut self) -> &Foo { ... }
    pub fn use_immutable(&self) { ... }
}

let mut t : T = T { ... };
let foo : &Foo = t.mutate_and_return_immut_ref();
t.use_immutable();
#+END_SRC

And indeed I don't see why there is a restriction there, and none of the
participants in the thread managed to exhibit a counter-example where allowing
this code would lead to unsafe behavior.

In fact, the thread ends with a [[https://stackoverflow.com/questions/38078936/borrowing-reference-in-structure/38080934][curious workaround]] from stackoverflow:

#+BEGIN_SRC rust
fn mutate_and_return_immut_ref(&mut self) -> (&Self, &Foo) {
  (self, &Foo { .. })
}

let (t2, foo : &Foo) = t.mutate_and_return_immut_ref();
t2.use_immutable();
#+END_SRC

This will compile, but it seems to go against the restriction of the first
snippet.  In the first snippet, the last line is disallowed by the borrow
checker because the reference ~foo~ is still in scope at the time of the last
call.

My understanding is that the call to ~mutate_and_return~, because of elided
lifetimes, will compute that the reference to ~mut self~ has the same lifetime
as the returned reference ~&Foo~.  Consequently, as long as ~foo~ is around,
~t~ is mutably borrowed.  Hence, the last call is forbidden, since it tries to
borrow ~t~.

In the second snippet, this is still the case.  But, since the call is made from
another reference to a T, it's fine.  Except, if I understand correctly, we are
in fact dealing with the same T; ~t == t2~.  That means the exact same call, on
the same object, is disallowed in one instance, but allowed in another.

** Transitions and ownership                                   :tangled:rust:
Been struggling with implementing Transitions as cleanly as possible.  The
problem is the way I do it in JS, is I hold a list of active transitions, and
each transition holds a reference to the object it modifies.

In Rust that means trouble, since I must hold a mutable reference for the
lifetime of the transition, ensuring that I can never do anything else with the
object.

I think it could work if I went with an ECS pattern.  But I'm not there yet.

I thought about letting the transition hold a /node index/ rather than a
reference to the node.  In fact, that's what I had at first.  But that's
obviously brittle if we move nodes around in the vector that holds them.  (But
in fact, I don't remove nodes actually, so it could be fine...).

On the topic of dealing with cycles in Rust, [[https://m-decoster.github.io//2017/01/16/fighting-borrowchk/][someone mentioned]] that you could
follow the same tactic as normalizing tables in relational algebra.  Here, a
node can have at most one transition, and a transition is tied to a node, so I
can in fact let the node /own/ the transition.  That way, the node updates the
transition, and can update its position after it.

That works, but it's still a pain fighting the checker for creating swapping
transitions, since it requires mutable references to two nodes, and the nodes
are inside a graph.

Still not satisfied.  Maybe I can clean up that, or try an ECS.

* [2017-01-27 ven.]
** RLS alpha, take two (three?)                                :rls:flycheck:
So let's try that again.

Got diagnostics to work now with latest RLS and latest lsp-mode from vibhavp.

Here's what's needed in .emacs:

#+BEGIN_SRC elisp
  (add-to-load-path "~/proj/vibhavp-lsp")
  (require 'lsp-mode)
  (setenv "RLS_ROOT" "/home/fmdkdd/proj/rustls")
  (global-lsp-mode t)
#+END_SRC

emacs-lsp takes care of running ~cargo run~ for you.  Except, of course, my
default cargo is stable, and the RLS requires nightly.  I tweaked the command to
add ~+nightly~ there.

Need to toggle the global-lsp-mode /before/ opening a Rust file.  Because that's
how it triggers the connection:

: (add-hook 'find-file-hook #'lsp-on-open)

Then, it asks whether to start a server.  Answer yes, and after some edit it
will gather diagnostics from the server.  Diagnostics are put in a hashtable,
but are not displayed right now.  I suppose the author will want to use flycheck
as a backend for displaying errors?  Or is the other way around, by defining a
flycheck-rust-lsp checker that communicates with lsp-mode?

Inspired by [[https://github.com/flycheck/flycheck-ocaml/blob/master/flycheck-ocaml.el][flycheck-ocaml]], I defined a generic flycheck checker that merely
reports the diagnostics collected by the lsp-mode.  When global-lsp-mode is
active, it will collect diagnostics from the RLS into an hashmap.  Whenever
flycheck decides to run the checker, we transform the diagnostics from the
hashmap into flycheck errors, and that's it.

It doesn't look like the RLS is particularly faster than using cargo at the
moment.  And it's (slightly) more involved to setup.  But, on flycheck's side,
it's a lot simpler to implement, since the communication is taken care of by the
LSP package.

For reference, so I don't have to keep this in my head, here is the life cycle
of the rust-lsp checker:

- enable flycheck-mode in a rust buffer
- select the rust-lsp checker

  At this point, flycheck should start the checker automatically according to
  the value of flycheck-check-syntax-automatically.  'idle-change' is the most
  likely to trigger a syntax check first.

- on syntax check, the ':start' function property of rust-lsp is called with a
  callback

  In rust-lsp, this function will just save the callback for later.

- When diagnostics have been received by lsp-mode, a hook defined by rust-lsp is
  called, where it transforms the diagnostics to flycheck-error objects and
  passes them to flycheck using the saved callback.

- With the list of flycheck-error objects, flycheck populates the error list,
  updates the overlays etc.

Ideally, since lsp-mode does all the interaction with the server, we would like
flycheck to simply update the overlays and error list whenever new diagnostics
are received by the LSP.  There's no mechanism at present in lsp-mode to signal
diagnostics, that's why I added a hook.

So ideally, flycheck wouldn't have to initiate a checker, as that would be done
by lsp-mode.  Currently, flycheck initiates a check on idle, and since the RLS
is a bit slow, waiting for the diagnostics works.  But if diagnostics arrive at
any other time, we won't get them.

Also, since the hashmap is never cleared by lsp-mode, it means that it's the RLS
that will report "no diagnostics" for a file.

* [2017-02-03 ven.]
** Merging rust-cargo branch with multiple targets                 :flycheck:
There was an issue with dependencies, and the fact that we did not pass
--error-format with RUSTFLAGS.  This can be fixed by using --message-format
instead.  But, --message-format is an option for ~cargo rustc~, not ~rustc~
directly, and the output of rustc is wrapped.

To use --message-format then, we need a slightly different parser for
rust-cargo, which unwraps the message and uses the previous rust parser.

After a bit of refactoring, this works as intended.  I can start brushing up the
multiple targets PR by rebasing on that.

Hmm, the previous behavior relied on ~cargo rustc~ to invoke the "default"
target when none is provided.  With my patch, the target type and name /must/ be
supplied.

I've added :enabled code to ensure we don't call the checker prematurely, and
:verify to inform the user in case of a wrong setup.

I should move the test-crate tests I had written for flycheck-rust in flycheck
proper, since they are more useful as integration tests.  To ensure we catch
errors when the crate type and binary name are properly setup.

That reminds me, I should have added one test to ensure error from dependencies
were correctly caught in the previous PR.  Not merged yet, so still time to do
it.

Done.  Had to modify the flycheck-ert helpers since I wanted to catch a
suspicious state, but that was not registered.

* [2017-02-05 dim.]
** Generating a trace of Flycheck to understand the whole flow     :flycheck:
I figure that using Edebug should do it.  As in, I could follow the code, look
at values coming in and out, and take note on the side of the most interesting
steps.

Problem: Edebug is barely usable with evil-normal-state.

I found a [[https://github.com/syl20bnr/spacemacs/pull/2398][somewhat promising PR]] that was abandoned without any answer.  Trying
it out...

Okay, micro-states are deprecated.  Should use transient-states instead.

Transient states are based on [[https://github.com/syl20bnr/spacemacs/pull/2398][Hydra]], whose documentation is ... not quite
friendly.

Anyhow, looking at examples in the spacemacs source, I manage to make it work.
The first time you enter an instrumented function.  Then, hitting any key
managed by Hydra makes the docstring disappear.

This is unlike the behavior I am witnessing in other transient states, and I
don't see how I am doing things differently.

Looking through the edebug source code, I found the culprit:
help:edebug-save-windows.  Set to nil, the bindings of the transient state are
kept on screen.

But now we do not exit the transient state when Edebug does.

Managed to exit by calling ~hydra-disable~ in the edebug-mode-hook, since the
hook is called at exit of the mode as well.

Last thing: Edebug indicates the current expression with an arrow.  In
Spacemacs, this arrow is invisible.

Hmm, looking at a vanilla Emacs, I remember this one wrong.  Edebug seems to put
arrows in the fringe instead.  And I know Spacemacs disable all fringy stuff.
Found the missing value in ~fringe-indicator-alist~ by looking at its value in
vanilla Emacs.

* [2017-02-06 lun.]
** Heisenbug in i3                                                  :arch:i3:
Cannot reproduce.  But I had it a couple of times with Emacs not getting focus
back after a short-lived application closes itself.

Might be related to: https://github.com/i3/i3/issues/2600

If I can reproduce I might reply to this thread.

** Exploring Flycheck process with Edebug                          :flycheck:
First of all, run Emacs in its own instance, since I cannot take notes on the
side while Edebug is running.  It steals input.

Instrument ~flycheck-buffer~, since I believe it's the entry point where the
magic happens.

On edit in a rust buffer, I fall into flycheck-buffer with the backtrace:

: flycheck-buffer()
: flycheck-buffer-automatically(save)
: flycheck-handle-save()
: run-hooks(after-save-hook)

But flycheck does not find any checker, since ~flycheck-get-checker-for-buffer~
returns nil.  This is because there isn't a checker in ~flycheck-checkers~ that
returned true for ~flycheck-may-use-checker~.  The conditions to use a checker
are:

: (and (flycheck-valid-checker-p checker)
:      (flycheck-checker-supports-major-mode-p checker)
:      (flycheck-may-enable-checker checker)
:      (or (null predicate) (funcall predicate)))

- valid-checker makes sure ~checker~ was defined with ~define-checker~:

  : (and (symbolp checker)
  :      (= (or (get checker 'flycheck-generic-checker-version) 0)
  :         flycheck-generic-checker-version)))

  Since ~define-generic-checker~ adds the property
  'flycheck-generic-checker-version, this is a way to ensure that arbitrary
  symbols are not passed as checkers.

  Also, this shows what checkers are: a bunch of properties put in a symbol
  under the 'flycheck' namespace.

  Curiously, valid-checker uses ~(get checker)~ instead of the dedicated
  ~(flycheck-checker-get)~, so the code that sets and gets this property does
  not quite match.

- supports-major-mode is self-explanatory: checks the buffer major-mode in the
  list of modes declared by the checker

- may-enable determines if the checker can be enabled

  : (shall-enable (and (not (flycheck-disabled-checker-p checker))
  :                (or (memq checker flycheck-enabled-checkers)
  :                    (null enabled)
  :                    (funcall enabled)))))

  - no if it has been explicitly disabled
  - yes if it is in flycheck-enabled-checkers
  - yes if :enabled is nil

    Curious.  :enabled is a function given at definition to checker, but the
    actual function put into the :enabled property on the checker symbol is a
    lambda that calls :enabled.  In other words, :enabled is never nil unless
    the checker has been altered after its creation.

    Looking at git blame, :enabled was [[orgit-rev:~/proj/flycheck/::bade2de5][added recently]] for eslint.  At first it
    there was no lambda.  Then [[orgit-rev:~/proj/flycheck/::bd33d6ea][some commits later]] the lambda was added to
    disabled a checker if its executable could not be found.

    (orgmode links to magit are delightful)

  - yes if the :enabled function says it should be

- finally the :predicate property, if present, determines whether the checker
  will be used.  The :predicate function, like :enabled is run in the
  working-directory for the checker.

So the first checker in flycheck-checkers that matches true for these condition
is selected, unless there is already a manually selected checker in
flycheck-checker.

Here flycheck-buffer was started automatically on idle, and no checker matched,
so errors are cleared and the 'no-checker status is reported.

Reporting status just calls hooks in flycheck-status-changed-functions, which by
default is empty.  Maybe this is for using Flycheck from another package?

Hmm seems I may be confusing things, as there are flycheck-status, and
flycheck-checker-status.  One is the status of flycheck itself, the other is for
checkers.

** Benchmark json-read vs json-read-string                         :flycheck:
As suggested by cpitclaudel.

Filled a buffer with a mix of JSON and plain text lines.

#+BEGIN_SRC elisp
(defun ~/read-str (str)
  (let ((objects nil)
        (json-array-type 'list)
        (json-false nil))
    (with-temp-buffer
      (insert str)
      (goto-char (point-min))
      (while (not (eobp))
        (when (memq (char-after) '(?\{ ?\[))
          (push (json-read) objects))
        (forward-line)))
    (nreverse objects)))


(defun flycheck-parse-json (output)
  "Return parsed JSON data from OUTPUT.

OUTPUT is a string that contains JSON data.  Each line of OUTPUT
may be either plain text, a JSON array (starting with `['), or a
JSON object (starting with `{').

This function ignores the plain text lines, parses the JSON
lines, and returns the parsed JSON lines in a list."
  (let ((json-array-type 'list)
        (json-false nil))
    (seq-map #'json-read-from-string
             (seq-filter (lambda (line)
                           (or (string-prefix-p "{" line)
                               (string-prefix-p "[" line)))
                         (split-string output "\n")))))

(defun fancy ()
  (let ((str (buffer-string)))
    (benchmark-run-compiled 100
      (flycheck-parse-json str))))

(defun raw ()
  (let ((str (buffer-string)))
    (benchmark-run-compiled 100
      (~/read-str str))))
#+END_SRC

Result for running three times, the raw and fancy functions above.

| test  | Run time (seconds) | # of GC pauses | Time of GC pauses (seconds) |
|-------+--------------------+----------------+-----------------------------|
| raw   | 5.3949537020000005 |              3 |         0.47090892299999965 |
| fancy |        6.399940678 |              3 |          0.4271344749999999 |
| raw   |         5.34557943 |              3 |          0.4363561350000005 |
| fancy |        6.890653127 |              3 |          0.4778678799999998 |
| raw   |         5.21638785 |              2 |         0.30012468800000036 |
| fancy |        7.052852691 |              4 |          0.6481165220000005 |

Fancy version seems to have larger variance, but is still consistently 1sec
worse or more.  So raw it is.

* [2017-02-08 mer.]
** Pipeline for Rust support in Flycheck                           :flycheck:
After the current PR is merged, I still have the corresponding PR in
flycheck-rust to take care of.

That should take care of Rust stable support.

Then, onto RLS support for the bleeding edge.

*** DONE Merge flycheck-rust detection of targets for the full conventional layout
CLOSED: [2017-02-15 mer. 14:28]
*** DONE Add RLS checker (or flycheck support in lsp-mode)
CLOSED: [2017-03-01 mer. 17:26]

** Exploring Flycheck                                              :flycheck:
Last time I looked at how a run of Flycheck went when no checker was found.  Now
it's time to explore what happens when a checker is found.

This time, the rust checker is eligible.  It's enabled, and I saved the buffer,
so the predicate is true.

Now it calls ~-start-current-syntax-check~, which creates a ~syntax-check~
object, a struct that holds information about the state of the syntax check.

It creates a callback to report status at a later point passing this syntax
check as first argument, and saves the syntax check as the
~-current-syntax-check~.

Flycheck status turn to "running" (but this only sends the status to hooks which
by default are not present).

Finally, it calls ~-syntax-check-start~ with the syntax check object and
callback.  There, the :start function of the checker is called, and its return
value put into the context slot of the syntax-check struct.

In this case, the start function is -start-command-checker.  There, we call
start-process, attach a sentinel and filter, and return the created process.
The filter just accumulates output into the process property
~flycheck-pending-output~.

The signal handler, -handle-signal, waits for the process status to be 'signal'
or 'exit'.  On 'signal', the syntax-check callback is called with 'interrupted'
(so the syntax check will report the interrupted status).  On exit,
-finish-checker-process is called with the accumulated output.

First, the output is parsed by -parse-output.  If the exit status was non-zero,
but no errors were collected, we have a suspicious state.

Otherwise, we call the syntax-check callback with 'finished' after mapping
-fix-error-filename for temporary files.

Parsing is just calling the 'error-parser of the checker.  Nothing more.

So next, control flows to -report-buffer-checker-status, since that's what the
syntax check callback calls.  Here the status is 'finished', so we flow to
-finish-current-syntax-check.

There, we first filter the errors with -filter-errors (which calls
:error-filter or -sanitize-errors), expand the filenames, and discard the
irrelevant errors.

Errors are relevant if they refer to the same buffer OR if they have no
filename, and the buffer has no file name either (for checkers called with
stdin).

Then, if the number of errors exceed -checker-error-threshold, the checker is
disabled.

Otherwise, call -report-current-errors with the relevant errors.

There, errors are added to the -current-errors, and sorted with -error-<
(interesting, as the order from rustc actually matters, and I did not know how
to control it).  Then, hooks from -process-error-functions are called for each
/new/ error (/not/ with -current-errors).

Initially, the only function present there is -add-overlay, which gets the
region for the error and applies the overlay on the region and prepare the
tooltip message.

After -report-current-errors returns, we check if there is a next checker.  If
we do, we -start-current-syntax-check with it.

Otherwise, we set -current-syntax-check to nil, report 'finished' as flycheck
status, delete the overlays that were marked /when this syntax checked had
started/.  This is to avoid flickering.  Then refresh the error-list (using
-current-errors).

Lastly, run any deferred check.  From the comments, I gather that deferred
checks are checks that were started while a syntax check was already active, and
so were put in a queue.

So it seems that flycheck does indeed merely two things with the errors: put
overlays, and populates the error list.

For lsp-mode, it means we could simply call -add-overlay and populate
-current-errors without relying on a checker definition, since lsp-mode would
take care of it.

* [2017-02-09 jeu.]
** Preparing the flycheck-rust PR                                  :flycheck:
In parallel, to merge the changes as soon as the first is reviewed.

*** DONE Fix the order of errors in the minibuffer
CLOSED: [2017-03-01 mer. 17:52]
This is annoying: the order of errors from rustc is meaningful, but they are
given in the wrong order in the minibuffer for some reason.  The error list
lists them in the proper order, but the minibuffer order is reversed.

[2017-03-01 mer.] matters less with flycheck-inline, but finding out why it's
happening would still be valuable.

* [2017-02-10 ven.]
** Drawing on top of an Emacs buffer                         :flycheck:emacs:
Seems Sublime text has very decent syntax checking similar to flycheck, but
error messages can appear /in the buffer/ just below the code they refer.  See
https://github.com/rust-lang/sublime-rust for a Rust example.

That takes space, but it lets you avoid the back-and-forth of looking at the
error message.

Can I do that with Emacs?

I've looked at overlays, and I think they can be used to display errors in the
buffer, but with major limitations:

- They have to be put at an existing buffer position.  You can't put an overlay
  at an arbitrary position (x,y) in the window; there must be text or space in
  the buffer.

- They move when you cut text.  I guess this could be worked around by
  recomputing their position after a text change.

Trying to find packages that draw on a window.

Looking at fill-column-indicator.  You would expect that a simple solution would
be to tell Emacs that you want to draw a vertical rule on the 80th column of the
window.  Instead, it uses overlays: one for each newline char.  After each
newline, it adds an overlay, and position the vertical rule using the ~display~
overlay property with a value of ~(space :align-to 80)~.

Overlays are flexible.  The bad part is that you have to write the code to get
rid of and redraw the overlays when the windows scrolls, or when the buffer
contents change.

Things like autocompletion with popups appear /on top/ of the text below.

Hmm, can't find anything conclusive.  Will have to ask.

* [2017-02-11 sam.]
** Inline errors                                                   :flycheck:
After asking on Flycheck repo, cpitclaudel quickly provided his nifty quick-peek
package.

Looks like exactly what I need.  Or at least, it shows that phantoms are
possible in Emacs.

The trick is to add overlays /at the end of the line/.  If the overlay text is
wrapped in newlines, it will appear as phantom lines, like in Sublime text.

* [2017-02-13 lun.]
** Inline errors as a flycheck extension                           :flycheck:
I've got a prototype working.  Inline errors show all related errors for Rust.
That's what I want in the end, since it's the most useful for most Rust errors
that have multiple parts.

However, for a Flycheck extension, it makes the most sense to cut the
functionality in two parts:

1. Phantoms as an alternative flycheck-display-errors-function.
2. Group errors from the same diagnostic in Flycheck; add support for
   displaying phantoms of a whole group in flycheck-phantoms

I may be able to leverage quick-peek by cpitclaudel if there is sufficient
overlap.

I wrote a minor-mode mostly lifted from flycheck-pos-tip, without caring for
error groups.

An open question is when to clear the phantoms.  After toying with it, editing
with the phantoms is weird; but just moving around is fine.

Experimenting with clearing the phantoms on post-command, I find the behavior of
the display-error timer weird.  When you are just moving point around, it's
supposed to debounce for 0.9 seconds (default display error delay).  But when
using next-error, the error should show directly (and the timer is canceled).
What I witness is that using next-error triggers the display-error function
/twice/.

I think the culprit is the post-command hook.  Next-error displays the error
directly, but the post-command triggers a display-soon, and after the delay
there's another display-error.  Which is fine with ~(message~ (though useless),
but not with phantoms.

So, that interferes with clearing the phantoms on post-command.  When using
next-error, phantoms for the errors at point are added.  Then, the post-command
hook clears them.  But the post-command hook also schedules a display-soon.
So after the display error delay, phantoms are added again.  That's dumb.

What's the correct fix for next-error?  We want errors to display right away,
but display-soon should not be triggered in the post-command hook.  Hmm I think
you can lookup what command has triggered the post-command hook with
this-command, so maybe test that in the post-command hook?  Hmm, it breaks since
I'm using spacemacs/next-error, but the idea works otherwise.

I think I need a cflow ...  wait would it work?  When the post-command hooks are
run, you are no longer below the control flow of next-error; next-error has
returned.

I think I want some sort of causality test:

---- next-error      ---- post-command / display-soon : nope
---- (anything else) ---- post-command / display-soon : ok

If display-soon is called in the post-command of a next-error, do not display
error.  For any other command, display error.

But I can't test for next-error directly because spacemacs redefines it (and
presumably, the user could wrap it).

Sooo.  That leaves me with setting a flag when running next-error, and clearing
it on post-command.

Okay so that works, regardless of the command that ends up calling
flycheck-next-error.

Now, when to clear phantoms?  Post-command is tempting, but it's messy because
that's also when we display them, so the order of insertion into the hook
matters.  Or, we just have to /not/ clear them after a flycheck-next-error.
That flag is useful.

Had to clear the flag in a function run at the end of post-command-hook, but
otherwise this works.

Clearing right before displaying them makes sense, because we are only
displaying one phantom at time (or one group).

Err, that was tricky to get right.  Will proofread tomorrow.

Aside: sometimes spacemacs/next-error is incapable of finding errors in a
flycheck buffer, even when they are present.  That's confusing.  Found out
that's because I have a Org buffer open in a window.  Since Org binds
next-buffer-function, it is considered as next-error capable, and
spacemacs/next-error prefers next-error buffers over flycheck.  Grrr

A downside of error groups is that while they work fine for small examples,
where you can see everything in the same buffer, but if your borrow starts a
thousand lines prior, or even in another file, that's not helpful.  Maybe
quick-peek would be best in these instances, since you could show the location
of the borrow start/end right below the current line.

But unless you have a very large function, you should be fine, since I don't
think borrow errors can cross function boundaries.  Needs more testing.

* [2017-02-14 mar.]
** Tasks I would like to have done by the end of the month         :flycheck:
Free time will probably dwindle starting in March.  That's two weeks.

*** DONE Make PR for inline-errors
CLOSED: [2017-02-15 mer. 14:28]
To at least gather interest, review, and toy with it.

*** DONE Make PR for grouping Rust errors
CLOSED: [2017-02-27 lun. 18:46]
This is is more controversial.  Don't know how it will fit with flycheck.

Maybe later.

*** DONE Experiment with nix (guix) to run integration tests
CLOSED: [2017-02-22 mer. 18:41]
The idea is to install checkers in sandbox (so it's separate from my regular
system), with multiple versions, to be able to run all the flycheck integration
tests without too much hassle.

Eventually, put that inside a VM for reproductibility.

*** DONE Document flycheck internals
CLOSED: [2017-02-27 lun. 18:46]
The intent is to have a point of entry on flycheck.org for adding or modifying a
checker.

*** DONE Add checklists to flycheck maintaining guide
CLOSED: [2017-02-28 mar. 20:06]
For things that are not automated: run integration tests, squash commits, make
sure a new feature is added to CHANGES and doc/ (esp. new checkers).

And see: [[https://github.com/flycheck/flycheck/issues/928][#928]].

*** DONE Pick up next-checker PR
CLOSED: [2017-03-28 mar. 12:43]
Seemed important, and might be doable now that I have more Flycheck chops.

* [2017-02-15 mer.]
** Making GIF screencasts                                              :arch:
Was more tricky to get right than expected.

First of all, forget recordmydesktop when using i3.  The GTK and QT versions are
both unusable.

Using raw ffmpeg is possible when you want a video:

: ffmpeg -video_size 800x600 -framerate 10 -f x11grab -i :0.0+10,100 output.mp4

But getting the area right is a pain.  So, instead, use ffcast

: ffcast -s rec

It wraps ffmpeg with xrectsel to let you select a region with the mouse first,
then invoke ffmpeg.

For a small Emacs screencast, the resulting video is only 30Kb.

Now, to make a GIF, since Github won't accept a video for insertion into
comments by drag and drop.

I've tried to use ffmpeg to convert directly:

: ffmpeg -i output.mkv -framerate 10 output.gif

But that only gives me GIF >1Mb.  That's an insane inflation.

So I've resorted to the imagemagick method [[https://superuser.com/questions/556029/how-do-i-convert-a-video-to-gif-using-ffmpeg-with-reasonable-quality][suggested here]]:

: mkdir frames
: ffmpeg -i output.mkv -vf fps=10 frames/ffout%03d.png
: convert -loop 0 frames/ffout*.png -dither None -colors 10 -layers OptimizeFrame output.gif

That gives me more reasonable 142Kb GIF.  Still a 500% size increase without the
ability to pause... but blame the web.

** Looking to improve our travis-ci build times             :flycheck:travis:
And how to run integration tests as well.

Currently looking at Travis documentation.  Of note:

- we always build the manual even when the build fails.  There is
  ~after_success~ for that.

- travis.yml file states we build and deploy the manual.  Deploy where?
  flycheck.org states Readthedocs hosts and builds the manual.

- Half the time of each job is spent installing Emacs (70sec), the other half in
  running the tests.

  Building emacs from source takes 423sec.

- Jobs can run in parallel.  Do they?  It appears they do.

- Looking at [[https://github.com/flycheck/flycheck/pull/1159][#1159]] that uses docker to speed up Travis, the builds take 10min
  instead of 3min with containers.  Not worth it?

- Travis runs Ubuntu 12.04 or 14.04, either in VM or container.

- .cask directory is intended to be cached, but ~make init~ still takes 9sec,
  and end of the run states that cache has not changed.  Hmm.

  The logs indicate that Cask manipulates ~/.emacs.d/cask, not ~/.cask.  Which
  is weird, since on my machine running ~make init~ installs cask packages in a
  .cask folder under flycheck

  But regardless, it's probably not a good idea to cache Cask dependencies
  anyway, since they are moving targets.

- we have a 'matrix' field and an 'env.matrix'.  What is the difference here?
  Trying to find documentation on the Travis.yaml file, because the official
  docs only define it by examples, not exhaustively.

  [[http://blog.tgrrtt.com/exploring-the-travisci-configuration-file][This]] is the best I found, and it's not much.


So, I think we can cache the stable Emacs releases, since they are not supposed
to change.

We can still build Emacs snapshot from scratch, since it is an allowed failure
it won't impact the build time.  (But is it reported somehow on a PR?  Or do you
have to check the build page?)

After a bunch of stupid mistakes and failing builds on Travis (the slow feedback
time is killing me), I shaved 1min per job by caching Emacs and 30sec further by
caching .emacs.d/.cask.

I might have broken Emacs snapshot though.  Needs to double check it's on my
end.  Haha, apparently [[https://hydra.nixos.org/build/48775188][it's a coincidence]].  The CI for Emacs has the same error.

Okaaay.  After making a branch on flycheck/emacs-travis and fixing /its/
travis.yml (in the process also caching Emacs there), the board is all green.
Will send a proper PR tomorrow.

* [2017-02-16 jeu.]
** Mounting a VM using qemu and libvirt                        :qemu:libvirt:
The intent here is to test Guix/Nix locally, and eventually use it for running
the full suite of Flycheck integration tests, without polluting my system.

Ideally.

Following the archwiki on Qemu and Libvirt.

Using virt-manager to manage VM, since I intend to use snapshots, or at least
persistent storage.

Only gotcha so far was to correctly set up polkit.  I didn't have any
authentication agent running, so virt-manager was failing.  The correct fix was
to install polkit-gnome and run:

: /usr/lib/polkit-gnome/polkit-gnome-authentication-agent-1

Then virt-manager was a breeze to use.

Marie told me about [[https://www.vagrantup.com/][Vagrant]].  It cakes care of provisioning a VM with a given
system, hence letting me avoid the installation step.  There's even a [[https://github.com/vagrant-libvirt/vagrant-libvirt][plugin for
libvirt]] as a backend.  Though that's mostly useful if I need to reproduce
installations.

In fact, the [[https://github.com/flycheck/flycheck/commit/2449c3dd7a386e6b53597bf20b21ed3eb97d19c1][previous VM]] used vagrant.

My intention is more to use Guix on Travis to manage dependencies.

Had to disable ipv6 in NetworkManager (in the guest VM) to get the network
going.

** Trying Guix/Nix                                                 :guix:nix:
Following the Guix tutorial / manual now.

Hmm, not so sure about Guix.  ~guix package -i hello~ has been running for
20 minutes now, with no end in sight.

That does not bode well to be run on our CI.

Let's see Nix instead.

Hmm nix installs itself in /nix.  That means using sudo at some point to create
and chown this directory.  You /can/ change the prefix, but apparently most
packages are built with the /nix prefix in mind, so you'll have to rebuild them
from source (??); [[https://nixos.org/nix/manual/#sec-building-source][cf. manual]].

Okay I'm a bit lost by looking around for examples.  Will resume tomorrow.

* [2017-02-17 ven.]
** Nix deadend                                                          :nix:
So it turns out that Nix [[https://github.com/NixOS/nixpkgs/issues/9682][is not]] the right solution to manage multiple versions
of a specific package.

There /are/ multiple versions of /some/ packages in the default nixpkgs channel,
e.g. go or lua:

: $ nix-env -qa go
: go-1.4
: go-1.6.4
: go-1.7.4

But you can't install arbitrary versions other than these.  Or you have to
specify your own derivation, which I gather is rabbit-holey.  Plus, chances are
your specific version won't be in the build cache, so you'll end up rebuilding
it from source (and potentially all its dependencies).

So, in the end, rather than being Cargo.toml-like, it's much more like any other
distro.  You are supposed to update your packages to the latest version that is
in the nixpkgs channel and go with the flow.

Well, for Flycheck I'm principally interested on running the integration tests
with the version that most users will use.  Unfortunately, the Travis VM runs
Ubuntu 12.04, which is outdated.  At the very least, running against the latest
Debian is better.

I think the most interesting use of Nix would be to deploy a build environment
for running all integration tests, without polluting my Arch system.  Something
[[https://ariya.io/2016/06/isolated-development-environment-using-nix][like this]].

Just have to install Nix, and write a nix expression with a list of tools.  Then
I should be able to spawn a nix-shell with all the tools in PATH whenever I want
to run the tests.  No need for a VM.

** Setup nix on Arch                                                   :arch:
Tried to symlink /nix to a different partition... nix does not support
symlinks.  But, you can use ~mount -o bind~ [[https://stackoverflow.com/a/34966233][instead]]:

: sudo mount -o bind /mnt/foo/nix /nix

and even put that in /etc/fstab for a permanent link (see man mount).

** Using nix-shell for running flycheck integration tests      :nix:flycheck:
Trying out with the following default.nix file:

#+BEGIN_SRC nix
with import <nixpkgs> {};
stdenv.mkDerivation rec {
  name = "env";
  env = buildEnv { name = name; paths = buildInputs; };
  buildInputs = [
    go
  ];
}
#+END_SRC

Spawning ~nix-shell~ downloads a bunch a stuff (~linux-headers~, really?), but
it's not too long.  After that, I do have ~go~ in PATH.  Running integration
tests for flycheck...

#+BEGIN_EXAMPLE
([cl-struct-flycheck-error #<killed buffer> go-build "/home/fmdkdd/proj/flycheck/test/resources/language/go/src/b1/main.go" 4 2 "cannot find package \"b2\" in any of:
	/usr/local/go/src/b2 (from $GOROOT)
	($GOPATH not set)" error nil])
       ([cl-struct-flycheck-error #<killed buffer> go-build "/home/fmdkdd/proj/flycheck/test/resources/language/go/src/b1/main.go" 4 2 "cannot find package \"b2\" in any of:
	/nix/store/c3vvkavjzf33vcgi0l98vxr2r91id78p-go-1.7.4/share/go/src/b2 (from $GOROOT)
	($GOPATH not set)" error nil]))
#+END_EXAMPLE

and

#+BEGIN_EXAMPLE
 skipped  5/8  flycheck-define-checker/go-errcheck/default
   passed  6/8  flycheck-define-checker/go-gofmt/syntax-error
   passed  7/8  flycheck-define-checker/go-test/default
  skipped  8/8  flycheck-define-checker/go-unconvert/default
#+END_EXAMPLE

Two issues: first, since Nix use its own idiosyncratic system hierarchy, a test
fails.  Arguably, the test could maybe be written in a generic way.

Second issue: I'm still missing binaries that other go checkers use.  Wow, we
have seven go checkers.  It seems other tools can be fetched using ~go
get~... but that would defeat the purpose of using a nix expression in the first
place.  We'll look into that later (same issue with tools from npm).

Let's try adding what I can find in nixpkgs, to see if this approach is
worthwhile.  Running ~make integ~ without nix-shell gives me:

: Ran 152 tests, 34 results as expected, 2 unexpected, 116 skipped (2017-02-17 13:57:56+0100)

Well, that's interesting.  Added a bunch of packages to my nix expression, ran
~nix-shell~ and went for lunch.  Came back to:

: error: build of ‘/nix/store/sbnm4dams3zgamzrmv524xcz8m2i7pga-verilator-3.884.drv’ failed
: /usr/bin/nix-shell: failed to build all dependencies

Apparently, verilator is built from sources, and it fails.  Removing verilator
then.

Uhoh:

: collision between `/nix/store/pp27kdpb0i8hgpjhwl64f498aj1xdkhx-gcc-wrapper-5.4.0/bin/cc' and `/nix/store/mc92v912d55s5nm6f1z45dqbx5hnn0dx-clang-wrapper-3.9.1/bin/cc'
: builder for ‘/nix/store/d9bbzg7llqcq3z4amrgdsg3xp98n4kq4-env.drv’ failed with exit code 25
: error: build of ‘/nix/store/d9bbzg7llqcq3z4amrgdsg3xp98n4kq4-env.drv’ failed
: /usr/bin/nix-shell: failed to build all dependencies

Looks like gcc and clang are both trying to provide /bin/cc.  Can't they play
nice with each other?

Can't find anything.  Might as well remove gcc since it's the most likely to be
present already on a machine.

Also, found out that nix [[https://docs.travis-ci.com/user/languages/nix][is supported by Travis]].  That means being able to use
nix in a Travis container, so integration should be painless.  If I can get it
to install all the checkers.

: collision between `/nix/store/sx08223kn0aymmjcjd59sd0jmp1d9x0w-gfortran-wrapper-5.4.0/bin/cc' and `/nix/store/mc92v912d55s5nm6f1z45dqbx5hnn0dx-clang-wrapper-3.9.1/bin/cc'

Grumble.

Okay, let's ditch clang.  I have it on my machine anyway.  Wait, no.  Apparently
I don't have it?

: Ran 152 tests, 62 results as expected, 11 unexpected, 79 skipped (2017-02-17 14:42:29+0100)

Progress.

Grr.  Trying to install gnat, again running into a /bin/cc collision.  Stop it
already.

Maybe using ~nix-shell~ is not the right way to do it.  Maybe just using
~nix-env~ would be sufficient, and maybe ~nix-shell~ is trying to do something
more.

Trying to install both gnat and clang with ~nix-env~.  First of all, there is no
"gnat", though there is a "clang".

: $ nix-env -i gnat
: error: selector ‘gnat’ matches no derivations

But it worked in the default.nix buildInputs list, where the names correspond to
/attribute paths/.  We can pass attribute paths to nix-env with -A.

#+BEGIN_EXAMPLE
$ nix-env -iA nixpkgs.gnat nixpkgs.clang
installing ‘gnat-wrapper-4.5.4’
installing ‘clang-wrapper-3.9.1’
building path(s) ‘/nix/store/9bb1ds5q2gacdp3q8asmyzh2w59in5bm-user-environment’
Wide character in die at /nix/store/64jc9gd2rkbgdb4yjx3nrgc91bpjj5ky-buildenv.pl line 79.
collision between ‘/nix/store/p9yy0z3w5cvv91kzqj4d9iicya4mskck-gnat-wrapper-4.5.4/bin/as’ and ‘/nix/store/mc92v912d55s5nm6f1z45dqbx5hnn0dx-clang-wrapper-3.9.1/bin/as’; use ‘nix-env --set-flag priority NUMBER PKGNAME’ to change the priority of one of the conflicting packages
#+END_EXAMPLE

Ah!  Both clang and gnat want to install /bin/as...  But here we have a
suggestion to resolve the conflict using priorities.  If I could set that in my
default.nix derivation that would be swell.

Ah, [[http://lists.science.uu.nl/pipermail/nix-dev/2016-August/021371.html][found it]]:

: (lib.recursiveUpdate gnat { meta.priority = 100; })

(where is lib.recursiveUpdate documented?  Not on the nix or nixpkgs manual mind
you.)  Also, the thread mentions that using nix-shell for these things is not
recommended.  The use case for nix-shell is to be able to run, say, one version
of GHC in one project, and another version for another project, by spawning a
different nix-shell in each instance.  Yet, here I'm trying to put everything in
the same shell, or even in the same profile.  Maybe the more correct approach
would be to install the checker, run the integration tests for just this
language, and repeat for each language.  But that means many invocations of
~make integ~, and I'd rather have just one that tells me "yep, all pass".  So,
workaround it is.

This (supposedly) sets the priority for gnat to 100 (higher number = lower
priority).  But by doing that, ~which cc~ in the nix-shell gives me the cc from
gnat-wrapper, and I would expect the one from gfortran.  Meh.  It resolves the
conflict anyway.

But...:

#+BEGIN_EXAMPLE
Suspicious state from syntax checker ada-gnat: Flycheck checker ada-gnat returned non-zero exit code 4, but its output contained no errors: gcc -c -I/run/user/1000/flycheck26662rXr/ -gnatf -gnatef -gnatwa -gnat2012 -I/nix/store/nmfsxjx4f7lq16ai5l027kwm4ix2nc4n-gnat-4.5.4/lib/gcc/x86_64-unknown-linux-gnu/4.5.4/adainclude -I- -o /run/user/1000/flycheck26662eNl/hello.o /run/user/1000/flycheck26662rXr/hello.adb
gnat1: invalid switch: -gnat2012
gnatmake: "/run/user/1000/flycheck26662rXr/hello.adb" compilation error
#+END_EXAMPLE

And here I don't know whether that's due to an invalid test or an invalid setup
with Nix.

AAAAH.  Okay I give up.  For today.

* [2017-02-20 lun.]
** Nix for flycheck integration tests                          :nix:flycheck:
Installing gcc-ada on Arch to see if that makes the test pass.  And it does.

Trying a nix shell with only gnat installed, all tests fail because of missing
-gnat2012.

I think the culprit is an outdated gcc version in nix.  Here is what Arch
reports:

: $ gnat --version
: GNAT 6.3.1 20170109
: Copyright (C) 1996-2016, Free Software Foundation, Inc.

And in nix-shell:

: $ gnat --version
: GNAT 4.5.4
: Copyright 1996-2010, Free Software Foundation, Inc.

Note the copyright years.  I suppose "gnat2012" refers to the year, so it's no
surprise that it's absent from a gcc version dated from 2010.

Found an [[https://github.com/NixOS/nixpkgs/commit/1a0a1619206f4a25d724bf04027980b45b15b16e#diff-036410e9211b4336186fc613f7200b12][incriminating commit]] from 2014, reverting to gcc 4.5 because more
recent versions failed to build gnat.  And looking at the latest master it's
still the same code.

I'm a bit puzzled.  I thought NixOS would be at least as up to date as Debian,
but Debian Jessy has gnat 4.9, and this one has the gnat2012 flag.

So using Nix won't solve my problems if I still have to install some packages on
my system.  Might as well have an Arch VM for testing latest releases, and a
Debian VM for testing legacy versions (though there is already the Debian CI).

Nixing nix.

** Installing an Arch VM with Vagrant                          :vagrant:arch:
Because I still want a reproducible environment.

Installing vagrant.  Trying to install the vagrant-libvirt plugin since I
already have libvirt installed.

This fails, but [[https://wiki.archlinux.org/index.php/Vagrant][the wiki has a solution]].  Run the command in bash since
fishshell will choke on the PATH substitution.

Vagrant has a list of existing boxes, these seem to be pre-configured VMs.
Since I don't want to install Arch on a VM myself, might as well use that.

The wiki suggests [[https://wiki.archlinux.org/index.php/Vagrant][this Arch linux box]].  So:

: mkdir vagrant
: vagrant init terrywant/archlinux
: vagrant up

#+BEGIN_EXAMPLE
The box you're attempting to add doesn't support the provider
you requested. Please find an alternate box or use an alternate
provider. Double-check your requested provider to verify you didn't
simply misspell it.
#+END_EXAMPLE

Duh.  The box requests virtualbox.  So virtualbox it is.

: pacman -S virtualbox
: modprobe vboxdrv
: vagrant up

Downloading the image...

: vagrant ssh

Oh hey, I'm in!

: $ gcc --version
: gcc (GCC) 5.3.0

Hmm, okay, what happens if I update this VM.  Does it stick?  [[https://www.vagrantup.com/docs/getting-started/teardown.html][Let's see]].

So by default it will stick, but it depends on how I tear it down.

- ~vagrant suspend~ will save a snapshot, so it should be faster to boot
- ~vagrant halt~ will power off the VM
- ~vagrant destroy~ will remove the VM completely from disk

If destroy, the next ~vagrant up~ will bring up the VM and provision it.

Provisioning is where I should put the pre-requisites to run the flycheck
tests.  Ideally I want to:

: vagrant up && vagrant ssh --command "make integ"

For my local machine, I can suspend or halt.  But after boot the VM should
update all its packages, and the flycheck dependencies to ensure we are always
testing the latest version.

Now to add all missing checkers and run the tests.

Some checkers are Ruby gems or NPM packages... that means installing these
package managers first and using them, and setting PATH correctly (grmbl grmbl).

Coq is in AUR, not Arch.  Curious.  Also, it failed to compile because of low
memory.  Let's up the RAM in the VM to 1024M... nope.  2048M?  Yep.

Hmm, coq checks are still skipped with coqtop installed.  I see this line in the
tests:

: (skip-unless (load "coq" 'noerror 'nomessage))

What is this supposed to do?  I suppose loading the binary and checking there
are no errors.  But as far as I can see, ~load~ is for elisp files, not
binaries.  And there is no ~coq~ elisp file anywhere in the tests.

And that reminds that the VM I am setting up is testing the flycheck integration
tests from the latest master on Github, not an arbitrary version.  Especially,
it would be useful to be able to test a local version as well.  It seems vagrant
syncs the directory with the Vagrant file by default.

Oh and using ~pacman-key --refresh-keys~ as a first step is a bad idea.  I was
having trouble running ~pacman -Syu~ because of outdated keys, but
~--refresh-keys~ will download the latest keys directly from a keyserver, which
might invalidate some keys prematurely.  It failed to validate the signature for
dmd:

#+BEGIN_EXAMPLE
error: libphobos-devel: signature from "Dicebot <public@dicebot.lv>" is marginal trust
:: File /var/cache/pacman/pkg/libphobos-devel-1:2.073.0-1-x86_64.pkg.tar.xz is corrupted (invalid or corrupted package (PGP signature)).
Do you want to delete it? [Y/n]
error: dmd: signature from "Dicebot <public@dicebot.lv>" is marginal trust
:: File /var/cache/pacman/pkg/dmd-1:2.073.0-1-x86_64.pkg.tar.xz is corrupted (invalid or corrupted package (PGP signature)).
#+END_EXAMPLE

Best to install ~archlinux-keyring~ as a first step in Vagrant.

To fix the issue on the VM, I [[https://wiki.archlinux.org/index.php/Pacman/Package_signing#Resetting_all_the_keys][cleaned the keyring]]:

: sudo rm -rf /etc/pacman.d/gnupg

Then:

: sudo pacman-key --init
: sudo pacman-key --populate
: sudo pacman -S archlinux-keyring

After that, dmd and libphobos installed without trouble.

Hadolint is best installed using stack... yet another package manager.

And stack appears to manage GHC installations itself.  Skipping for later.

GJSlint is deprecated.  Might be a good idea to remove it, or switching to
Closure compiler lints.

JSCS has also merged with ESLint, so while we can get a version from npm, it
won't be updated anymore.

Amazing.  All JS tests fail.

The lua checker has no tests.  I should perhaps go over each checkers and see if
it has at least one test... though ideally that should be an automatic check.

Perl and PHP both have their idiosyncratic package managers...  In fact, they
have several, and I don't know which to pick.  Skipping for now.

Hmm groovy installed jdk7, but processing is installing jdk8.  It seems groovy
can work on top of java8, but probably the choice has been made automatically by
pacman with ~--noconfirm~.  Might be best to install jdk8 upfront.

Oh, interesting.  Puppet has version-specific tests: one for version 4, and one
for below.

rpmlint is weird.  It has no installation instructions, and the sourceforge
website seems to be abandoned.  There is an updated github project page, but
still no clue on how to install it other than clone the repository and symlink
the ~rpmlint~ script.

Rust from pacman is outdated.  Have to use rustup?  Using rustup as that is the
"recommended" way of installing rust.

SCSS and Sass appear to be the same thing, but we have checkers for both.

systemd-analyze is skipped because I suspect we don't have systemd-mode.  It's
absent from Cask, and I doubt it's default.

verilator from AUR fails to build, but that seems to be an upstream bug, not a
packaging issue.

** Installing remaining checkers                                   :flycheck:
That I've skipped because it was as "straighforward" as finding the package name
and package manager and add it to the Vagrant file.

*** Systemd
Need to add to the Cask file:

: (depends-on "systemd")

Also, synced folders are great.  I moved my Vagrantfile and .vagrant folder to
flycheck, and I can just:

: cd /vagrant
: make integ

to test my local copy.

*** Haskell                                                       :ghc:stack:
Installing ghc passes 2 tests.  2 other need hlint.

There are hlint in pacman: haskell-hlint and hlint.  Both same software, same
version, same maintainer  Confusing.  Let's go with haskell-hlint since it's
more informative and follows the python-* naming scheme.

Stack needs GHC 8.0.2.  But pacman provides GHC 8.0.1.  Running

: stack setup

installs the version required by stack.

On a related note, the VirtualBox image is 11G as of right now.  13G after stack
has finished setting up...

But, now, no tests are skipped (but one fail).

*** Moving the VirtualBox folder to another partition            :virtualbox:
Essentially, [[http://superuser.com/a/943588][this]].

*** go complete-chain                                                    :go:
This one is skipped.  But I don't have golint installed.

That was it.  Adding golint passes the test.

*** hadolint                                                       :hadolint:
This one isn't packaged anywhere.  The recommended install is clone and use stack.

There is a /fork/ of hadolint on Hackage.  Don't know why, don't really care to.

Hadolint seem requires GHC 7.10 ... yet another GHC installation!

Hmm, ~stack install~ copies stuff in ~/.local/bin.  Have to add that to PATH.

After that, success.

*** coq                                                                 :coq:
Ah I see now that ~load~ actually searches in directories from ~load-path~.  So
the checks:

: (skip-unless (load "coq" 'noerror 'nomessage))

only ensure that some coq package is correctly loaded.  Can't find coq on
MELPA.  Can't find coq.el on the VM actually.  There are some coq-related files
in /usr/share/emacs/site-lisp: coqdoc.el, gallina.el.

According to [[https://coq.inria.fr/refman/Reference-Manual017.html#Emacs][the manual]], gallina.el contains coq-mode.  Duh, that's not the way
you are supposed to name your elisp files.  But anyway.

Also, it's not autoloaded.  Is anyone actually using this mode?  Or are they
using proofgeneral directly?

In any case, tweaking the Coq-specific lines in flycheck-test to look for the
"gallina" file make the tests... fail.

But they pass, and that was tomorrow's task.  Fixing the tests is for later.

*** Headcount
After these, make integ reports:

: Ran 152 tests, 113 results as expected, 30 unexpected, 9 skipped

The skipped tests are:

#+BEGIN_EXAMPLE
  SKIPPED  flycheck-define-checker/javascript-gjslint/complete-chain
  SKIPPED  flycheck-define-checker/javascript-gjslint/default
  SKIPPED  flycheck-define-checker/perl/default
  SKIPPED  flycheck-define-checker/php/default
  SKIPPED  flycheck-define-checker/puppet-parser/parser-error-puppet-3
  SKIPPED  flycheck-define-checker/r-lintr/default
  SKIPPED  flycheck-define-checker/rpm-rpmlint/default
  SKIPPED  flycheck-define-checker/verilog-verilator/error
  SKIPPED  flycheck-define-checker/verilog-verilator/warning
#+END_EXAMPLE

- gjslint is deprecated
- verilator does not build
- puppet-parser is expected (but we probably should report version checks
  differently)

That leaves perl, php, lintr and rpmlint to figure out.

Tomorrow.

* [2017-02-21 mar.]
** Remaining skipped tests                                         :flycheck:
*** Perl                                                          :perl:cpan:
I need perl critic.  I see that it's on CPAN.  Apparently I have a ~cpan~ script
on the VM.  But it needs interactive configuration, that's bad for my
Vagrantfile.  The recommended tool seems to be ~cpanm~, and this one is in
pacman.

: cpanm Perl::Critic

Using sudo to install under /usr, as a $HOME install needs more setup.

Except now I can't run perlcritic without sudo.

: sudo chmod -R a+rX /usr/share/perl5 /usr/lib/perl5

seems to fix it.  ~X~ is handy: it's +x only on directories, or files that
already had at least one executable permission.

*** Php                                                                 :php:
Need : php, phpcs and phpmd.  Phpmd is already in pacman.  Phpcs is in PEAR.
But I don't have PEAR installed.  It's in AUR.  Actually, there are several
versions.

Let's use php-pear.

: sudo pear install PHP_CodeSniffer

Oh, look, ~phpcs~ is on PATH!  But it can't find its libraries!  Have to edit
/etc/php/php.ini to modify the include_path to include pear.  Why isn't that
done by default when installing PEAR?

Luckily, there is a /etc/php/conf.d/, so that saves me from using sed.

After that, there is again a permission issue.  Fixed with:

: sudo chmod -R a+rX /usr/share/pear/PHP

After that, both tests fail.

*** lintr                                                                 :r:
Installing packages in batch requires creating a file: [[https://orfe.princeton.edu/help/r-packages][example]].

That means heredoc in heredoc in my Vagrantfile:

#+BEGIN_EXAMPLE
    echo "Installing packages from CRAN..."
    export R_LIBS_USER=~/R
    cat <<-EOF > install-packages.R
      dir.create(Sys.getenv("R_LIBS_USER"), showWarnings = FALSE, recursive = TRUE)
      install.packages("lintr", Sys.getenv("R_LIBS_USER"), repos="http://cran.case.edu")
EOF
    R CMD BATCH install-packages.R
#+END_EXAMPLE

There's a gotcha with the dangling EOF.  Heredocs must not have whitespace in
front of them ([[https://stackoverflow.com/a/2954835][see]]).

That should do it.  The test fails, of course.

*** rpmlint
We meet again.  There is a rpmlint package on Pypi, but it's version 0.48.  The
latest release on the github page is 1.9.

Problem is, there is no one-line way of installing rpmlint.  There's an INSTALL
file that just lists the dependencies.

Cloning from master and symlinking ~rpmlint~, it fails loading the module
~rpm~.  That's not in rpmlint, it's a dependency.  I assume it's this one
from the INSTALL file:

: rpm 4.4.2.2 or newer and its python bindings

What is the name of the package?  Have to guess.

Hmm, there is an rpmlint in AUR.  It's outdated (1.6), but I might get
information from its dependencies and PKGBUILD.

Okay I give up.  My internet is so slow it makes this search painful.  Tried to
install rpm-org, but it does not provide me with rpm python bindings.  I see
that there is a rpm-python package in Ubuntu, but not in Arch.

Doesn't seem worth the trouble.

*** Making sure it works from scratch
So...

: vagrant destroy
: vagrant up

Hopefully, everything checks out.  Heading to lunch, because this will take some time.

It doesn't.  Making a small adjustment to PGP keys again.

: pacman -Sy
: pacman -S archlinux-keyring
: pacman -Su

First refresh packages, then install the latest keyring before any other
package.  Then upgrade.

After taking a while (1 hour?), it works without intervention.  And all tests
run except gjslint, puppet3, verilator, and rpmlint.

Oh, and lintr.  Somehow I forgot to set R_LIBS_USER permanently.

Now, to fix the tests?

** Fixing flycheck integration tests                               :flycheck:
Fixed asciidoc and c++.  Here is the remaining:

#+BEGIN_EXAMPLE
30 unexpected results:
   FAILED  flycheck-define-checker/coq/error
   FAILED  flycheck-define-checker/coq/syntax-error
   FAILED  flycheck-define-checker/css-csslint/syntax-error
   FAILED  flycheck-define-checker/go-build/directory-with-two-packages
   FAILED  flycheck-define-checker/go-build/missing-package
   FAILED  flycheck-define-checker/go-unconvert/default
   FAILED  flycheck-define-checker/haskell-stack-ghc/literate
   FAILED  flycheck-define-checker/javascript-eslint/complete-chain
   FAILED  flycheck-define-checker/javascript-eslint/warning
   FAILED  flycheck-define-checker/javascript-jscs/default
   FAILED  flycheck-define-checker/javascript-jshint/complete-chain
   FAILED  flycheck-define-checker/javascript-jshint/default
   FAILED  flycheck-define-checker/javascript-jshint/syntax-error
   FAILED  flycheck-define-checker/javascript-standard/error
   FAILED  flycheck-define-checker/javascript-standard/semistandard
   FAILED  flycheck-define-checker/markdown-mdl/default
   FAILED  flycheck-define-checker/php/default
   FAILED  flycheck-define-checker/php/syntax-error
   FAILED  flycheck-define-checker/python-flake8/default
   FAILED  flycheck-define-checker/python-flake8/syntax-error
   FAILED  flycheck-define-checker/python-pylint/default
   FAILED  flycheck-define-checker/python-pylint/no-symbolic-id
   FAILED  flycheck-define-checker/python-pylint/syntax-error
   FAILED  flycheck-define-checker/r-lintr/default
   FAILED  flycheck-define-checker/rst-sphinx/default
   FAILED  flycheck-define-checker/ruby-jruby/default
   FAILED  flycheck-define-checker/ruby-rubocop/syntax-error
   FAILED  flycheck-define-checker/ruby-rubocop/with-rubylint
   FAILED  flycheck-define-checker/ruby-rubylint/syntax-error
#+END_EXAMPLE

Oups, forgot sqllint.

Done!

: Ran 152 tests, 144 results as expected, 2 unexpected, 6 skipped

Still 2 failures, not sure how to fix them (might be an upstream bug, might be
an obsolete test).

That's 31 tests fixed.

* [2017-02-23 jeu.]
** Writing the developer's guide to flycheck                       :flycheck:
First setting up building the doc on my machine.

It's recommended to use ~virtualenv~.  Let's do that.

: cd doc/
: virtualenv venv
: source venv/bin/activate.fish  # oh it recognized my shell!
: make init
: make html-auto

Ok, I'm in.

What do I want to put into it?

- Give an idea of how flycheck works.  How it executes checkers, parse their
  output, produce errors, refresh the error list, etc.  How a check is started
  (automatically, manually); how errors are per-buffer.

- Give recipes for writing a checker (using the rx parser, or a custom parser
  for JSON output), or extending one (adding variables)

* [2017-02-28 mar.]
** Nil-checker                                                  :types:elisp:
Made a quick and dirty prototype for a basic nil-check for Elisp.  Emacs Lisp,
like JavaScript, is rather lenient, but some calls still create errors.  Why not
check them statically?

The byte compiler already does some static checks: unused variables mainly.

The nil-checker only has 3 concrete types: Nil, Non-Nil, and Maybe-Nil (top).
Then there are arrow types for functions.

With a base type context of:

: car : NonNil -> MaybeNil
: list : MaybeNil -> NonNil

I got this to typecheck:

: (car (list 1)) : MaybeNil

but not that:

: (car nil) : TypeError

This also fails:

: (car (car 1)) : TypeError

but you also have weird ones:

: (car 1) : MaybeNil

So, as a proof of concept it works, but it's not terribly useful for Elisp right
now since the type system allows things that crash ~(car 1)~, and forbids things
that are fine ~(car nil)~ (though that one is arguable).

I think my idea was that having types like List, Symbol, Number, was not enough,
since most of the bug I deal with are instances of not checking for nil values.
If a List can be nil, that eliminates one category of errors, but not all of
them.

I've looked around for existing examples.  [[https://stackoverflow.com/questions/3323549/is-a-statically-typed-full-lisp-variant-possible][This SO answer]] suggests [[http://docs.racket-lang.org/ts-guide/types.html][TypedRacket]].
That might be the most directly applicable type system indeed.  In particular,
[[http://docs.racket-lang.org/ts-guide/occurrence-typing.html][occurrence typing]] is clearly needed to make the type system palatable.  [[http://www.ccs.neu.edu/racket/pubs/icfp10-thf.pdf][This
paper]] seems like a good start.

I was thinking that Flow could also be interesting to look at.  [[https://github.com/facebook/flow/issues/867][They don't seem]]
to have any documentation on the inner workings of the type systems though.
The main idea is apparently taken from François Pottier's thesis.

* [2017-03-01 mer.]
** Making that lsp-mode + Flycheck PR                          :rls:flycheck:
Just moving everything to lsp-mode, since the RLS is alpha and there's no point
putting the checker in Flycheck at this time.

Also, simplified the process: instead of waiting for Flycheck to start the
syntax check automatically on its own and look into the collected errors
~lsp--diagnostics~, we call ~flycheck-buffer~ after diagnostics are collected,
and the generic checker signals immediately the list of flycheck errors to the
callback.

Having issues to try it out... hash-table-p is nil in process-filter of
lsp-mode.  Something fishy.

Updated lsp-mode and rustls.  Instructions for running rustls have changed.

Adding:

: (setenv "LD_LIBRARY_PATH" "~/.rustup/toolchains/nightly-x86_64-unknown-linux-gnu/lib")
: rustup component add rust-analysis

Is that better?

: error in process filter: vector: Wrong type argument: hash-table-p, nil
: error in process filter: Wrong type argument: hash-table-p, nil

Nope.  What was I saying about type systems yesterday?  :(

Let's Edebug this.  This fails in creating the lsp-diagnostic.  Apparently,
rustls moved the "start" field to "range".

Hmm, now that I think of it, I've tested it with the RLS, but it should work the
same with any server following the protocol.  The diagnostic format should be
part of the protocol, so...  I could remove references to rust.

Or maybe not, since ~:modes~ is a required property of Flycheck checkers, right?
And it should be a major mode, so it can't be used with lsp-mode.

Well, improvements; later.

* [2017-03-10 ven.]
** Picking up GameBoy sound emulation                                   :gbs:
Watched [[https://www.youtube.com/watch?v=HyzD8pNlpwI][The Ultimate GameBoy talk]], and was reminded that GBS progress is
stalling.

Even if my CPU is not accurate yet, I would like to write the APU.  For
emulating GBS, I need the CPU to work reasonably well, since it drives the APU.
But I can write the whole APU and test it separately without writing the CPU;
treat it like writing to an API.

The main thing I haven't solved is timing.  How long should a note be?  For
emulating the LCD, I guess you can wait for VBLANK to update the screen, even
though that's not necessarily correct, it gets you 60fps which is at least
unnoticeable.

For Boyo, I think the sound was also updated 60 times per second, though I
remember basing the emulation around a 256Hz timer.

So what's the right way to approach it?  If, say, I set the pulse channel length
counter to 1sec, and frequency to 220Hz, and start the emulation.  I know the
program should play a 220Hz pulse wave for 1 second and then stop.  I know what
the samples of that sound look like.  But how are the samples actually
generated, procedurally?

For instance, if emulating at 50Hz, that means one frame = 20ms.

The pulse wave period is: 1 / 220Hz = 4.5454ms, so in one frame I have 20 /
4.545 = 4.4 pulse periods (the ratio 220/50).

So, now I have to fill my 20ms buffer with 4.4 periods of pulse wave samples.
How many samples?  At 48KHz, I need 48,000 / 50 = 960 samples per frame.

A 50/50 pulse wave period is ____----, so I know I have to alternate between low
and high signals 8.8 times per frame, or every 800 / 8.8 = 109.09.. sample.

One way to fill the 800 samples is then to write -1 109 times, +1 109 times, 4
times and a half.  If you don't account for the decimal, that ends up to a
period of 218 samples, or 48,000 / 218 = 220.18Hz; close but not just.

I can also use the remainder:

960 - 109.09.. = 850.9090..   -> -1
850.90.. - 109.09.. = 760     -> +1
...

That way, I end up exactly filling my 960 samples at 220Hz, with a
leftover for the next frame.

Though iterating over 960 samples seems a bit inefficient in the long run.

Researching...

* [2017-03-13 lun.]
** Square wave synthesis                                                :gbs:
Reading Musimathics vol. 2, I see that the canonical way of synthesizing audio
waves is to use Fourier summations.

A square wave for example, is the infinite sum of odd harmonics:

: \sum sin((2k+1)2\pi{}t) / (2k+1)

where k varies from 0 to +\infin.

Of course we don't have to compute infinite sums; higher values for k will
contribute less and less to the total, so we can ignore them once we stop
hearing a difference.

Using this series should generate what is called a /band-limited/ square wave.
The geometrical square wave that is all +1 and -1 is /non-band-limited/ and
contains infinitely high frequencies that could cause aliasing.

Let's try to generate the band-limited version and the non-band-limited in order
to compare them.  First I will try to hear the difference, then I will run them
through a Fourier transform to see if there are any aliased frequencies in the
spectrum.

Then I will do the same with a SunVox square wave, and maybe one from a DMG.

Well, there is an audible difference between geometric and Fourier sum.  The
geometric seems clearer at first, although a bit grainy; but by summing the
first 20 terms of the Fourier series, the output has is quite similar and
without any grain.

Though, pushing to 50 or even 100 terms, the grain starts to appear again.

Looking at the spectra now.  The geometric square has the advantage of working
at any frequency: it has infinite harmonics.  For the Fourier square, you have
to keep computing terms until they hit the Nyquist barrier, otherwise the wave
sounds muffled.

Tweaking the generator to push up to the Nyquist barrier...  Now I don't have to
compare several versions of Fourier sums, especially as adding more terms than
necessary introduces artifacts.

The geometric square is still grainier; maybe that's what aliasing sounds like:
tiny dots of high frequencies.  The Fourier square sounds smoother, without this
grain.

The SunVox plain generator square also has this grain.  You can clearly see from
the waveform and spectrum that the plain generator is geometric, whereas the
analog generator in SunVox is closer to a Fourier sum, but probably using a
different algorithm that the naive one I'm using.

The DMG square is closest to the Fourier square, except the overall waveform is
slightly bent, as if it was generated from a sawtooth:

[[file:data/dmg-waveform.png]]

Compare to the more orthogonal Fourier:

[[file:data/fourier-waveform.png]]

In both cases, we can see overshoots at the transitions (Gibbs' horns), but the
DMG pulse is clearly /more/ distorted.

The spectra are also different.  Here is the spectrum of the geometric square:

[[file:data/geometric-spectrum.png]]

All odd harmonics, with decreasing amplitude.  Clear cut.

Compare to the spectrum of the Fourier square (the Y-axis scale is sadly not the same):

[[file:data/fourier-spectrum.png]]

Still odd harmonics, but with some overlap in the lower frequencies.

And now, the DMG spectrum (yet another Y-axis scale):

[[file:data/dmg-spectrum.png]]

Overlaps everywhere, and much more prevalent at low frequencies.

According to [[https://en.wikipedia.org/wiki/Pulse_wave][wikipedia]], we can create a square wave by subtracting a sawtooth
wave from a phase-shifted version of itself.  Maybe that's how it is done on the
DMG.  Let's try it.

Well, no, it doesn't change a thing.  In fact, it's totally equivalent, since we
are subtracting values we add.

Maybe what the waveform needs is a slight modulation of amplitude based on a
sawtooth wave with the same frequency.

Managed to have a very similar waveform with:

#+BEGIN_SRC rust
  let square = fourier_square(rate, length);
  let saw = fourier_sawtooth(rate, length, 0.0);

  let ratio = 0.125;

  square.iter().zip(saw.iter())
    .map(|(a, b)| {
      if *b > 0.0 { (a - (b * ratio)) / (1.0 + ratio) }
      else        { (a + (b * ratio)) / (1.0 + ratio) }
    }).collect()
#+END_SRC

[[file:data/square-sawtooth-waveform.png]]

The spectrum is still relatively clean:

[[file:data/square-sawtooth-spectrum.png]]

Much less overlap than the DMG pulse.

But, apart from the waveform, the timbres all sound pretty similar to me.  The
plain Fourier square is just a bit louder, but I can't hear any other
difference.

So I guess band-limited synthesis is best for GBS.  Not sure if I should look
into faster algorithms, since I can generate 6 1-sec samples in 140ms right
now.  That's enough for running it in real time.

* [2017-03-15 mer.]
** Square wave synthesis in GBS                                         :gbs:
Now that I know I should use a Fourier sum to generate the square wave, let's
apply that to the sound channel of GBS.

First try: generate samples for 20ms at a time and concatenate them.  Result:

[[file:data/synth-fail.png]]

It sounds as awful as it looks.  The problem here is that each 20ms block of
samples totally ignores what samples were there previously.  We are trying to
emulate a continuous signal, but there's no continuity.

Second attempt: can I create an iterator over an infinite stream of samples, and
modify the value it refers to on the fly?

I guess not, because that's unsafe for data races.

Third attempt: since we are generating a wave alongside time, we need to keep a
continuous time counter.  That's what the length counter is for, presumably.

What's the finest granularity to emulate?  Per-sample.  So instead of generating
a wave for 20ms at a time, we generate one sample.  The generating function
receives the running time as input.

With that, we can compute a sample, change the frequency, compute another
sample, etc.  So we can presumably do frequency sweeps at a very fine
resolution.

Here is an example of changing the frequency from 440Hz to 880Hz:

[[file:data/freq-switch.png]]

No hiccups.

The time parameter can't be increased infinitely.  We are operating on finite
machines here.  Luckily, notes played by the DMG are not infinite either; they
are regulated by the length counter.  We can use the length counter as time
value.

Okay, so the concept seems working.  I can adjust frequency and length, emulate
as many samples as I want.  Now, to follow the specs of the DMG PAPU.

** PAPU specs have wonky parameters                                     :gbs:
Take the length register for example.  According to the docs, it's a 5bit value
that's clocked at 256Hz.  So the length in seconds is:

: length in seconds = (64 - [length]) * (1/256)

where [length] is the register value.  Since [length] is in [0,63], the length
is between 0.004 and 0.25 seconds.  If you want a 1sec note, you have to reload
the length counter while it's playing.

That's a bit too low-level.

So, I will just write a square synth with a friendly interface (length and
frequency in seconds, as real numbers), and write the plumbing for the DMG
interface separately.  That way, I can test the synth without going through the
contrived formulas.

** Timing troubles, again
I guess I haven't though things totally through.  Envelope control is fine, it's
just a linear decrease of volume (more a staircase in the case of the DMG, since
it only has 16 steps of volume).

Been trying to implement a frequency sweep, but I have these clicks:

[[file:data/sweep-fail.png]]

I think the problem is that, since my signals are on the same global time, I'm
switching from a pure 440Hz to a pure 441Hz in the middle of a period.

Maybe, if I hold the switch to the end of the current period...  Otherwise, we
should shorten the current period according to the new frequency.  But in order
to do that, I think the computation should be done differently than I'm doing
right now.

Hmm waiting for the end of the period doesn't work either, since I'm not
guaranteed that samples fall exactly on a period's end.  That calls for a
different approach.

* [2017-03-16 jeu.]
** Reading on how PAPU emulation should work                            :gbs:
These threads shed some light:

https://www.reddit.com/r/EmuDev/comments/5gkwi5/gb_apu_sound_emulation/
http://forums.nesdev.com/viewtopic.php?f=3&t=13749
http://forums.nesdev.com/viewtopic.php?f=3&t=13767

Specifically, the participants suggest to emulate the APU at the frequency of
the CPU or higher.  Some say one CPU cycle should correspond to one APU cycle,
some say they emulate the APU at 100Hz in a separate thread.

The important point is to decorrelate the APU emulate rate from the final
sampling rate of the generated audio.  So, the APU can generate samples at the
frequency of the CPU, but the final audio can stay at 44100Hz.  Obviously, you
then have too many samples, and have to discard them.  There are various ways to
do that, but the threads suggest just to drop them regularly.

In GBS, if I'm solely concerned with generating a WAV from a GBS file, I can run
the emulator as fast as I can, pump out samples, and not worry about any kind of
synchronization, buffer overflows or underruns.

One thing that surprised me reading these threads, is that while I think I
understand that the role of the APU is to generate samples in the form [0,
max_volume], they never touch on how these APU samples are turned into proper
PCM samples.  Surely, you don't want these APU samples fed directly to your
output, otherwise you will get nasty aliasing.

In other words, no one talked about emulating the DAC of the DMG.  Gotta
research more on that front.

* [2017-03-17 ven.]
** Cargo check has landed in Rust stable                     :cargo:flycheck:
Can Flycheck benefit from it?  Should we switch?  Does it check all targets?

It seems we can still pass a specific target, so it should behave like ~cargo
rustc~.

Argh, but it doesn't check code inside #[cfg(test)].  So that's no use.  [[https://github.com/rust-lang/cargo/issues/3431][There's
a PR]], but that will have to wait.

Also, we will lose the ability to pass custom arguments to rustc.  And, from
running the integration tests, we also lose the linking information given in the
notes-test (though that one is presumably minor).

So, no cargo check for the time being.

* [2017-03-18 sam.]
** Comparing GME behavior for GBS emulation                             :gbs:
Really can't get something decent working from the docs alone (should've
guessed... been down this road before).  So that leaves me two options: lifting
code from working emulators, or getting a trace from emulators and using that as
spec.

I've tried the first option for Boyo.  It's not as fun, since you end up mostly
copying the code.

I'll try the second option now.

Higan doesn't eat GBS files directly.  Might be easier to modify libgme.

Apparently, it's no longer maintained by Blargg.  [[https://bitbucket.org/mpyne/game-music-emu][Here's]] the current repo.
Cloning...  Working.  Now, to INSTRUMENT.

Hmm, there was a promising line:

: gb_cpu_log( "new", pc - 1, op, data, instr [1] );

But seems the code for the function is not there anymore.  Maybe in Git history?
Shoot.  The history only goes back to 0.5.2.

Well, I only need to print the registers anyway.

First discovery: GME simulates a CALL to run the INIT subroutine.  That way, you
just have to monitor the stack pointer to know when the subroutine is done.

GME uses 0xF00D as the address to return to after INIT.  Strangely though, the
RAM has the 0xFF opcode at this location in GME, and I don't.

Since 0xFF is RST 38H, I'm jumping to 0x0038.  But the GBS documentation
mentions that you should offset the base of the RST vectors to the load
address.  So instead of jumping to 0x0038, you jump to load_addr + 0x38.

Ah, but actually, GME will stop emulating on a 0xFF that's exactly at 0xF00D.
That's how it gets out.

Duh, next discrepancy is on 0xFE: CP imm.  We have:

: 655a fe 01 AF:0000 BC:0000 DE:0000 HL:64ef SP:cff5
: < 655c 28 46 AF:0070 BC:0000 DE:0000 HL:64ef SP:cff5
: > 655c 28 46 AF:0000 BC:0000 DE:0000 HL:64ef SP:cff5

I set the NHC flags and GME doesn't.  Except GME seems wrong here, since CP will
always set the N flag.  Wait.  Am I printing the flags correctly?  Haha, no.

Next:

: 69ae 3d cb AF:0300 BC:0300 DE:dffa HL:6530 SP:cff1
: < 69af cb 27 AF:0240 BC:0300 DE:dffa HL:6530 SP:cff1
: > 69af cb 27 AF:0260 BC:0300 DE:dffa HL:6530 SP:cff1

3d is DEC A, and GME sets flags.H and I don't.  Except... there is no half carry
here.  3 - 1 = 2.

GME formula is:

: ((data & 15) + 0x31) & 0x20

(2 & 15) = 2
2 + 0x31 = 0x33
0x33 & 0x20 = 0x20
H is set

Hmm hmm.  If data is 0x0F, then:

0x0F & 15 = 0x0F
0x0F + 0x31 = 0x40
0x40 & 0x20 = 0
H is clear

So H is cleared if data is 0x0F, and set otherwise (since 0x0F is the only value
that will overflow 0x3_ into 0x40).

And I'm doing:

: self.f_setb(HY, (data & 0x0F) == 0x0F)

So H is set only if data is 0x0F and clear otherwise.  That's the reverse, and
it seems more sensible.

Let's see what Higan says.

: r.f.h = (r[x] & 0x0f) == 0x0f;

Grmbl.

Mooneye:

: HALF_CARRY.test(value & 0xf == 0) |

value is the before the subtraction, so 2/3 in favor.

I'll inverse the behavior for the time being to see if there are other
discrepancies.

: 6d5c f6 80 AF:c000 BC:0023 DE:0000 HL:dfca SP:cff1
: < 6d5e e2 7d AF:4000 BC:0023 DE:0000 HL:dfca SP:cff1
: > 6d5e e2 7d AF:c000 BC:0023 DE:0000 HL:dfca SP:cff1

F6 is OR d8.  Hmm, bad copy paste on my end.  OR was doing xor.

: 65a3 c9 cd AF:0300 BC:0000 DE:0000 HL:64ef SP:cffd
: < f00e ff 00 AF:0300 BC:0000 DE:0000 HL:64ef SP:cfff
: > f00d ff ff AF:0300 BC:0000 DE:0000 HL:64ef SP:cfff

After C9 (RET), I'm back at 0xF00E and GME is at 0xF00D.  Hmm.  Looks like I
saved PC one byte too far.

That's because I actually take the RST 38H jump after the INIT subroutine, but
GME doesn't.

At this point, I don't quite understand how GME deals with this idle_addr.
Sometimes it stays for two loops at 0xF00D, sometimes for one loop.

But, I can git diff the rest.

:  6d4c 7e e1 AF:0000 BC:0011 DE:8074 HL:df9f SP:cfef
: -6d4d e1 cb AF:0100 BC:0011 DE:8074 HL:df9f SP:cfef
: +6d4d e1 cb AF:0000 BC:0011 DE:8074 HL:df9f SP:cfef

7E is LD A,(HL).  I have 1 at DF9F, GME has 0.  Maybe something to do with RAM
initialization.

Other than that, there doesn't seem to be any discrepancies left.

But, it doesn't sound good at all.  All noise.

I suspect I'm missing some timing stuff.  The GBS doc mentions timing.  At the
very least, it seems that for most GBS files, you should call the play address
at 60Hz.

Haha!  Victory!  I've got the first channel replicating the familiar melody.  It
sounds bad, but the melody is there, so I must be on the right track.

How I understood the timing:

The PLAY subroutine sets up notes, and you should emulate it until it RET.
While emulating it, you also want to emulate the APU.  Currently I'm clocking
the APU for every CPU cycle.

After PLAY returns, you want to continue emulating only the APU until the next
V-blank.  Here, I'm going with a period of 70224 cycles (59.73Hz).

Once the period is over, we can call PLAY again and start over.

After emulating 10 seconds with a very rough APU implementation (duty cycle,
frequency and length), the melody is there.

* [2017-03-19 dim.]
** Extracting GBS as its own project                                :gbs:git:
It's time to leave the nest.  Now that it works and the basic architecture seems
in place, it gets its own repository!

The procedure is [[https://help.github.com/articles/splitting-a-subfolder-out-into-a-new-repository/%0A][helpfully documented]] on Github.

* [2017-03-23 jeu.]
** Finishing flycheck checker stages revamp                        :flycheck:
Seems it's mostly done, save for:

- stopping the chain if an error is present
- user documentation

And all these steps were helpfully laid out by lunaryorn.

In addition, I should rebase on master.

One thing I'm not sure about is whether integration tests for complete chains
have to be changed.

Rebase done.  Had to take care of new checkers that were merged in the meantime,
otherwise smooth sailing.

Stopping after error is just a matter of adding a test in
~flycheck-finish-current-syntax-check~.  Seems to work, but I don't know if that
catches everything.

Argh, wait, no.  It breaks 21 spec tests.  How come?

These tests use

: (flycheck-test-with-nav-buffer 'error

Which loads an Elisp buffer with a file containing a warning and an error.  The
tests then check if point is on the correct error by indexing into
~flycheck-current-errors~.  Except, with this change, ~flycheck-current-errors~
is modified since the warning comes from a lint checker and the error from a
syntax checker, so the lint checker is never run.

What is stranger is that I don't understand how the tests pass in the first
place.  Hmm.

Ah okay, it's only "over-error" tests that fail.  It's because these tests limit
the navigation to some error level, and thus bypass the warning.

So I can change the example so that emacs-lisp checker is the one to generate a
warning.  But this mean we might not test the functionality of multiple checkers
any more.  Need to make sure there are tests that catch that.

There, fixed.

Question: can there be multiple checkers per stage?  Doesn't necessarily make
sense to call two syntax checkers.  That's why I guess most of them are mutually
exclusive with ~conflicts-with~.

Well, looks like ~conflicts-with~ is the only way to control this.

* [2017-04-06 jeu.]
** Additional test support for rust-cargo                     :rust:flycheck:
So you can have [dev-dependencies] in your Cargo.toml file, which are
crate dependencies that should only be included in your compilation when you are
running tests, examples or benchmarks.

Problem: flycheck uses ~cargo rustc~, which totally ignores these dependencies.
The dev dependencies are added to rustc by ~cargo test~, ~cargo bench~ and
~cargo example~.

I can get the errors to work by doing:

: cargo rustc -- -Zno-trans
: cargo test --no-run

Problem: that's two commands.  So I use another checker to run the second
command, and use next-checker.  But, even with ~no-run~, ~cargo test~ /does/
build the tests.  So it's not as fast as it could, and you have to ~cargo clean~
before running the tests.

Besides, since you also have ~cargo bench~, I don't want to make 2 extra
checkers just for this case.

Better wait for ~cargo check~ to improve and check tests.

On the other hand, for two different runs to trigger in Flycheck, you need to
have changed your file.  So ~cargo test~ will run anew.

If we use ~cargo test~ to run the tests directly, then we don't need to call
~cargo rustc~ anymore, and can call ~cargo check~ directly.

Hmm, seems ~cargo test~ gives me the same errors than ~cargo check~ does, plus
it checks the code inside ~#[test]~.

Can I replace ~check~ by ~test~ when we should run tests?  And avoid the new checker?

Seems to work, except that both ~cargo test~ and ~cargo check~ will produce
warnings only the first time they are run, so for testing you have to clean
between tests.  And at runtime, say you edit a buffer, there are warnings, you
exit.  You run Emacs again: no warnings.  Make a change, edit the buffer: there
is the warning.  Or perhaps not.  I've got some weird flickering going on.

And: neither ~cargo test~ nor ~cargo check~ will run code in ~#[test]~ inside
examples.  Hmm, actually, that ones doesn't make sense.  Why would you put test
code in your examples?  Or even your binaries?

** Setting up sound in an HP EliteBook 840 G1                   :alsa:ubuntu:
Audio was not working on this machine.  And alsamixer was showing multiple
cards: Intel and ATI cards.  Unmuting channels didn't do anything.

dmesg showed errors related to the snd_hda_intel module and vga_switcheroo.

And,

: aplay -l

hung without showing any output.

This EliteBook laptop does not seem to have any model number marked anywhere.

: sudo dmidecode | grep -A5 '^System Information'
: System Information
:  Manufacturer: Hewlett-Packard
:  Product Name: HP EliteBook 840 G1

Good to know.  Then, head up to [[https://wiki.archlinux.org/index.php/HP_EliteBook_840_G1][the wiki]].

There you will find that audio needs some special options.  I'm not recompiling
my kernel to get HDMI audio.  But, putting

: options snd-hda-intel enable=1,1,0

in /etc/modprobe.d/snd-hda-intel.conf might have helped.

After that, I think the dmesg error disappeared.  At least, the ATI card
vanished from alsamixer.  aplay -l did not hang anymore, and showed just two
cards:

#+BEGIN_EXAMPLE
card 0: HDMI [HDA Intel HDMI], device 3: HDMI 0 [HDMI 0]
  Subdevices: 1/1
  Subdevice #0: subdevice #0
card 0: HDMI [HDA Intel HDMI], device 7: HDMI 1 [HDMI 1]
  Subdevices: 1/1
  Subdevice #0: subdevice #0
card 1: PCH [HDA Intel PCH], device 0: 92HD91BXX Analog [92HD91BXX Analog]
  Subdevices: 0/1
  Subdevice #0: subdevice #0
#+END_EXAMPLE

In alsamixer, unmuting the channels for the PCH card made the sound work.

Last bit: my i3 keybinding for muting/unmuting were set to toggle the "Master"
control.  Somewhat understandably, muting Master also muted the Speaker
control.  But, confusingly, unmuting Master left Speaker muted, rendering the
mute toggle useless.

The fix was found [[http://askubuntu.com/questions/339104/mute-key-mutes-master-and-headphone-speaker-alsa-channels-but-unmutes-only-ma][here]]:

: amixer -D pulse sset Master toggle

use the "pulse" device to mute/unmute the sound.  Since this is an Ubuntu
install, I have pulse installed and running.  Might as well use it.

* [2017-04-09 dim.]
** Reading Architecture of Open Source Applications             :types:elisp:
http://aosabook.org/en/index.html

Especially, the LLVM and GHC chapters.  Tidbits:

LLVM can be re-used piecewise.  Especially, you could write your own frontend to
generate LLVM IR, use LLVM to optimize the IR, then write your own backend to
emit whatever you want from this.

For instance, I guess one could write an Elisp frontend and benefit from the
LLVM optimizer, then write a backend that outputs Elisp bytecode.
Or even, native code that would be linked as an Emacs module.

From the GHC chapter:

"Notes" are a low-cost way of enhancing documentation in the code.  Instead of
making large, unwieldy comments next to the code, they just reference a note:

#+BEGIN_QUOTE
 data Type
   = FunTy Type Type -- See Note [Equality-constrained types]
#+END_QUOTE

Then the note appears elsewhere in the code:

#+BEGIN_QUOTE
  Note [Equality-constrained types]
  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  The type   forall ab. (a ~ [b]) => blah
  is encoded like this:

     ForAllTy (a:*) $ ForAllTy (b:*) $
     FunTy (TyConApp (~) [a, [b]]) $
     blah
#+END_QUOTE

And you can use standard tools to find the note definition and places where it
is used.

Also, they separate type checking into two phases: first, emit type constraints
from going through the code.  Then, solve these constraints.  The advantage of
this approach is that emitting constraint is rather straightforward code, so
it's easy to add constructs to the language.

The constraint solving is the heart of the type checker, but you don't have to
change it as often if you follow this approach.  They attribute this separation
scheme to "the French shool", which I guess means OCaml.

* [2017-04-20 jeu.]
** Synchronizing the sound in Boyo                                     :boyo:
Currently, the sound in Boyo works with a callback which fetches new samples
regularly from the application and sends them to the sound device for playback.

I've measured the times between each callback, and they are very consistent: the
callback asks for 4096 samples precisely every 92.87ms, which is exactly 4096 /
44100, the size of the buffer / the sample rate.

The buffer given to the callback is taken from an internal buffer that is filled
as we emulate.  When the callback arrives, we take 4096 samples off the internal
buffer, and send them to playback.

The problem is that our internal buffer is filling faster than it is pumped out.
So, the longer you let the emulator run, the larger the buffer becomes, and
there is an increasing larger delay between your actions and the audio feedback.

Currently, the emulator is timed by requestAnimationFrame, which should call us
back at exactly 60Hz, but might take more time depending on what goes on inside
or outside the browser (when compiling a Rust program on the side, I saw the
frame rate drop to 40Hz; also, running Boyo inside Chromium I can't get more
than 30Hz).

Here are some measures for each frame:

| Real time | Cycles | GB time |
|-----------+--------+---------|
| 16,1154   |  70680 | 16,8514 |
| 17,0825   |  70680 | 16,8514 |
| 17,0694   |  70680 | 16,8514 |
| 16,1492   |  70680 | 16,8514 |
| 17,8447   |  70680 | 16,8514 |
| 15,3163   |  70680 | 16,8514 |
| 17,0915   |  70680 | 16,8514 |
| 16,0937   |  70680 | 16,8514 |
| 17,0941   |  70680 | 16,8514 |
| 17,0772   |  70680 | 16,8514 |
| 16,1234   |  70680 | 16,8514 |
| 17,0956   |  70680 | 16,8514 |
| 16,1073   |  70676 | 16,8505 |
| 17,1078   |  70675 | 16,8502 |
| 16,0871   |  70680 | 16,8514 |
| 17,1007   |  70680 | 16,8514 |
| 16,1063   |  70680 | 16,8514 |
| 17,0725   |  70680 | 16,8514 |

Real time is the real time elapsed since the previous frame.  It measures the
frequency of the calls to gb.frame by requestAnimationFrame.

Cycles is the number of GB CPU cycles emulated during this time.  GB time is the
emulated time elapsed from the GB points of view, computed from the number of
cycles and the GB CPU frequency (4194304Hz).

Observations: the real time is hitting 60Hz but only on average.  Frame to
frame, we have wild variations.

On the other hand, the number of cycles is rather stable, and hence the GB time
is as well.  We are emulating the CPU, the APU and the PPU until a v-blank
happens, which is decided by Video.step.  This is usually 16.8514ms (but
sometimes a bit less), which corresponds to roughly 59.34Hz.

So, in perfect conditions, we should be calling gb.frame at 59.34Hz to avoid
overfilling the buffer.  So even in perfect conditions, using
requestAnimationFrame to drive the emulation is not a good idea.

I've looked at this emu: https://github.com/jbergknoff/nes/ which seems clean
enough to me.  They run the whole emulated system in a WebWorker, which
interacts with the page only with a few messages:

- ready (when the Worker is fully setup)
- screen (when a GB vblank occurs)
- audio (when a frame's worth of audio has been accumulated)
- log (for debugging, since the worker can't use console.log)

The HTML page runs a requestAnimationFrame at 60Hz, which calls the worker to
run for the amount of time elapsed since the last call.

The worker then decides how long to run based on the number of audio samples it
should output given this time delta.  Importantly, they use loops like this:

#+BEGIN_SRC js
while (PPUCycleCounter > NES.CyclesPerPixel) {
  PPU.Tick();
  PPUCycleCounter -= NES.CYclesPerPixel;
}
#+END_SRC

to ensure that leftover cycles are not dropped, and taken care in subsequent
calls.

Now of course we can have frame drops.  Using this worker scheme, the worker.run
method would try to catch up based on how long it has been since last frame
(say, 33ms) and double the work.

I think I can do the same thing, without a worker to begin with, by modifying
gb.frame to run not until vblank, but until we have created enough samples for
the time elapsed since the last frame.

[hours later]

Ahah!  Success!  Some audio buffer underruns at start, and from time to time,
but no overruns even after letting it run for a few minutes.

I didn't have to change too many things, mainly running gb.frame to run until we
have caught up with the cycles that have elapsed since the last frame.

Now that I think of it, we have two callbacks asking for pieces of the emu: the
audio callback that's asking for audio samples, and the requestAnimationFrame
callback that we use to drive the emulation.

Might be better to just use the audio one, emulate enough cycles to fill the
buffer, and continue.  That way, we wouldn't get into underruns, since we would
always fill the buffer with the right number of samples.  However, the default
buffer size of 4096 would translate into a callback every 93ms, so that would
increase the visual and input latency.  Maybe if I can set the buffer to 1024,
that would give us 23ms to emulate, which still loses frames, but shouldn't be
that noticeable.

* [2017-04-21 ven.]
** Emacs org-mode doesn't eval                                    :emacs:org:
C-c C-c is stubborn: evaluation of this code block is disabled, it keeps telling
me.  Even for elisp blocks, which should be enabled by default.

Turns out, it's [[https://github.com/syl20bnr/spacemacs/issues/7641][a bug]].  The correct procedure is to remove all elc files for
org-contrib:

: find elpa/org-plus-contrib-* -name '*.elc' -delete

Then it works.  But better to recompile using:

: (byte-recompile-directory (file-name-directory (buffer-file-name)) 0)

Since passing the prefix arg with SPC-u did not seem to work.

Arrgh, then a simple Dot example fails with "void symbol: result-params".  This
symbol is nowhere to be found in the source.. puzzling.  Okay, let's invoke dot
manually then.

* [2017-04-23 dim.]
** Boyo abysmal performance in Chrome                               :boyo:js:
In Firefox, it's mostly smooth as butter.  Steady 60FPS on Tetris.

Chrome can't keep up, and freezes, hard.  I've added logic to measure the time
spent each frame, and pause the emulation if it looks like we emulate fast
enough.  Here's how it looks for Chromium 58:

#+BEGIN_EXAMPLE
- Frame stats
Real time since last frame: 0.000ms
Cycles to emulate: 0
Cycles emulated: 0
GB time emulated: 0.000ms
Time spent: 0.000ms
- Frame stats
Real time since last frame: 16.67ms
Cycles to emulate: 69902.27046394348
Cycles emulated: 69904
GB time emulated: 16.67ms
Time spent: 34.85ms
- Frame stats
Real time since last frame: 34.28ms
Cycles to emulate: 143780.74112033844
Cycles emulated: 143780
GB time emulated: 34.28ms
Time spent: 39.72ms
Audio buffer underrun: -1850 samples
- Frame stats
Real time since last frame: 33.33ms
Cycles to emulate: 139804.54092788696
Cycles emulated: 139808
GB time emulated: 33.33ms
Time spent: 35.15ms
- Frame stats
Real time since last frame: 33.46ms
Cycles to emulate: 140328.82892799377
Cycles emulated: 140328
GB time emulated: 33.46ms
Time spent: 39.22ms
- Frame stats
Real time since last frame: 50.01ms
Cycles to emulate: 209744.56012821198
Cycles emulated: 209744
GB time emulated: 50.01ms
Time spent: 50.05ms
=> Can't keep up emulation, pausing emulator
frame @ gb.js:157
#+END_EXAMPLE

First frame is all good: nothing happens.

Second frame is called after 16.67ms, looking good.  We must emulate 16.67ms
worth of GB time, but here's the first snag: we spend 34.85ms doing it.  That
means the emulation speed is not fast enough to accurately emulate the system in
realtime!

Third frame is called late, since we spent too much time in the previous one.
This time the JIT might already have kicked in, since the delta between GB time
and time spent in emulation is smaller.  But we are still too short.

After the fifth consecutive frame too late, we drop it.

Here's what I get in Firefox 53 for the first frames:

#+BEGIN_EXAMPLE
- Frame stats
Real time since last frame: 0.000ms
Cycles to emulate: 0.000000
Cycles emulated: 0
GB time emulated: 0.000ms
Time spent: 0.000ms
- Frame stats
Real time since last frame: 33.20ms
Cycles to emulate: 139258.547405
Cycles emulated: 139264
GB time emulated: 33.20ms
Time spent: 58.12ms
- Frame stats
Real time since last frame: 216.4ms
Cycles to emulate: 907444.217709
Cycles emulated: 907444
GB time emulated: 216.4ms
Time spent: 169.4ms
- Frame stats
Real time since last frame: 166.9ms
Cycles to emulate: 699957.040382
Cycles emulated: 699952
GB time emulated: 166.9ms
Time spent: 63.89ms
- Frame stats
Real time since last frame: 225.4ms
Cycles to emulate: 945582.390641
Cycles emulated: 945584
GB time emulated: 225.4ms
Time spent: 80.06ms
#+END_EXAMPLE

First frame, nothing happens.

Second frame is called after 33ms... err, that's bad, but might be due to the
overhead of the logging.  Firefox is not particularly snappy when the console is
open.  Anyway, we take too long emulating this one.

Third frame: took a long time to be called, lot of emulation to be done.  But
already the ratio is positive: 169ms to emulate 216ms worth of GB time.

And it keeps decreasing.

Maybe we should let the JITs warmup a bit by running full speed behind the scenes.

Well, I'm not sure I've done this right, but that doesn't seem to have had any
effect in any case.

* [2017-04-30 dim.]
** Synchronizing Boyo to the sound callback only                       :boyo:
Instead of having two callbacks: one for emulating based on the time elapsed
since last frame, and one to fill the audio buffer, we could have just one.
Since the audio callback is a "pull" callback (it's waiting for an exact number
of samples), and the video callback is "push" (we emulate and push frames to the
screen without being asked), we have to use the audio callback.

The theory is this: when the audio callback is called, it asks for, say, 4096
samples.  At a 44100 sample rate, that's:

4096 / 44100 = 92.87ms

93ms worth of GB time to emulate, which is:

4096 / 44100 * 4194304 = 389566.19 cycles

If we emulate exactly 389567 cycles, we will get enough samples to completely
fill the buffer, and we shouldn't run into buffer underruns.

However, that means we catch up the emulator every 93ms.  We emulate the CPU,
then the video and audio units.  In that timeframe, the video will push 5 frames
to the canvas in rapid succession.  At 3GBPS, 93ms should be emulated in 30ms,
so we would have 5 frames in 30ms, then a pause for 93ms, then 5 frames in
30ms...  We will have an extremely choppy framerate (and input reading would be
choppy as well).

If we use a smaller audio buffer, like 512, that's:

512 / 44100 = 11.6ms

Is this small enough?  Not really:


#+BEGIN_EXAMPLE
         11.6ms       23.2ms      34.8ms      46.4ms
-----------|----*-------|---------*-|-----------|---*--
           +----        +--^-       +--^-       +----
                          26ms        37ms

|: audio callback
+: start emulation
^: render video frame
*: ideal frame push
#+END_EXAMPLE

Again, choppy frames.  The only thing we avoid is to push two video frames in
the same emulation frame, since our interval is smaller than 60Hz.  But our
video framerate is still inconsistent.

256?

256 / 44100 = 5.8ms

#+BEGIN_EXAMPLE
    5.8   11.6   17.4   23.2    29   34.8   40.6  46.4   52.2    58
-----|------|----*-|------|------|---*-|------|-----|---*--|------|--
     +--    +--    +-^    +--    +--   +-^    +--   +--    +-^    +--
                    19ms                36ms                54ms
#+END_EXAMPLE

Still not quite in sync, but the difference with an ideal 59.34Hz is not that
far off; at least at the start.  Since the frequencies are not multiple of each
other, there will be a drift over time.

The problem is, we can't have multiples since the audio buffer sizes are limited
to powers of two.  And we have:

16.85ms * 44100 = 743.085 samples

The nearest approximation is 3 * 256 = 768; we can see that in the example above
that an ideal video frame happens nearly every three audio frame.  But we end up
with an effective:

44100 / 768 = 57.42Hz

Not accurate.  Close enough?  Without a true multiple, there might be times
where we push out a video frame too soon.

Another issue is that I fear that 5.8ms is a hard target to hit reliably in the
navigator.

Trying it out, the audio doesn't seem glitchy.  With a 512 samples buffer, the
emulator seems able to keep up.  However, the emulation is too fast.  Need to
measure in order to understand.

But there may be another solution to avoid underruns.  The problem is that,
sometimes, we don't emulate enough samples just by being driven by the video
callback.  Then, when we detect an underrun, we could just emulate the GB to get
the missing audio samples.  The underruns I notice in Firefox are between 10 and
500 samples.  That's around 11ms max.

The problem with this approach is that if we take too long to get the samples,
the audio device might have played them already, and we still get an underrun.

There's no substitute to running very fast.

* [2017-04-27 jeu.]
** Improving Boyo                                                      :boyo:
I've implemented the sweep channel, at last.  I remember that I did not
understand how it to implement it for the initial audio work on Boyo.  But
sticking to Blargg's doc and double checking with the GB programming manual, it
wasn't that complex.

Chrome performance is still trash.

Some lingering issues:

1. Switching to new ROM does not work as reliably as reloading the web page.  We
   are probably not resetting everything as we should.

   Probably related: Pokemon Red does not boot after F5, but if I first load a
   demo rom, then Pokemon, it works alright.

2. F5, switch to another tab, come back to Boyo: the emulator starts even though
   we haven't loaded any ROM.

3. Selecting the same ROM in the drop list does not restart emulation

Okay I've fixed #2 and added a Pause/Resume button.  Now fixed #3 by adding a
Reset button which serves the same purpose as reloading the same ROM, since the
change event cannot fire if we select the same item.  We could workaround it
with mouseup, but it's messy.

Now #1 is fixed.  Most reset functions of the modules were in fact empty.  I
just needed to zero all RAM and visual artifacts disappeared.

I've added a measure for GBPS, GameBoy per second.  Since we measure how much GB
time we emulated, and how much real time it took us to emulate it, we can
extrapolate:

: gb_time / emu_time = how many GB we could emulate per second at the current speed

This is a more telling measure than FPS, since if GBPS > 1, we know we have room
for computing, and how much.  If GBPS <= 1, we barely can keep up emulating, and
we have to stop.

Using mrdoob/stats, this was easy to add.  This was what we were already using
for the FPS counter, which I never cared much about.  But in fact, you can add
custom panels!  The version we included used a bunch of spans to draw the stats,
which I would assume is slower than canvas.  But I've updated it to the latest
version, and it does use canvas now.

Okay so in Firefox I get solid 3GBPS in Tetris, on the title screen and in-game.
On Zelda, it's more around 1.4.  Kirby is around 2.5.

So, some games are more stressing than others; might keep this in mind when
trying to optimize.

Also, even when staying well above 1GBPS, I still get audio buffer underruns.
That means they are not due to a temporary drop in emulation speed, but rather
to a bad synchronization between the audio buffer callback and the animation
frame callback.

* [2017-05-04 jeu.]
** Chrome performance and Boyo                                  :chrome:boyo:
Here are a few resources on the topic of V8 optimizations:

https://developers.google.com/web/tools/chrome-devtools/evaluate-performance/
https://github.com/thlorenz/v8-perf/blob/master/compiler.md
https://github.com/petkaantonov/bluebird/wiki/Optimization-killers
https://github.com/vhf/v8-bailout-reasons

So, according to the third link, functions with ~get~ cannot be optimized.
In previous Chrome versions there used to be a warning sign next
to an unoptimized function in the profiler, giving you the reason for
the optimizer bailout.  However, either the compiler can optimize everything, or
I cannot find these warnings anymore in the dev tools.

Let's see.  If I add eval, with and a try/catch, I'm pretty sure the compiler is
unable to optimize them right?

Hmm, no warnings.  So either the compiler has gotten quite smart, or my Chromium
build is funky.  Let's try, /sigh/, Chrome.

Same thing: no bailout indication.  No hit on the Chromium bug tracker.  I'm in
the dark here.

According to the profiler, we spend most of the time in Video.scan_background.
I'll try to rewrite the video part using a straightforward JS function object,
and get rid of the get/set which might be optimization killers.

Aaah, looking down in the call tree, I spot a small "[deopt]", with a bailout
reason on hover.  They removed the warning flags.  So these bailouts are still
working.  Maybe V8 can now optimize more constructs.

[hours later]

Okay, so I rewrote the video using a function object.  I also removed the
indirection in the memory reading: we used to call functions for every read and
write that dispatched to the correct module.  I've changed it to a dumb switch,
which still dispatches to each module; that's one indirection fewer.

From what I can see, getters/setters where definitely performance killers in
V8.  Now I get 2.4GBPS in Tetris, up from 0.5.  That means it's playable!

Firefox seems to have benefited, if only from the change to the memory r/w.

Although, the video is a bit broken at the moment.  Objects are invisible.
Debugging that after a rewrite is a pain...

Though I managed to fix a bug: writing to LY should reset the counter, not set
it to an arbitrary value.  This was used mostly in demos, where manipulating the
counter is a known way to make neat effects.

[one hour later]

I rewrote the video module, again.  This time, I just removed the getter/setter
and left the rest intact.  I get decent Chrome performance now (2.4GBPS without
audio).  So the get/set really are perf killers.  The objects are back.
However, the palette of object is all wrong...  It can be fixed by selecting the
palette again from the menu.

Oh right, I forgot to update the cached palettes when writing new values.
Fixed.

All good now.

Okay so after cleaning up, in-game Tetris I get between 2 and 3GBPS with
Firefox, and 2.3GBPS with Chrome.  Chrome performance is much much more stable
than Firefox.  Firefox has much higher variation from frame to frame.

All ROMs are not equal however.  Zelda and demos are more demanding.

Donkey Kong Land for instance stutters below 1GBPS in-game.  It spends much time
in scan_pixel:

#+BEGIN_SRC js
scan_pixel: function(x, y, color) {

  var index = (y * 160 + x) * 4;
  buffer.data[index] = color[0];
  buffer.data[index + 1] = color[1];
  buffer.data[index + 2] = color[2];
  buffer.data[index + 3] = color[3];
},
#+END_SRC

I tried to use buffer.data.set(index, color).  But then I get errors, since
apparently the index can both be: 1) larger than the ImageData, and 2) negative.

Surely this confuses the compiler, and we can't get fast code for updating this
array.  Need to look into how the bogus indices happen.

* [2017-05-08 lun.]
** Further Boyo optimizations                                          :boyo:
I tried to remove all get/set in the code.  That did not result in any
noticeable performance increase.  If anything, the performance seemed less
stable overall without them, and for a small increase in code size.  So I will
leave it at that.

** Trying out Rust to WebAssembly                                 :rust:wasm:
Here is [[https://hackernoon.com/compiling-rust-to-webassembly-guide-411066a69fde][a guide]].  The steps are not complicated with rustup:

: rustup target add wasm32-unknown-emscripten

I also need Emscripten:

: sudo pacman -S emscripten

Using ArchLinux, 1.37 is in the repo, so I don't have to compile it myself.

Then, to use it:

: rustc --target wasm32-unknown-emscripten hello.rs -o hello.html

A 3 lines Rust file is turned into >1M of WASM and HTML.

Opening the HTML file in the browser, you are greeted with an Emscripten shell.
It works.

Now for the slightly more involved stuff.  Trying to build my Karplus-Strong example:

: cargo build --target wasm32-unknown-emscripten

#+BEGIN_EXAMPLE
          asm2wasm: ~/.emscripten_ports/binaryen/binaryen-version_30/src/asm2wasm.h:1476: void wasm::Asm2WasmBuilder::processAsm(cashew::Ref): Assertion `WasmValidator().validate(wasm)' failed.
          Traceback (most recent call last):
            File "/usr/lib/emscripten/emcc.py", line 2383, in <module>
              run()
            File "/usr/lib/emscripten/emcc.py", line 2162, in run
              subprocess.check_call(cmd)
            File "/usr/lib/python2.7/subprocess.py", line 186, in check_call
              raise CalledProcessError(retcode, cmd)

error: aborting due to previous error
#+END_EXAMPLE

Cool.  So, it converts asm to wasm, and in the process, some constructs are not
supported or badly generated.

I don't wish to delve on this right now.  The setup process is easy enough, but
the tool itself is still rough.

** Partial evaluation on Boyo                                         :boyo:
Oh yeah, I also tried to use [[https://prepack.io/][prepack]], a partial evaluator for JS, to try to see
if it would generate more efficient code.  Not really.

However, I tried it on the concatenated scripts in the src/ folder.  I think one
immediate application would be to partially evaluate the instructions file
statically rather than at runtime.

Hmm, no, doesn't do anything useful.  Of course, the instructions created at
runtime are functions, and I want something like macros...

I guess I could simply evaluate the instructions file.

Doesn't work... but that's because we don't call ~generate~ statically.  If we
do call ~generate~ inside instructions.js and return the table of generate
instructions, prepack is able to eliminate the opcode table and generate code
for the instructions directly.

But do we gain anything?  Startup time of Boyo should be up (though we have more
JS to parse).

Hmm, performance difference is not really noticeable.  And startup time was not
long to begin with.

Still, prepack seems to work decently, so that's something.

** Pondering using micro-opcodes for GB emulators                      :boyo:
So, I was reminded of [[https://www.youtube.com/watch?v=y71lli8MS8s][this video]] which shows a full NES emulator is less than
1000 lines of C++.

Since my GB CPU in Rust is already more than 2000 lines, I was gobsmacked.
Especially since the CPU of this video actually fits in 80 lines.

Here it is, for posterity ([[http://bisqwit.iki.fi/jutut/kuvat/programming_examples/nesemu1/nesemu1.cc][full source]]):

#+BEGIN_SRC c++
template<u16 op> // Execute a single CPU instruction, defined by opcode "op".
    void Ins()       // With template magic, the compiler will literally synthesize >256 different functions.
    {
        // Note: op 0x100 means "NMI", 0x101 means "Reset", 0x102 means "IRQ". They are implemented in terms of "BRK".
        // User is responsible for ensuring that WB() will not store into memory while Reset is being processed.
        unsigned addr=0, d=0, t=0xFF, c=0, sb=0, pbits = op<0x100 ? 0x30 : 0x20;

        // Define the opcode decoding matrix, which decides which micro-operations constitute
        // any particular opcode. (Note: The PLA of 6502 works on a slightly different principle.)
        enum { o8 = op/8, o8m = 1 << (op%8) };
        // Fetch op'th item from a bitstring encoded in a data-specific variant of base64,
        // where each character transmits 8 bits of information rather than 6.
        // This peculiar encoding was chosen to reduce the source code size.
        // Enum temporaries are used in order to ensure compile-time evaluation.
        #define t(s,code) { enum { \
            i=o8m & (s[o8]>90 ? (130+" (),-089<>?BCFGHJLSVWZ[^hlmnxy|}"[s[o8]-94]) \
                              : (s[o8]-" (("[s[o8]/39])) }; if(i) { code; } }

        /* Decode address operand */
        t("                                !", addr = 0xFFFA) // NMI vector location
        t("                                *", addr = 0xFFFC) // Reset vector location
        t("!                               ,", addr = 0xFFFE) // Interrupt vector location
        t("zy}z{y}zzy}zzy}zzy}zzy}zzy}zzy}z ", addr = RB(PC++))
        t("2 yy2 yy2 yy2 yy2 XX2 XX2 yy2 yy ", d = X) // register index
        t("  62  62  62  62  om  om  62  62 ", d = Y)
        t("2 y 2 y 2 y 2 y 2 y 2 y 2 y 2 y  ", addr=u8(addr+d); d=0; tick())              // add zeropage-index
        t(" y z!y z y z y z y z y z y z y z ", addr=u8(addr);   addr+=256*RB(PC++))       // absolute address
        t("3 6 2 6 2 6 286 2 6 2 6 2 6 2 6 /", addr=RB(c=addr); addr+=256*RB(wrap(c,c+1)))// indirect w/ page wrap
        t("  *Z  *Z  *Z  *Z      6z  *Z  *Z ", Misfire(addr, addr+d)) // abs. load: extra misread when cross-page
        t("  4k  4k  4k  4k  6z      4k  4k ", RB(wrap(addr, addr+d)))// abs. store: always issue a misread
        /* Load source operand */
        t("aa__ff__ab__,4  ____ -  ____     ", t &= A) // Many operations take A or X as operand. Some try in
        t("                knnn     4  99   ", t &= X) // error to take both; the outcome is an AND operation.
        t("                9989    99       ", t &= Y) // sty,dey,iny,tya,cpy
        t("                       4         ", t &= S) // tsx, las
        t("!!!!  !!  !!  !!  !   !!  !!  !!/", t &= P.raw|pbits; c = t)// php, flag test/set/clear, interrupts
        t("_^__dc___^__            ed__98   ", c = t; t = 0xFF)        // save as second operand
        t("vuwvzywvvuwvvuwv    zy|zzywvzywv ", t &= RB(addr+d)) // memory operand
        t(",2  ,2  ,2  ,2  -2  -2  -2  -2   ", t &= RB(PC++))   // immediate operand
        /* Operations that mogrify memory operands directly */
        t("    88                           ", P.V = t & 0x40; P.N = t & 0x80) // bit
        t("    nink    nnnk                 ", sb = P.C)       // rol,rla, ror,rra,arr
        t("nnnknnnk     0                   ", P.C = t & 0x80) // rol,rla, asl,slo,[arr,anc]
        t("        nnnknink                 ", P.C = t & 0x01) // lsr,sre, ror,rra,asr
        t("ninknink                         ", t = (t << 1) | (sb * 0x01))
        t("        nnnknnnk                 ", t = (t >> 1) | (sb * 0x80))
        t("                 !      kink     ", t = u8(t - 1))  // dec,dex,dey,dcp
        t("                         !  khnk ", t = u8(t + 1))  // inc,inx,iny,isb
        /* Store modified value (memory) */
        t("kgnkkgnkkgnkkgnkzy|J    kgnkkgnk ", WB(addr+d, t))
        t("                   q             ", WB(wrap(addr, addr+d), t &= ((addr+d) >> 8))) // [shx,shy,shs,sha?]
        /* Some operations used up one clock cycle that we did not account for yet */
        t("rpstljstqjstrjst - - - -kjstkjst/", tick()) // nop,flag ops,inc,dec,shifts,stack,transregister,interrupts
        /* Stack operations and unconditional jumps */
        t("     !  !    !                   ", tick(); t = Pop())                        // pla,plp,rti
        t("        !   !                    ", RB(PC++); PC = Pop(); PC |= (Pop() << 8)) // rti,rts
        t("            !                    ", RB(PC++))  // rts
        t("!   !                           /", d=PC+(op?-1:1); Push(d>>8); Push(d))      // jsr, interrupts
        t("!   !    8   8                  /", PC = addr) // jmp, jsr, interrupts
        t("!!       !                      /", Push(t))   // pha, php, interrupts
        /* Bitmasks */
        t("! !!  !!  !!  !!  !   !!  !!  !!/", t = 1)
        t("  !   !                   !!  !! ", t <<= 1)
        t("! !   !   !!  !!       !   !   !/", t <<= 2)
        t("  !   !   !   !        !         ", t <<= 4)
        t("   !       !           !   !____ ", t = u8(~t)) // sbc, isb,      clear flag
        t("`^__   !       !               !/", t = c | t)  // ora, slo,      set flag
        t("  !!dc`_  !!  !   !   !!  !!  !  ", t = c & t)  // and, bit, rla, clear/test flag
        t("        _^__                     ", t = c ^ t)  // eor, sre
        /* Conditional branches */
        t("      !       !       !       !  ", if(t)  { tick(); Misfire(PC, addr = s8(addr) + PC); PC=addr; })
        t("  !       !       !       !      ", if(!t) { tick(); Misfire(PC, addr = s8(addr) + PC); PC=addr; })
        /* Addition and subtraction */
        t("            _^__            ____ ", c = t; t += A + P.C; P.V = (c^t) & (A^t) & 0x80; P.C = t & 0x100)
        t("                        ed__98   ", t = c - t; P.C = ~t & 0x100) // cmp,cpx,cpy, dcp, sbx
        /* Store modified value (register) */
        t("aa__aa__aa__ab__ 4 !____    ____ ", A = t)
        t("                    nnnn 4   !   ", X = t) // ldx, dex, tax, inx, tsx,lax,las,sbx
        t("                 !  9988 !       ", Y = t) // ldy, dey, tay, iny
        t("                   4   0         ", S = t) // txs, las, shs
        t("!  ! ! !!  !   !       !   !   !/", P.raw = t & ~0x30) // plp, rti, flag set/clear
        /* Generic status flag updates */
        t("wwwvwwwvwwwvwxwv 5 !}}||{}wv{{wv ", P.N = t & 0x80)
        t("wwwv||wvwwwvwxwv 5 !}}||{}wv{{wv ", P.Z = u8(t) == 0)
        t("             0                   ", P.V = (((t >> 5)+1)&2))         // [arr]
        /* All implemented opcodes are cycle-accurate and memory-access-accurate.
         * [] means that this particular separate rule exists only to provide the indicated unofficial opcode(s).
         */
    }
#+END_SRC

At first, that's totally unreadable.  But the author does a good job of
explaining the concept in [[https://www.youtube.com/watch?v=QIUVSD3yqqE][another video]].

Basically, opcodes are cut into micro-opcodes: change this flag, add from this
register, set PC, etc.  All GB opcodes conceptually use a finite number of such
micro-opcodes, so we can actually describe the full effect of the opcode by
giving its list of micro-opcodes.

In the code above, the micro-opcodes are on the right.  On the left is a
base256-encoded string that tells, for each NES opcode, if it should execute the
micro-opcode on this line.  Decoded to binary, the string is just a bitset:

100101011110111....

If the bit N is set for the micro-opcode M, it indicates that opcode N should
execute M, and so on.

In the function above, one difficulty arise: the order of execution of the
micro-opcodes is set in stone.  Affectation micro-ops come first, then
computation (add/sub/and...), and flags are set at the end.  Since the structure
of opcodes tend to be highly repetitive, I guess this is fine, but you have to
find the right order of execution to describe all opcodes correctly.

Also, finding the encoding values is certainly a pain.  The author wrote a PHP
program to do that, so in terms of overall code complexity, you don't
necessarily benefit.

And ultimately, this is probably less efficient than a straightforward switch
for the opcodes themselves.  Lots of jumping around, since you are testing, for
every micro-op, if the opcodes should execute it or not.  And do that for each
opcode.

However, the micro-opcode approach reminds of ZINC by Leroy.  Here we have
around 65 micro-opcodes here for 256 opcodes.  Fewer opcodes lead to a smaller
interpreter.  A smaller interpreter might be more efficient, cache-wise.

I would be interested in seeing perf comparisons of a micro-opcode interp
approach versus an opcode interp.

* [2017-05-11 jeu.]
** A new chip: the YM2612                                            :genesis:
Now that Boyo is in an acceptable shape, it's time to step up.  Next chip: the
YM2612, the audio chip that's in the Genesis (though Megadrive is the better
name.)

First things first, cloning the emulator that Merwan started, and trying to
compile it.  And putting the Streets of Rage OST in the background.

There are no makefiles, only visual studio project files.  Can I convert from
them?

Apparently, [[http://stackoverflow.com/questions/6649606/how-to-support-both-vcxproj-to-cmake-on-a-project][yes]].  But do I want or need CMake?  Just plain makefiles should do
it.  [[http://stackoverflow.com/questions/870533/where-can-i-find-a-tool-to-convert-a-vs-solution-to-a-gcc-makefile][Wine has something]] for plain Makefiles.  Let's try that first.

Hmm ok, winemaker creates a Makefile for creating exe.

Let's go by hand then.

Oh my, it's full of warnings!  And unfortunately, some error as well.

: operands.c:374:142: error: void value not ignored as it ought to be
: ISTER(extension) (BIT(extension, 15) ? o->instruction->context->address_registers : o->instruction->context->data_registers)[FRAGMENT(e

Macro errors, yum!

Apparently, gcc and clang cannot handle this correctly, even though it seems
correct at first glance.  One fix is to pull the [FRAGMENT(...)] index into both
branches of the ternary operator.

: #define INDEX_REGISTER(extension) ((BIT((extension), 15) ? o->instruction->context->address_registers[FRAGMENT((extension), 14, 12)] : o->instruction->context->data_registers[FRAGMENT((extension), 14, 12)]))

Another error:

: m68k.c:161:9: error: non-void function 'm68k_step' should return a value [-Wreturn-type]
:        return;

That one is easy.  Strange that it compiles under MSVC though.

Anyway, three Makefile later, it compiles.  Maybe I need a ROM now.  Merwan told
me that Tetris was working.  Tetris?  On Megadrive?  What kind of heresy is
this?  There's only Columns... but alas, Columns does not show anything
interesting.

On the other hand... Tetris, ladies and gentlemen:

[[file:data/genesis-tetris.png]]

I guess we have debugging views directly into VRAM, palettes, and such.  Neat to
see every thing lighting up.

The emulator is hugging my CPU to death... good thing it's not in JavaScript.
Maybe if I toggle off the writes to the console.  It's currently dumping every
opcode.

Startup time is better with the debug output behind an #ifdef.  Still 100% CPU
time while running, and the game don't appear to run faster than they
should... maybe slower in fact.

Oh wait, I didn't turn optimizations on.  Hmm, not much of a difference with
-O3. Monopoly and Tetris seem fine, but Bloodlines look slow.

Okayyy.  Now, I would like to put the base of sound emulation.  Would be great
if the SEGA logo could sing.

Reading docs:
http://md.squee.co/YM2612
http://www.smspower.org/maxim/Documents/YM2612

(most of the info in these two overlap)

Okay so poking register $22 should start to play sounds.  Let's see if we can
get the CPU to write to this location.

Hmm, where's register $22?  The doc says you need to write at $A04000-A04001,
but that's only one byte, not one page.

I see that there are single-byte read/writes and "wide", two-bytes, read/writes.
The video module uses it.  Maybe one byte can be used to specify the register?

Hmm, nothing is written at these addresses by the working ROMs.  Let's check the
whole $A04100 range to be sure.  Still nothing.

Oh wait, Sonic 1 writes there!

#+BEGIN_EXAMPLE
sound write: a04000 2b
sound write: a04001 80   ; enable DAC
sound write: a04000 27
sound write: a04001 00   ; reset timers
sound write: a04000 28
sound write: a04001 02   ; mute channel 3
sound write: a04000 28
sound write: a04001 06   ; mute channel 6
sound write: a04000 28
sound write: a04001 01   ; mute channel 2
sound write: a04000 28
sound write: a04001 05   ; mute channel 5
sound write: a04000 28
sound write: a04001 00   ; mute channel 1
sound write: a04000 28
sound write: a04001 04   ; mute channel 4
sound write: a04000 40
sound write: a04001 7f   ; set max total level for ch1/op1
sound write: a04002 40
sound write: a04003 7f   ; set max total level for ch3/op1
sound write: a04000 44
sound write: a04001 7f   ; etc...
sound write: a04002 44
sound write: a04003 7f
sound write: a04000 48
sound write: a04001 7f
sound write: a04002 48
sound write: a04003 7f
sound write: a04000 4c
sound write: a04001 7f
sound write: a04002 4c
sound write: a04003 7f
sound write: a04000 41
sound write: a04001 7f
sound write: a04002 41
sound write: a04003 7f
sound write: a04000 45
sound write: a04001 7f
sound write: a04002 45
sound write: a04003 7f
sound write: a04000 49
sound write: a04001 7f
sound write: a04002 49
sound write: a04003 7f
sound write: a04000 4d
sound write: a04001 7f
sound write: a04002 4d
sound write: a04003 7f
sound write: a04000 42
sound write: a04001 7f
sound write: a04002 42
sound write: a04003 7f
sound write: a04000 46
sound write: a04001 7f
sound write: a04002 46
sound write: a04003 7f
sound write: a04000 4a
sound write: a04001 7f
sound write: a04002 4a
sound write: a04003 7f
sound write: a04000 4e
sound write: a04001 7f
sound write: a04002 4e
sound write: a04003 7f
#+END_EXAMPLE

Okay so there definitely is a pattern there: writes come in pair, to $A04000
then $A04001.  The first write appears to select the register: $2B would be the
DAC enable, which is consistent with the write to the bit 7 that follows.

I've annotated by following the reference document at:
http://www.smspower.org/maxim/Documents/YM2612

Oh hey, this doc actually explained the write to A04000/A04001 for writing to
part 1 registers; I missed that.

Hmm so this looks like resetting the audio to sane values.  Unfortunately,
letting Sonic run, I see not write to $28 which set the operators on, so it
seems we have no ROM actually playing sound... using the M68k!

The various docs mention the Genesis has two CPUs (I wasn't aware of that!), and
the Z80 is the CPU used for sound... so most games would use this CPU for
driving the YM2612!

And alas, the Z80 is unimplemented for now... I guess I know what's the next
step then.  Good thing that the Z80 is pretty close to the GB CPU.

I could even write the audio part in Rust and interface with the rest of the
emu... tempting, but that would certainly complicate the build.

More importantly, I need to find documentation on the operators themselves,
since they are at the heart of the YM2612.

[[http://gendev.spritesmind.net/forum/viewtopic.php?f=24&t=386&start=150][This thread]] seems to be rich with information, but it's 56 pages long at the
moment (and going!).  [[http://gendev.spritesmind.net/forum/viewtopic.php?f=24&t=386&start=150][This post]] tries to index the nuggets.  Overall, this forum
seems like a good source.

And then, of course, source code of accurate emulators.  Like [[https://bitbucket.org/exodusemulator/exodus/src/ceac297d914fc0d5f2b10225dbb89d56be4ebbe5/Devices/YM2612/YM2612.cpp?at=default&fileviewer=file-view-default][Exodus]].

Hmm wait, I don't see any magical code that creates a guitar sound or brass, or
organ in that code.  I'm thinking the operators are what the doc says: functions
which modify their input given a frequency and envelope.  They can feed into
each other, depending on the setup (the "algorithm").  That's what FM is all
about.  Maybe I can try something in Sunvox later to confirm this theory...

* [2017-05-18 jeu.]
** Emulating the Z80                                                :genesis:
Useful docs:

[[https://raw.githubusercontent.com/Emu-Docs/Emu-Docs/master/Shared%2520Components/CPU%2520Z80/z80-1-command-set.txt][Opcode table]]
[[https://raw.githubusercontent.com/Emu-Docs/Emu-Docs/master/Shared%2520Components/CPU%2520Z80/z80-1-command-set.txt][Summary with cycle count]]
[[https://raw.githubusercontent.com/Emu-Docs/Emu-Docs/master/Shared%2520Components/CPU%2520Z80/z80-1-command-set.txt][Most exhaustive document]]

Now, already I'm confused by the different cycle counts in the documents.  Maybe
they refer to Z80 used in different systems?

In any case, I didn't want to write out all the instructions as I did for the GB
CPU.  Generating the instructions, like Merwan did for Boyo, is probably the
less painful.

However I want to generate very plain C code with a large C switch-case.

I've started writing a code generator (in Rust, eh).  I managed to do all the LD
instructions from the first opcode table.  Like the GB CPU, the Z80 has opcode
prefixes, but more than the GB.

The hard part of writing the generator is to find out the minimal set of
micro-operations that you need in order to define all the opcodes faithfully.
What I need is to find the eigenvectors, but I'm struggling a bit by hand.

Looking at the reference:

#+BEGIN_EXAMPLE
|LD r,r      |r:=r                |......| 1 | 4 |                      |
|LD r,(HL)   |r:=(HL)             |      | 1 | 7 |                      |
|LD r,n      |r:=n                |      | 2 | 7 |                      |
|LD r,(ii+n) |r:=(ii+n)           |      | 3 |19 |                      |
|LD (HL),r   |(HL):=r             |      | 1 | 7 |                      |
|LD (ii+n),r |(ii+n):=r           |      | 3 |19 |                      |
|LD (HL),n   |(HL):=n             |      | 2 |10 |                      |
|LD (ii+n),n |(ii+n):=n           |      | 4 |19 |                      |
|LD A,(BC)   |A:=(BC)             |      | 1 | 7 |                      |
|LD A,(DE)   |A:=(DE)             |      | 1 | 7 |                      |
|LD A,(nn)   |A:=(nn)             |      | 3 |13 |                      |
|LD (BC),A   |(BC):=A             |      | 1 | 7 |                      |
|LD (DE),A   |(DE):=A             |      | 1 | 7 |                      |
|LD (nn),A   |(nn):=A             |      | 3 |13 |                      |
|LD A,I      |A:=I                |.***00| 2 | 9 |PV=IFF                |
|LD A,R      |A:=R                |      | 2 | 9 |PV=IFF                |
|LD I,A      |I:=A                |......| 2 | 9 |                      |
|LD R,A      |R:=A                |      | 2 | 9 |                      |
|LD rr,nn    |rr:=nn              |      | 3 |10 |                      |
|LD ii,nn    |ii:=nn              |      | 4 |14 |                      |
|LD HL,(nn)  |HL:=(nn)            |      | 3 |16 |                      |
|LD rr,(nn)  |rr:=(nn)            |      | 4 |20 |                      |
|LD ii,(nn)  |ii:=(nn)            |      | 4 |20 |                      |
|LD (nn),HL  |(nn):=HL            |      | 3 |16 |                      |
|LD (nn),rr  |(nn):=rr            |      | 4 |20 |                      |
|LD (nn),ii  |(nn):=ii            |      | 4 |20 |                      |
|LD SP,HL    |SP:=HL              |      | 1 | 6 |                      |
|LD SP,ii    |SP:=ii              |      | 1 |10 |                      |
#+END_EXAMPLE

For the GB CPU, I basically had one Rust function for every LD variant.  LD
functions are very simple, so the code was easy to copy/paste and adapt, but
it's still rather dumb code to write and read.

At the moment in the code generator, I only have one LD function:

#+BEGIN_SRC rust
fn LD(p1: Param, p2: Param) -> Block {
  block![
    Val(p2),
    Assign(p1)
  ]
}
#+END_SRC

Most of the orthogonality comes from the parameters, like in Boyo.  Of course I
have yet to implement all the variants above, and we can already that there are
variants that touch the flags.  So I might end up with two functions or more.

Ideally, I should get one function per group in the table.  There are even
groups that can be collapsed together: like ADD/SUB, XOR/OR/AND, etc.

* [2017-05-30 mar.]
** Static and dynamic binary translation                        :genesis:gbs:
Seems like a good idea to tremendously speed up the emulation.  Instead of an
interpreter loop with a jump table, we can generate assembler from each byte in
the ROM, load that code directly as an executable page, and run it.

You have to convert the addresses so that you are jumping into host RAM, and not
GB RAM.  The conversion cannot be done statically, since we do not know all the
addresses beforehand.

One trick suggested by I. is to allocate a block of, say, 8 bytes for each byte
in the GB ROM.  This block will hold the converted instructions, since we cannot
do a 1-to-1 conversion in most cases.

Addresses then need to be scaled:

: host_address = base + GB_address * block_size

There is in fact already addressed modes for this conversion: base indexed
addressing.

After we generate the assembly, we can pass it to nasm to generate a (ELF-less)
x64 binary.  This can be then loaded by the runtime emulator, to run the CPU as
fast as possible.

I might try this on a CHIP8 first, since it's much faster to get going.

I know of [[http://andrewkelley.me/post/jamulator.html][one previous attempt]] of static recompilation, but they concluded JITs
were more useful as they had to bake an opcode interpreter into the static
binary to get around assembly tricks like jumps in the middle of opcodes.

I'm not sure how the binary translation outlined above gets around such assembly
tricks.  If a trick uses the fact that an opcode has two operands, and the first
operand happens to be another opcode which takes one operand, these 3 bytes
effectively act as two different instructions.

If we do a binary translation of opcodes, only the first one will be
translated into host assembly.  The second packed instruction will only be
treated as operands to the first.

When we jump into the translated assembly, we will jump in the middle of the
translated instruction, but the effect might be totally different than what was
intended.

Unless we generate instructions for every /byte/ of the ROM, and not just every
opcode.  That changes the address calculation, but at least we are sure to end
up with the correct code.  Except now, we might generate way too much assembly.

The [[https://news.ycombinator.com/item?id=5838326][two HN]] [[https://news.ycombinator.com/item?id=11309907][threads]] have interesting discussion on the topic of feasibility of
static recompilation.  Essentially, assembly tricks, interrupts and dynamic code
modification are easier to deal with dynamic recompilation.  I didn't see any
definitive proof that static recompilation was impossible in practice, just more
complex.  The efficiency gains are also potentially higher with dynamic
recompilation, since you can gather more precise information.

The second thread has a link to a "tracing decompiler" for CHIP8, which keeps
track, for each opcode, of the "reaching set", or potential jump destinations,
and potential register access.  Since it's a static analysis, these sets may
larger than what's used at runtime, but that's a start.

Overall, vastly interesting topic.  Not sure that static binary translation is
viable for the GB.  Might test with CHIP8 to start with and see how much can be
gained, and at what price.

* [2017-06-01 jeu.]
** Another genesis day                                              :genesis:
Another rebase.  Excited to find out how much the work has improved while I was
sleeping!

Rebase, make...

: ./renderer.h:25:17: error: field has incomplete type 'enum Planes'

Hmm. make clean?  Nope, still there.  Where is the enum defined?  vdp.h it
seems.  Why don't we include vdp.h directly?  I understand that declaring the
enum could work, but it's actually never defined anywhere, since the definition
in vdp.h is a typedef on an anonymous enum.

Including vdp.h in renderer.h fixes it.

Cleaning up the Makefile so we can have debug/release builds side-by-side.

Taking care of the more interesting warnings:

: m68k/conditions.h:5:37: warning: declaration of 'struct M68k' will not be visible outside of this function [-Wvisibility]
: typedef bool(*ConditionFunc)(struct M68k*);

Again, a forward declaration thing?  Including m68k fixes it... I can see that
the code deliberately does not include the relevant headers, but I'm not sure
why.

Fixed a few minor warnings of bitwise operator precedence and missing newlines.

The release build is rather fast, even too fast to be playable.  TMNT for
instance you can get into Stage 1 and then... get beat up to death.  The joypad
being reversed does not help.

Most games I try show something: exciting!  Columns even is nearly playable!

Now, what games are waiting for the Z80?  Maybe we can mock it.  It would also
be helpful to have a debugger... for now maybe just looking at dumps of the
debug build is enough.

Sonic seems to hang after the SEGA logo.  Here is the loop:

#+BEGIN_EXAMPLE
0X72750   BCC
0X72746   MOVE.b ($0000a04000).l, D2
0X7274C   BTST.l #$0007, D2
#+END_EXAMPLE

It's reading a value from the YM2612 and testing it against 7.  According to the
doc, reading should return:

#+BEGIN_QUOTE
READ DATA: Reading from any of the four locations gives:

D7   D6 D5 D4 D3 D2 D1          D0
Busy                Overflow A  Overflow B

Busy: 1 if busy, 0 if ready for new data
Overflow: 1 if the timer has counted up and overflowed. See register 27H.
#+END_QUOTE

So it's testing for the overflows?  Let's try returning 0x7: never busy, and
timer always overflowing.

Haha!

[[file:data/sonic-title.png]]

And then... it stops:

[[file:data/sonic-stage-hangs.png]]

The loop:

#+BEGIN_EXAMPLE
0X71B5A   BTST.b #$0000, ($0000a11100).l
0X71B62   BCC
#+END_EXAMPLE

Now expecting the Z80 to be stopped?

#+BEGIN_QUOTE
Reading this bit will return 0 if the bus can be accessed by the 68000,
 or 1 if the Z80 is still busy.
#+END_QUOTE

Ok ok.  We are not busy.  Return 0.

I get into the first stage, and then:

[[file:data/sonic-dies.png]]

Sonic dies of time over.  Probably the time is kept by a timer somewhere that's
unimplemented and returns 0.

Took the time to flesh out the z80 implementation a bit, so we can easily expand
later.  BUSREQ according to spec; it's a bit confusing because the two lines on
the Z80 BUSREQ and BUSACK are active low, but you have to write 1 to request the
bus from the M68...

Anyway, toggling the bus state happens on the next clock of the Z80, so that's
why we have it in z80_step.

Not sure what Addams Family is doing... seems to wait for the Z80 bus, but even
though it should be released, it still loops.  Now I might need a debugger to
see the registers; or more information in the DEBUG dumps (the BCC and BRA have
no operands right now).

Reading the Z80 User Manual; seems pretty comprehensive.  There's an explanation
for the time cycles / machine cycles: time cycles are cycles from the clock
input, and machine cycles correspond to internal operations (opcode fetch is one
machine cycle, memory read is another, etc.).

There's also a convenient list of addressing modes, so it should help generating
opcodes.  Individual instructions are helpfully documented.  According to
spritesmind, it also contains errors, so... double check.

** Replacing the hard-drive on my 3rd gen iPod                    :ipod:arch:
The 40Gb hard drive was randomly failing, and generally being slow.

I read that you could replace them with SD cards or compact flash cards, so I
was curious.

Unfortunately, most of the resources I found were for more recent iPod (4 and
up).  There's a website that even sells custom hardware for that, but not for
3rd gens.

I scrounged the web and found a few pictures of someone modifying his 3rd gen
with a compact flash card and ordered the same piece from China.  I also ordered
a 64gb compact flash, since anything above was too expansive.

When the adapter arrived a few weeks later, I started opening the iPod.  That's
certainly the trickiest part since it's shut tightly.  I managed to gnaw at it
with small screwdrivers... not without leaving a few marks.

Anyway, the adapter was not the right one.  It had a ZIF connector, and my iPod
had a small IDE-like connection.  I ordered the right piece, and waited again.

Couple of weeks later, I went back to the open iPod (did not dare to close it
since it would mean potentially scratching it again to open it...).  Still not
the right piece.  I had ordered a female 44-pin IDE, but I needed some small
IDE.

Finally I ordered a "Compact Flash to 1.8 Inch Toshiba HDD Adapter", and waited
again.

Third time's the charm: this was the right piece.  Except it had a little
protrusion preventing it from plugging completely to the iPod.  I have a file on
my Swiss army knife, so it was a matter of a couple minutes.

Now that the hardware part was done, I left the case open and jumped to the
software part.

Plugging and turning on the iPod, at first I got a folder icon with an
exclamation point.  Something was wrong with the drive.  Huho.  I grepped the
Internet; turns out I had not connected the HDD connector bridge to the main
board.  But now the iPod was stuck on this screen.

I tried various suggested chords, holding for a few seconds, nothing worked.  In
the end I just unplugged the battery from the board, taking care to not short
anything.

After that I made sure to connect the HDD to the board, then plugged the iPod to
the computer.

Tada!  It recognized the device.  Now I wanted to install [[https://www.rockbox.org][Rockbox]], a custom
firmware which can handle FLAC and other formats, much more than the original
firmware.

I installed the RockBoxUtility through pacman (rbutil).  It could not recognize
the iPod partition table.

Okay, you need to restore the iPod first.  The [[https://www.rockbox.org/wiki/IpodManualRestore][suggested way]] to do that on Linux
is to ~dd~ the original MBR and firmware to the device.  The trouble with that
is that the original MBR is for a 40Gb iPod, not a 64Gb device...  I tried to
~dd~ the MBR and resize the partition using GParted, but it ended up screwing
the partition table; RockBox would still not have it.

I ended up loading iTunes on a Windows PC to try to restore it from there.
iTunes would not recognize the iPod.  Panic.

Windows did recognize the device, and suggested I format.  Okay, let's try
that.  FAT32 please.

Error.  Windows could not format the device.  Sweat.

Okay, plugged back the iPod into my linux box, erased the MBR, and formatted the
whole disk to FAT32.  This worked.

Now back to windows.  Oh hey!  iTunes detected a corrupted iPod.  Would you like
to restore it?  Yes please.

I let it do its thing.  Then I eject and unplug the iPod.  Hmm, nothing.
Plugged it back in, still corrupted.  Okay, let's try that again.  This time
it's faster.  Eject, unplug.  Nothing.  Maybe I need to restart?

Hold Play....

Apple logo comes on, with a progress bar.  I'm guessing it's flashing the
firmware or something.

Menu comes up.  I run for the settings->about page... 64Gb!  Success!

Now back to the linux box, I mount the partition (there are two partition on the
device now: a 34Mb one and another FAT with the rest of the disk; I mount the
second), and run RockBoxUtility (sudo, to make sure it has access).

I select iPod 3rd gen and the IPOD mount point, then Install.

It starts downloading stuff and installing.  It spends a lot of time downloading
the rockbox software...

I go do something else for 30min.  Stuck at 42%.  Okay let's try that again.
Install.

Now it zips through the download, everything installs.  Great!

Let's try that: unplug, reset (hold Menu + Play for a few seconds).  Apple
logo... and Rockbox menu.

I tinker with a few settings (LCD contrast was up the wazoo).

Plug back into the linux box, mount.  Now I can just mv the music that I want to
a folder on the thing, rather than having to use iPod-specific software which
deals with the convoluted iPod library.

Only downside is that USB mode from Rockbox does not work on 3rd gen... so I
need to reset and boot into the original firmware whenever I want to update the
collection.  Minor hassle.

However, I have a few files with non-ASCII names, and I don't think I can use
anything other than FAT32, so rsync complains.

Loading up MusicBrainz, I toggle the Windows compatibility option, then update
the library.

Unplug, reset, update the database... oh hey, it works!  I even have a tiny
black and white preview of the cover.  You can nearly recognize them if you
squint hard.

I let it run for a few tracks.  Seems to work.

Shutdown.  Secure the compact flash with duct tape, make sure everything is
plugged correctly.  Close the iPod down.

Much lighter!  And no more disk read errors.  I only wish I could have put
something larger, like 128Gb.  Not looking forward to opening it again...
hopefully the battery and compact flash will last for a few years.  I've had it
since ... 13 years!  Works better than ever.

* [2017-06-05 lun.]
** Catching up on emulation resources                             :emulators:
One of the difficulties with starting up writing emulators is the lack of
documentation.  Systems themselves are badly documented: their documentation is
scattered around, in various state of accuracy.  But I found little resources on
general information for /writing/ emulators.

Like, how do you go about writing a CPU interpreter, how to deal with
interrupts, how do you start with graphics and audio...

[[https://github.com/avivace/awesome-gbdev][This list]] is a great start for GB resources.  Since the GB (along with the NES)
is a favorite target for emulator writers, you can also find plenty of tutorials
or post-mortem for those.  That list has a few of them.

[[http://www.codeslinger.co.uk/][This website]] in particular has information about emulating different systems.
The author starts by referring [[http://www.codeslinger.co.uk/files/emu.pdf][a report on writing emulators]], "Study of the
techniques for emulation programming" by Victor Moya del Barrio.

It's from 2001, and the English can be approximate, but most of the content is
still relevant.  Of course, there are considerations that might have changed a
bit since then.  For instance, they discard parallel emulators as too complex
for little benefit, seeing as the target consumer hardware then was mostly
single-processor based.

But it covers stuff like dynamic binary translation that I'm curious about, so
it's a start.

*** Intra-system timing
Quick note about emulating the CPU versus emulating the other hardware.  In
Boyo, we went with emulating one CPU instruction, then run the audio and the
video for the amount of CPU cycles elapsed.

That's because in one instruction, the CPU can write to IO, and in another it
can write another value, erasing the previous one.  So you have to emulate the
hardware to simulate the fact that, in the original system, all these units work
in parallel.

That's trading performance for accuracy, since you are switching contexts and
probably ruining the code cache.

Also, in Boyo (and GBS) writing to IO ports like the trigger audio function will
immediately resets things like the envelope etc.  So we are technically
emulating part of the audio system while the CPU is running.

It doesn't make a huge difference since we stop after one CPU instruction.
However, it might not be accurate, since the APU could poll the IO values at the
end of its cycle rather than right as they are written to.

At the scale we are talking about (one instruction ~= 10 cycles = 2.4ns for a
4Mhz CPU), it certainly wouldn't have a perceptible effect.  Unless, other units
in the systems take advantage of such timing for specific effects.

*** Computing flags with lookup-tables
They suggest pre-computing all the flag results in a lookup-table.  That
eliminates the tests usually needed for them at runtime.

For 8bit values, you just need to run through all the 256 potential values, and
compute the flags you can.

But for the GB CPU at least, the most complex flags compare the operands and the
result.  So you'd need a double-entry table...  Or maybe you can just use the
high bits of each nibble for the carry flags, reducing the table size
considerably.

Maybe modern branch prediction does not need such tricks.  But, unless the
performance on modern CPUs is /worse/ with lookup-tables, it's still something
to consider, as it would probably up the perf for other CPUs.

*** Static and dynamic binary translations
I think the document glosses over a lot of details here.  There is an algorithm
for dynamic binary translation, but it's really more like pseudocode.  The gory
details are unfortunately left out, like: how to build blocks, what kind of
optimizations to do, how to bail out of translated code when written to...

It does an okay job at giving an overview of these topics, and includes some
references to dig further, but that's it.  So, not a gold mine in this respect.

* [2017-06-08 jeu.]
** Finished reading the book about techniques for emulation       :emulators:
Additional comments follow.

*** Emulating video hardware
The document does a good job as overview of different video hardware: 2D tiling
engines versus 3D instruction pipelines.  It goes more in depth for 2D systems,
since the author wrote a Master System emulator.

One highlight is the suggestion of emulating the guest video hardware with the
host hardware.  This can be done for 3D, and is tied to high-level emulation
(HLE): instead of emulating the guest 3D hardware, you just capture the graphics
instruction, and convert them to equivalent instructions for the host 3D
hardware.  When the hardware is close, it works, it saves you from emulating the
guest hardware on the host CPU.

For 2D engines, however, there usually are no close parallel for the host
machines.  But it got me thinking.  The video hardware of the GB merely blits
tiles and sprites textures to a framebuffer.  We could treat the VRAM as texture
for a modern GPU and let our GPU handle the blitting itself, freeing the CPU
from having to loop over pixels and putting them in an off-screen buffer.

*** Emulating sound hardware
The GB has what is called a "programmable sound generator" (PSG) in the Master
System/Genesis parlance.  Square waves, noise channels; generated tones, sound
is very crude.  FM synthesis is more sophisticated and based on frequency
modulation of sine waves.  The Master System and Genesis both have a PSG chip
and a FM chip.

Again, we can emulate the guest sound hardware directly on the host CPU, or we
can use the host sound hardware.  The document talk about SoundBlaster 16 cards
(memories...) with FM capabilities.  I wonder what capabilities are present in
modern integrated sound chips.

*** The Genesis is backward-compatible with the Master System
The Master System is based on a Z80, a tile-based 2D VDP and a YM2413 FM chip.
The Genesis has a Z80 as well, its VDP is tile-based, with an larger palette,
larger sprites, more tile window, and the sound chip is a YM2612.

So, emulating the Master System, you already have a good idea of how to tackle
the Genesis.  Conversely, if you build a Genesis emulator, you nearly have a
Master System one for free.

Too bad Merwan didn't follow through with Mr. System (especially with such a
great name!).

*** Dynamic binary translation
Was left hungry for more information about this topic after reading the
document.  I found more information on the MAME wiki.  These [[http://wiki.mamedev.org/index.php/Core_Concepts][two]] [[http://wiki.mamedev.org/index.php/Dynamic_Recompiler_Author%2527s_Guide][pages]] do a good
job.  The second one, under "front-end analysis" especially explains how they
build blocks out of the guest program:

#+BEGIN_QUOTE
- A code window is a predefined PC-relative lower and upper bound within which
  the analysis will take place. An example window from the MIPS3 case has a
  minimum of -128 and a maximum of 512. This means that as soon as any path
  through the code goes more than 128 bytes before the starting PC, or more than
  512 bytes beyond the starting PC, it effectively stops the analysis.
- A code block is the collection of instructions that result from walking
  through the code from the starting PC until all known paths terminate (either
  explicitly or by branching outside of the window)
- A code sequence is a subset of a code block where all instructions from
  beginning to end are guaranteed to execute sequentially, with no branches into
  the middle
#+END_QUOTE

Too bad the page cuts off after that.  It was promising!

There are still unanswered questions: how do you deal with interrupts?  Do you
check for them after executing a block?

*** Testing the emulator
Apart from manual testing of ROMs and debugging, which the author acknowledges
as time-consuming, they suggest writing small test ROMs for targeting specific
tricky behaviors.  That saves you from having to load a whole game ROM, and
replay inputs to get a to a specific point.

That's what Blargg's test ROMs for the GB are, basically.  Now, are there any
equivalent ROMs for the Genesis?  (Not that Blargg's test matter for getting the
emulator running, mind you)

** Genesis tests                                                    :genesis:
Found [[https://bitbucket.org/eke/genesis-plus-gx/downloads/md_test.zip][some tests]] for Genesis Plus GX, courtesy of [[https://www.reddit.com/r/emulation/comments/2orsgi/android_gensmd_emulator_accuracy_testing_result/][this post]].  Most of these seem
to target the VDP, and unfortunately, the archive doesn't include any expected
results :(

[[https://imgur.com/a/VzyXR][This album]] contains the results for some emulators, so that's a start.  [[http://segaretro.org/Sprite_Masking_and_Overflow_Test_ROM][This test]]
is Blargg-like in the sense that it runs the tests automatically and report on
the screen whether they passed or not.

For posterity, here is where we stand right now:

[[file:data/sprite-masking-test-results.png]]

(Also, I have to kill the process to get out of the test)

There's a 'memtest_68k' that looks interesting.  Unfortunately, running it
SIGSEGV!

Maybe we are going outside the CPU RAM and never checking it.  GDB tells me we
are in instructions_logic/or, failing at the first line:

#+BEGIN_SRC c
int or (Instruction* i)
{
    uint32_t result = FETCH_EA_AND_GET(i->src) | FETCH_EA_AND_GET(i->dst);
#+END_SRC

Crucially:

: (gdb) p i->dst
: $3 = (struct Operand *) 0x0

Okay, so i->dst wasn't initialized.  Since the FETCH_EA macro is:

: #define FETCH_EA_AND_GET(operand) ((operand)->last_ea = (operand)->fetch_ea_func(operand), (operand)->get_value_func((operand)))

dereferencing NULL leads to SIGSEGV.

What was the instruction?

: p m->instruction_register
: 63

: p m68k_decode(m, m->instruction_address)->mnemonics
: ORI.b #$0000, D0

That's an immediate OR, but we end up executing an OR for two effective
addresses.  Something wrong in the generation?

: (gdb) p *i
: $16 = {name = 0x412a6a "ORI", context = 0x619080, func = 0x40de20 <or>, src = 0x61c780, dst = 0x0, size = Byte,
: base_cycles = 0 '\000', {condition = 0x0}}

Seems we generated an ORI, and the ~or~ function is the one used for ORI as
well, so all's good.

However, DST should probably point to D0 or something.  The generating
instruction reads:

: i->dst = operand_make(FRAGMENT(opcode, 5, 0), i);

And operand_make has a switch with a default to return NULL.  So we are probably
not matching anything and defaulting.

Actually, there are a bunch of opcodes defaulting in this switch.  But it seems
this is expected by instruction_generate, since it checks whether the
instruction is valid.  Although, in gen_ori:

: if (instruction_is_valid(i, true, true))

we don't do anything if the instruction is invalid?  There is another check in
m68k_make:

: if (!instruction_is_valid(instr, false, false))

But it doesn't check src and dst fields.  Even it if did, at this point, it
would just leave the opcode_table empty for this particular opcode, and that
wouldn't solve the problem.

Let's follow what happens:

: (gdb) break instruction_generate if opcode==63
: (gdb) bt
: #0  operand_make (pattern=63, instr=0x61c740) at m68k/operands.c:10
: #1  0x000000000040d53c in gen_boolean_instruction_immediate (opcode=63, m=0x619080, name=0x412a6a "ORI", func=0x40de20 <or>)
:     at m68k/instructions_logic.c:39
: #2  0x000000000040e0d7 in gen_ori (opcode=63, m=0x619080) at m68k/instructions_logic.c:173
: #3  0x0000000000403dcc in pattern_generate (pattern=..., opcode=63, context=0x619080) at m68k/instruction.c:131
: #4  0x0000000000403e6a in instruction_generate (context=0x619080, opcode=63) at m68k/instruction.c:142

So we taking the NULL branch after matching the `case 0x38` line in
operand_make.

63  = 111111b
38h = 111000b
 7h = 000111b

so, 63 & 7 = 111b = 7.  I would expect the switch to do an
operand_make_data_register, since the decoder gives us D0 as destination.

At this point I don't know the M68k enough, and what is the correspondence
between opcodes and mnemonics.  I'll leave the fix to the pro.

** Updating the Makefiles for GLFW and ImGui                         :megado:
We ditched SDL for OpenGL/GLFW in order to use ImGui.  Let's adapt the
Makefile.  The deps are from git submodules, so:

: git clone megado
: git submodule init
: git submodule update

: fatal: reference is not a tree: 4f6bdcd9db1632d2b5b5090483f3491f3d5b9ced
: Unable to checkout '4f6bdcd9db1632d2b5b5090483f3491f3d5b9ced' in submodule path 'deps/cimgui'

-_-

Apparently, [[https://stackoverflow.com/a/13425990][I need to slap someone]].  But I don't actually understand how to fix
this.  Hmm, looks like the deps/cimgui submodule was pointing to 4f6bd, but this
commit was somehow unavailable, because it was the commit used for the PR, but
it disappeared after merging?

Whatever, doing:

: git submodule sync

Updated the ref to the latest master, and I had to commit the change locally
before running:

: rm -rf deps/cimgui
: git submodule --init --recursive

At this point it doesn't complain anymore, and I have access to the files in
deps/cimgui.

Now, the Makefile.

Okay, I need glew and glfw.  I don't want to bother compiling the ones in deps/
for now, so I'll just get them from the system:

: sudo apt install libglew-dev libglfw3-dev

Using `pkg-config glew glfw3` for the makefile...

: genesis/renderer.c:770:25: error: use of undeclared identifier 'GLFW_TRUE'

-_-

Okay, the work machine is an Ubuntu 16.04, and glfw3 is 3.1 there, and that
define is 3.2.  Grmbl.

Building the ones in deps then.

For GLFW:

: mkdir build
: cd build
: cmake -DBUILD_SHARED_LIBS=ON ../
: make

For GLEW:

: cd auto
: make
: cd ../build
: cmake ./cmake
: make

For cimgui:

: cd cimgui
: make

After that, adding the include and libs to the Makefile... and to
LD_LIBRARY_PATH when run...

Yeah it works!  The debug build is slow though...  let's try release.  Hmm, not
as unbridledly fast as before.  But solid.  Love all the windows, and the
debugger!

[[file:data/megado-debugger.png]]

Unfortunately, seems none of my keys are recognized.  Neither by the games or
imGui.  Hmm, seems the keys are recognized on RELEASE, but not on PRESS...

Ah:

: handle_inputs(r, key, modifiers);

It's ~action~ we want to pass.  Okay, fixed it.  Now the game recognizes input.
However, it doesn't seem that imGui does recognize the P/Space shortcuts for the
debugger.  Maybe it's not working yet, the only code relevant for keys
interacting with imGui is:

#+BEGIN_EXAMPLE
    if (action == GLFW_PRESS)
        io->KeysDown[key] = true;
    else if (action == GLFW_RELEASE)
        io->KeysDown[key] = false;
#+END_EXAMPLE

** Genesis documentation                                             :megado:
Some useful reference document, before I forget where I got them:

- [[http://www.nxp.com/assets/documents/data/en/reference-manuals/MC68000UM.pdf][M68k manual from the constructor]]
- [[http://www.nemesis.hacking-cult.org/MegaDrive/Documentation/GenesisSoftwareManual.pdf][Genesis official (and confidential) manual]]
- [[http://nemesis.hacking-cult.org/MegaDrive/Documentation/YM2608J.PDF][YM2608 manual in Japanese]].  Not the YM2612, but pretty close.
- [[http://www.myquest.nl/z80undocumented/z80cpu_um.pdf][Z80 official manual]]
- [[http://www.myquest.nl/z80undocumented/z80-documented-v0.91.pdf][Sean Young's doc on the Z80]]

** Sonic doesn't die of timeover!                                    :megado:
If you hold right when the stage begins, Sonic flies through the level, and the
timer counts up.

But he quickly dies anyway of running into the decor.  I'm guessing something
wrong the way collision are calculated.

* [2017-06-10 sam.]
** Toggling off vsync with Intel integrated graphics           :arch:chipers:
I ran into that issue on my desktop machine.  Was testing out chipers, and was
getting constant 60FPS even without any sleeping...

I don't know if there's a way to turn it off from the application, but to
disable it at the driver level, [[https://wiki.archlinux.org/index.php/Intel_graphics#Disable_Vertical_Synchronization_.28VSYNC.29][this is it]].  Write the following to ~/.drirc:

#+BEGIN_EXAMPLE
<device screen="0" driver="dri2">
	<application name="Default">
		<option name="vblank_mode" value="0"/>
	</application>
</device>
#+END_EXAMPLE

That's it.  Re-running the application, swapping buffers does not sleep anymore.

Hmm, passing ~env vblank_mode=0~ on the program also works.

Glutin doesn't support turning vsync off, [[https://github.com/tomaka/glutin/issues/228][apparently]].

** Changing ImGui histogram colors using imgui-rs             :imgui:chipers:
Since I had two histograms, I wanted them to have separate colors.  Found a way
to change the colors used to draw the histogram:

: imgui.style_mut().colors[ImGuiCol::PlotHistogram as usize] = ImVec4::new(232.0, 0.0, 123.0, 255.0);

This requires to have ~imgui_sys~ as a crate, since ImGuiCol is not re-exported
by imgui-rs.

But, we can't change the color while drawing the imgui frame since we have
already borrowed imgui mutably.

* [2017-06-11 dim.]
** Profiling Rust programs                                          :chipers:
Found a few post for profiling rust programs:

- https://llogiq.github.io/2015/07/15/profiling.html
- https://athemathmo.github.io/2016/09/14/tools-for-profiling-rust.html
- http://blog.adamperry.me/rust/2016/07/24/profiling-rust-perf-flamegraph/

First of all, I need to hammer the CPU.  Chipers is not really hard on the CPU
with the default frequency of 600Hz.  At this rate, I get around 40kCPS in
KALEID when letting it draw.

Now, if I bump the frequency of the CPU to 24MHz, I get around 3CPS.

I tried perf on that:

: perf record -g target/release/chipers -dc 24000000 ../chip8/c8games/KALEID.c8

Then

: perf report

I'm a bit surprised by the results though.  We spend most of the time in
chipers::main, so far so good... looks like everything is inlined, since I don't
have any stack beyond the main.  The surprising bit is that it seems the hottest
instruction is this line:

: let opcode = (ram.read(pc as usize) as u16) << 8 | (ram.read((pc + 1) as usize) as u16);

Hmm, valgrind trashes the performance of the program so hard that it's not
possible to test at 24MHz:

: valgrind --tool=callgrind target/release/chipers -c 24000000 ../chip8/c8games/KALEID.c8

At 600Hz, the video code is the bottleneck.

oprofile, like perf, does not instrument the whole code so I can go to 24MHz.
opannotate reports the same line as being hotter than the rest.

More reading, found additional resources:

- https://www.reddit.com/r/rust/comments/5zbx87/problem_using_perf_for_profiling_under_linux/
- https://jbendig.github.io/fix-rs/2017/01/24/how-to-optimize-rust-programs-on-linux/

I tested perf on the debug binary without any optimizations, and there I found
the expected functions in the flamegraph.  So the compiler inlines mostly
everything.

So the hot code seems to be:

#+BEGIN_EXAMPLE
 18.43 │        movzwl %dx,%eax
       │      _ZN7chipers5chip86memory8{{impl}}9read_16leE():
       │          let h = self.mem[addr] as u16;
  2.47 │        mov    %edx,%esi
       │        shr    $0x10,%esi
  0.43 │        movzwl %dx,%ecx
  0.91 │        cmp    $0xfff,%ecx
       │      ↓ ja     7327
       │          let l = self.mem[addr + 1] as u16;
  2.15 │        lea    0x1(%rax),%rcx
       │      _ZN4core5slice8{{impl}}9index<u8>E():
       │        cmp    $0x1000,%rcx
       │      ↓ jae    733b
       │      _ZN7chipers5chip83cpu8{{impl}}110clock<chipers::chip8::memory::WatchedRAM,chipers::glscreen::GLScreen,chipers::chip8::key▒
  1.98 │        mov    -0x19030(%rbp),%r12d
       │      _ZN7chipers5chip86memory8{{impl}}9read_16leE():
       │          let h = self.mem[addr] as u16;
  0.50 │        shr    $0x10,%r12d
  0.38 │        movzbl -0x9018(%rbp,%rax,1),%r14d
       │      _ZN7chipers5chip83cpu8{{impl}}109exec<chipers::chip8::memory::WatchedRAM,chipers::glscreen::GLScreen,chipers::chip8::keyb▒
       │          let y = ((opcode & 0x00F0) >> 4) as usize;
  6.19 │        movzbl -0x9017(%rbp,%rax,1),%r13d
#+END_EXAMPLE

That ~movzwl~... a great deal of our samples fall on this instruction.  If I
understand it correctly, it's for casting of self.pc as usize.  If I use an
usize from the start, does it disappear?

Made the change... and yes, after that, the instruction has disappeared.  I was
under the impression ~as~ casts in Rust could be optimized away... but no.
Picking sizes matters.

I went from 3.0 to 4.4CPS with that small change.  Impressive!

To double check, let's see what ~perf stat~ gives.  Before the change:

: $ perf stat -d target/release/chipers -dc 24000000 ../chip8/c8games/KALEID.c8

#+BEGIN_EXAMPLE
      15210.351520      task-clock:u (msec)       #    0.992 CPUs utilized
                 0      context-switches:u        #    0.000 K/sec
                 0      cpu-migrations:u          #    0.000 K/sec
             1,503      page-faults:u             #    0.099 K/sec
    29,958,447,556      cycles:u                  #    1.970 GHz
    53,751,931,997      instructions:u            #    1.79  insn per cycle
    10,150,569,190      branches:u                #  667.346 M/sec
         3,428,708      branch-misses:u           #    0.03% of all branches
    12,720,928,547      L1-dcache-loads:u         #  836.334 M/sec
         9,055,738      L1-dcache-load-misses:u   #    0.07% of all L1-dcache hits
        15,963,466      LLC-loads:u               #    1.050 M/sec
        13,704,755      LLC-load-misses:u         #   85.85% of all LL-cache hits

      15.336652249 seconds time elapsed
#+END_EXAMPLE

After:

#+BEGIN_EXAMPLE
      17968.899257      task-clock:u (msec)       #    0.992 CPUs utilized
                 0      context-switches:u        #    0.000 K/sec
                 0      cpu-migrations:u          #    0.000 K/sec
             1,499      page-faults:u             #    0.083 K/sec
    31,469,036,717      cycles:u                  #    1.751 GHz
    61,300,710,896      instructions:u            #    1.95  insn per cycle
    12,385,181,235      branches:u                #  689.257 M/sec
         4,265,538      branch-misses:u           #    0.03% of all branches
    14,849,904,692      L1-dcache-loads:u         #  826.423 M/sec
        10,311,192      L1-dcache-load-misses:u   #    0.07% of all L1-dcache hits
         2,532,866      LLC-loads:u               #    0.141 M/sec
            91,932      LLC-load-misses:u         #    3.63% of all LL-cache hits

      18.114880383 seconds time elapsed
#+END_EXAMPLE

O_O

From 1.79 to 1.95 instruction per cycle, that's good.  The cause might be the
LL-cache misses going down from 85.85% to 3.63%!

So the ~movzwl~ was causing us to miss the cache somehow?  That's why it ended
up in so much samples.  Cache misses are indeed deadly.

Other tidbits: switching to the plain RAM instead of the WatchedRAM gives
another 0.2CPS boost.  Removing debug info from the release build does not seem
to impact perf.  Probably binary size?  Nope, 28Mb in each case.

28Mb??  Wow, the megado binary is just 104Kb.

Hmm, [[ https://mail.mozilla.org/pipermail/rust-dev/2014-July/010731.html][Rust defaults to static linking]].  Okay, that makes sense.  Makes the binary
portable.

Here are [[https://lifthrasiir.github.io/rustlog/why-is-a-rust-executable-large.html][some tips on reducing size]].

First of all, using ~strip~ to /actually/ remove the debugging symbols get us
down to 2.4Mb (still no impact on runtime perf though).

Add LTO... it's 5Mb after LTO, and 2.4Mb stripped.  Acceptable for a portable
binary I guess.

* [2017-06-14 mer.]
** Looking at the disassembly of my opcode dispatch loop       :chipers:rust:
First hurdle was /getting/ the disassembled code, and then /finding/ the
relevant place.

I recalled perf was able to intersperse the assembly with the source code.  Even
if it's not a 100% match because of optimizations and inlining, it's still
helpful as I am not fluent in x86.

Anyway, did I need to run perf to obtain that?  Looked around for
debuggers... but in the end, `objdump` fits the bill:

: objdump -Sd target/release/chipers

Gives me the output used by perf.  Not sure if the `-d` is necessary there or
implied by `-S`.  Anyway.

After that, wading through the 28Mb ASM file is made easier by the fact that it
contains even the comments in my code.

So here is what my switch dispatch looks like:

#+BEGIN_SRC asm
    match opcode & 0xF000 {
   3c991:	25 00 f0 00 ff       	and    $0xff00f000,%eax
      0x0000 => match opcode & 0x00FF {
   3c996:	0f bf c8             	movswl %ax,%ecx
   3c999:	0f b7 c0             	movzwl %ax,%eax
   3c99c:	81 f9 ff ef ff ff    	cmp    $0xffffefff,%ecx
   3c9a2:	7e 2f                	jle    3c9d3 <_ZN7chipers4main17h0d0151857b9b6578E+0x3c23>
   3c9a4:	81 f9 ff 3f 00 00    	cmp    $0x3fff,%ecx
   3c9aa:	7f 6d                	jg     3ca19 <_ZN7chipers4main17h0d0151857b9b6578E+0x3c69>
   3c9ac:	81 f9 ff 1f 00 00    	cmp    $0x1fff,%ecx
   3c9b2:	0f 8f 18 01 00 00    	jg     3cad0 <_ZN7chipers4main17h0d0151857b9b6578E+0x3d20>
   3c9b8:	3d 00 f0 00 00       	cmp    $0xf000,%eax
   3c9bd:	0f 84 93 06 00 00    	je     3d056 <_ZN7chipers4main17h0d0151857b9b6578E+0x42a6>
   3c9c3:	3d 00 10 00 00       	cmp    $0x1000,%eax
   3c9c8:	0f 84 a8 08 00 00    	je     3d276 <_ZN7chipers4main17h0d0151857b9b6578E+0x44c6>
   3c9ce:	e9 61 07 00 00       	jmpq   3d134 <_ZN7chipers4main17h0d0151857b9b6578E+0x4384>
   3c9d3:	81 f9 ff af ff ff    	cmp    $0xffffafff,%ecx
   3c9d9:	7e 7b                	jle    3ca56 <_ZN7chipers4main17h0d0151857b9b6578E+0x3ca6>
   3c9db:	81 f9 ff cf ff ff    	cmp    $0xffffcfff,%ecx
   3c9e1:	0f 8f 9c 00 00 00    	jg     3ca83 <_ZN7chipers4main17h0d0151857b9b6578E+0x3cd3>
   3c9e7:	3d 00 b0 00 00       	cmp    $0xb000,%eax
   3c9ec:	0f 84 2a 01 00 00    	je     3cb1c <_ZN7chipers4main17h0d0151857b9b6578E+0x3d6c>
   3c9f2:	3d 00 c0 00 00       	cmp    $0xc000,%eax
   3c9f7:	0f 85 37 07 00 00    	jne    3d134 <_ZN7chipers4main17h0d0151857b9b6578E+0x4384>
#+END_SRC

Doesn't look like a particularly efficient jump table to me.  There are multiple
tests that branch out to other parts.

The mangled names are not the most readable.  And following jumps through
assembly is... not fun.  Aren't there any tools that can give me a decent
control graph?  Or at least, allow me to follow jumps and back?

Seems like radare2 is basically the only tool that has plenty of features, runs
on Linux /and/ doesn't cost a leg.  Call graphs [[https://monosource.gitbooks.io/radare2-explorations/content/intro/visual_graphs.html][seem supported]].

Trying it out... but it takes a great deal of time to analyze the binary.  Then,
I don't know what keys I hit, but it didn't seem to like it...
Okay, got it.

: r2 target/release/chipers
: $ af @ 0x3c999
: $ 0x3c999
: $ VVV

[wait]

[[file:data/chipers-asm-call-graph.png]]

Okay, so maybe the straight ASM is more helpful in the end...

* [2017-06-15 jeu.]
** More assembly exploration                                   :chipers:rust:
Showed the assembly to I., we tried to understand what was going on.  Looks like
the compiler doesn't make a jump table because there are too few valid opcodes
out of the possible values.

I tried refactoring the code using a single match instruction.  It's not
correct, and it doesn't even cut the number of tests and jumps.  Looks like the
compiler derived a tree in order to make O(n) comparisons to get to the correct
opcode.  It would be interesting to go back and see this tree.

I. suggested we write a proof of concept of dispatching on an opcode table, to
see what kind of code it generated.  Something simple:

#+BEGIN_SRC rust
use std::env;

struct Ctxt {
  pc: u16,
  mem: [u8; 0x1000],
}

fn nop(ctxt: &mut Ctxt) { println!("nop"); }
fn add(ctxt: &mut Ctxt) { println!("add"); }
fn sub(ctxt: &mut Ctxt) { println!("sub"); }

fn main() {
  let args : Vec<_> = env::args().collect();
  let opcode = args[0].parse::<u16>().unwrap();
  let mut op_table : [fn(&mut Ctxt); 0x10000] = [nop; 0x10000];

  let mut c = Ctxt { pc: 0, mem: [0; 0x1000] };

  op_table[12] = add;
  op_table[31] = sub;

  op_table[(opcode as usize)](&mut c)
}
#+END_SRC

Here is the relevant assembly part:

: objdump -Sd -M intel-mnemonic opcode-table > opcode-table.asm

[Switched to the less noisy intel ASM syntax]

#+BEGIN_SRC asm
  op_table[(opcode as usize)](&mut c)
    5f7f:	4a 8b 84 e5 08 df f7 	mov    rax,QWORD PTR [rbp+r12*8-0x820f8]
    5f86:	ff
    5f87:	48 8d bd 08 df ff ff 	lea    rdi,[rbp-0x20f8]
    5f8e:	ff d0                	call   rax
#+END_SRC

The ~mov~ takes the opcode value (r12), multiplies it by 8 (for 64bit
alignment), and adds some offset.  Then it calls that address.

So, instead of a bunch of tests, you dispatch straight to the opcode function.

For passing arguments, we can use context object as the examples above shows.
Decoding of the opcode should be done inside each function, by calling the
decoding function which should be inlined, so the compiler discards any code
that deals with arguments we don't need.

** Stepping through Sonic assembly                                   :megado:
Seems stuck in a loop after some changes I made to the Z80.

The loop:

#+BEGIN_EXAMPLE
  250  BTST.b D0, (A1)          01 11
  252  BNE.b $FC [350]          66 FC
#+END_EXAMPLE

D0 and A1 are all zeroes.

The disassembler is drunk, as I don't know where that 350 value is coming
from... The displacement to BNE is can only be 8bit, and it's signed, so it can
hardly go higher than 126...

Stepping the BTST, the next line changes to:

: 252 BNE.b $11 [265]       66 FC

o_-

Let's trust the raw memory values (assuming they are right):

: 01 11  ->  BTST D0, (A1)
: 66 FC  ->  BNE  $FC

$FC is -4 when taken as a signed displacement.  That ends up back to 250 after
we have read past the opcode at 252.

So the loop is the correct behavior, but the debugger is wrong.

Hmm, seems the register display of the debugger is also wrong.  By plugging into
the btst function to display the value of A1, I get A11100.

So if it's reading A11100... it's probably my changes to the Z80.

Hmm, seems Sonic expects the Z80 /not/ to be running at the start.  Some docs
says the Z80 has the bus on reset, but the Genesis manual says otherwise.

Turning the Z80 off at the start fixes Sonic.

Let me double check that BTST still... seems good according to the doc I found.
The number of cycles is zero, but that shouldn't impact games too much for now.

Now, Addams Family is also polling the Z80.  Here is a log of how it interacts:

#+BEGIN_EXAMPLE
BUSREQ.w 100
RESET.w 100
BUSACK 0
BUSACK 0
RESET.w 0
BUSREQ.w 0
RESET.w 100
--
RESET.w 0
BUSREQ.w 100
RESET.w 0
RESET.w 100
RESET.w 0
BUSREQ.w 0
RESET.w 100
BUSREQ.w 100
BUSACK 1
BUSACK 1
BUSACK 1
BUSACK 1
...
#+END_EXAMPLE

Okay so first of all, we missed the word writes to BUSREQ/RESET because we
needed to add the code in write_w.

That said, this interaction is funky.  It's as if the game is trying different
access patterns to see how the Z80 responds.

The Genesis manual suggests this access pattern:

#+BEGIN_EXAMPLE
BUSREQ 100
RESET 100
[mov data to Z80 RAM]
RESET 0
BUSREQ 0
RESET 100
#+END_EXAMPLE

This is exactly what happens at the start.  Then it does something else entirely
(though I don't have timing between operations in this output).

It seems I haven't implemented the busreq/reset stuff correctly, as the last two
RESET BUSREQ attests: it's letting the Z80 run, but then requests the bus again,
which should stop the Z80.

Further investigation: one MOV is not triggering a write_b:

: 0X43C94   MOVE.b #$1, ($A11100).l

Argh, stupid mistake on my part by masking the address with 0xA04003 in write_b
to write to the ym2612...

Also, the register window /is/ working.  I wasn't aware that data registers were
32bit wide, and was looking at the top byte which was often zero...  No way to
resize this window!

It seems Addams Family is reading 0x1000 in the Z80 and expecting values from
there...  According to the manual, that's in the static RAM area of the Z80.

Hmm, but the game starts by writing to the RAM, so that's a good sign:

#+BEGIN_EXAMPLE
BUSREQ 1
RESET 1
BUSACK 0
BUSACK 0
ZWRITE 1 1
ZWRITE 2 d9
ZWRITE 3 1f
ZWRITE 4 11
ZWRITE 5 27
ZWRITE 6 0
ZWRITE 7 21
ZWRITE 8 26
ZWRITE 9 0
ZWRITE a f9
ZWRITE b 77
ZWRITE c ed
ZWRITE d b0
ZWRITE e dd
ZWRITE f e1
ZWRITE 10 fd
ZWRITE 11 e1
ZWRITE 12 ed
ZWRITE 13 47
ZWRITE 14 ed
ZWRITE 15 4f
ZWRITE 16 d1
ZWRITE 17 e1
ZWRITE 18 f1
ZWRITE 19 8
ZWRITE 1a d9
ZWRITE 1b c1
ZWRITE 1c d1
ZWRITE 1d e1
ZWRITE 1e f1
ZWRITE 1f f9
ZWRITE 20 f3
ZWRITE 21 ed
ZWRITE 22 56
ZWRITE 23 36
ZWRITE 24 e9
ZWRITE 25 e9
#+END_EXAMPLE

Doesn't write to 0x1000 though.


However, Since the Z80 PC starts at 0, that means the game is writing a program
to the Z80!  These are opcodes that should be executed after the Z80 is reset.
Maybe even a program that deals with sound.  Or one that ends up writing
something to 0x1000.

Fleshed out the Z80 implementation a bit with an opcode table.  Just with a nop
function for now, but the rest will come.

At this point there's not much more I can do for this ROM until more Z80
instructions are implemented.

* [2017-06-16 ven.]
** That weird switch optimization                              :chipers:rust:
I want to know what's going on there.

: objdump --no-show-raw-insn -SCM intel-mnemonic target/release/chipers

-M because intel syntax is less noisy,
-C is able to demangle rust symbols,
-S for interspersing source code (rough indication)
--no-show-raw-insn removes the instruction bytes

#+BEGIN_SRC asm
   3c920:	mov    rsi,QWORD PTR [rbp-0x19060] ; rsi = self.pc;
    self.reads[addr] += 1;
   3c927:	cmp    rsi,0x1000                  ; bounds check
   3c92e:	jae    400eb <chipers::main+0x733b>; "
   3c934:	inc    QWORD PTR [rbp+rsi*8-0x19010] ; self.reads[addr] += 1
      | (ram.read(self.pc + 1) as u16);
   3c93c:	lea    rax,[rsi+0x1]                ; rax = self.pc + 1
   3c940:	cmp    rax,0x1000                   ; bounds check
   3c946:	jae    400d7 <chipers::main+0x7327> ; "
    let opcode = ((ram.read(self.pc) as u16) << 8)
   3c94c:	movzx  r12d,BYTE PTR [rbp+rsi*1-0x9010] ; r12d = self.ram[pc]       : opcode.h
   3c955:	mov    eax,r12d                         ; eax = r12d
   3c958:	inc    QWORD PTR [rbp+rsi*8-0x19008]    ; self.reads[addr-2] += 1
   3c960:	shl    eax,0x8                          ; eax <<= 8                 : opcode.h << 8
    let y = ((opcode & 0x00F0) >> 4) as usize;
   3c963:	movzx  r13d,BYTE PTR [rbp+rsi*1-0x900f] ; r13d = self.ram[pc+1]     : opcode.l
    let opcode = ((ram.read(self.pc) as u16) << 8)
   3c96c:	lea    ebx,[r13+rax*1+0x0]              ; ebx = r13 + eax           : opcode
        self.stack.push_front(self.pc);
   3c971:	lea    r14,[rsi+0x2]                    ; r14 = self.pc + 2
    self.pc += 2;
   3c975:	mov    QWORD PTR [rbp-0x19060],r14      ; self.pc = r14
  fn exec<M, S, K>(&mut self, opcode: u16, ram: &mut M, screen: &mut S,
   3c97c:	mov    WORD PTR [rbp-0x2a],bx           ; mov 16b opcode to stack
    let addr = opcode & 0x0FFF;
   3c980:	and    ebx,0xfff                        ; ebx: opcode & 0xfff    : addr
    let x = ((opcode & 0x0F00) >> 8) as usize;
   3c986:	and    r12d,0xf                         ; r12d : opcode.h & 0xf  : x
    let y = ((opcode & 0x00F0) >> 4) as usize;
   3c98a:	mov    r15,r13                          ; r15 : opcode.l
   3c98d:	shr    r15,0x4                          ; r15 : opcode.l >> 4    : y
    match opcode & 0xF000 {
   3c991:	and    eax,0xff00f000                 ; eax : (opcode.h << 8) & 0xff00f000
      0x0000 => match opcode & 0x00FF {         ;  ax : (opcode.h << 8) & 0xf000
   3c996:	movsx  ecx,ax                         ; ecx : 0xfffff000 & (opcode.h << 8) or 0x0000f000 & (opcode.h << 8)
   3c999:	movzx  eax,ax                         ; eax : 0x0000f000 & (opcode.h << 8)
   3c99c:	cmp    ecx,0xffffefff
   3c9a2:	jle    3c9d3 <chipers::main+0x3c23>
   3c9a4:	cmp    ecx,0x3fff
   3c9aa:	jg     3ca19 <chipers::main+0x3c69>
   3c9ac:	cmp    ecx,0x1fff
   3c9b2:	jg     3cad0 <chipers::main+0x3d20>
   3c9b8:	cmp    eax,0xf000
   3c9bd:	je     3d056 <chipers::main+0x42a6>
   3c9c3:	cmp    eax,0x1000
   3c9c8:	je     3d276 <chipers::main+0x44c6>
   3c9ce:	jmp    3d134 <chipers::main+0x4384>
   3c9d3:	cmp    ecx,0xffffafff
   3c9d9:	jle    3ca56 <chipers::main+0x3ca6>
   3c9db:	cmp    ecx,0xffffcfff
   3c9e1:	jg     3ca83 <chipers::main+0x3cd3>
   3c9e7:	cmp    eax,0xb000
   3c9ec:	je     3cb1c <chipers::main+0x3d6c>
   3c9f2:	cmp    eax,0xc000
   3c9f7:	jne    3d134 <chipers::main+0x4384>
   ...
#+END_SRC

#+BEGIN_SRC rust
let opcode : u32 = self.ram[pc] << 8 | self.ram[pc+1];
let a = opcode & 0xf000;
let x = opcode & 0x0f00 >> 8;
let y = opcode & 0x00f0 >> 4;
let l = opcode & 0x00ff;
if (a < 0xf000) {
   if (a < 0xb000) {
     3ca56
   }
   else if (a >= 0xd000) {
     if (a == 0xd000) {
       // draw sprite
     }
     else if (a == 0xe000) {
       if (l == 0x9e) {
         // check key
       }
       else if (l == 0xa1) {
         // !check key
       }
       else {
         panic!
       }
     }
   }
   else if (a == 0xb000) {
     // self.pc = (addr + self.v[0])
   }
   else if (a == 0xc000) {
     // RNG opcode
   }
   else {
     if (l == 0xe0) {
       // clear screen
     }
     else if (l == 0xee) {
       // pop stack
     }
   }
}
else {
  if (a >= 0x4000) {
    3ca19
  }
  else if (a >= 0x2000) {
    3cad0
  }
  else if (a == 0xf000) {
     3d056
  }
  else if
}
else {
}
#+END_SRC

It takes ages to decipher it by hand... but it certainly looks like a balanced
tree.  It's not a straight conversion of the switch.

But it's still more comparisons than needed, compared to the opcode table
approach.

* [2017-06-23 ven.]
** Improving the megado debugger                                     :megado:
Fixed a couple of annoyances with the debugger, namely the register view being
cut and the displacement calculation for branching instructions being funky.

In the process, I triggered a SIGFPE from a divide by zero in DIVU.  We did not
account for this eventuality.  I added a check, but the M68k actually has a its
own exception mechanism in case of division by zero, so that should be emulated
rather than proceeding to the next instruction.

Turns out that DIVU has a sibling, DIVS, which is exactly the same but for
signed operands.  Pretty sure we did not handle that correctly, since:

0xFE = -2 as signed = 254 as unsigned
0x02 =  2 as signed =   2 as unsigned

so: 0xFE / 0x02 = 0xFF if the division is signed
                = 0x7F if the division is unsigned

Now, I'm hoping this will fix some games... but it's unlikely as DIVU/DIVS each
take around 150 cycles, so I would guess they are not used that often.

** Fixing Quackshot                                                  :megado:
Quackshot is hanging on the intro, I'm only seeing this torch:

[[file:data/quackshot-torch.png]]

... and the program becomes unresponsive.  What?

GDB tells me we are in ~vdp_draw_scanline~.  Oh, I see, there's a ~do/while~
loop here to browse the linked list of sprites.  But it's not exiting.. there's
supposedly a hard limit on the number of sprites it can draw per scanlines:

: true || (v->display_width == 32 && sprite_counter <= 16 || v->display_width == 40 && sprite_counter <= 20) disabled for now */);

and re-activating this code indeed takes me further, but the victory is hollow:

[[file:data/quackshot-intro-garbage.png]]

Pressing start takes me to the glorious title screen though:

[[file:data/quackshot-title-success.png]]

But less than one second after, the garbage returns:

[[file:data/quackshot-title-garbage.png]]

Also, this change fucks up Sonic.

Even if the condition doesn't work yet, it might be a good idea to stop the loop
at some point, even with a ludicrous number, like 64.

Doing that doesn't fuck up Sonic, but Quackshot is still garbage.  You can still
make out the enemies and plungers behind the bars, so you /can/ play, but it
could be better.

** Sonic 2                                                           :megado:
Hangs in a loop waiting for $C00004 to be ANDI $4.  That address is the control
port of the VDP, and bit 2 is to indicate HBlank.

But we are never setting the HBlank field.

genvdp.txt says:

#+BEGIN_QUOTE
Bit 2 returns the real-time status of the horizontal blanking signal.
 It is set at H counter cycle E4h and cleared at H counter cycle 08h.
#+END_QUOTE

Cool.  But we are not setting the h_counter either.  Hmm hmm.

According to [[http://gendev.spritesmind.net/forum/viewtopic.php?t=94#p1105][someone on the Internet]], the Hblank period lasts for 84 CPU cycles.
Let's run with that.

Hey, it works!  (After fixing an embarrassing sign bug in the Z80).

[[file:data/sonic2-annoyed.png]]

And then, it crashed.

It crashes on a FETCH_EA_AND_SET, because i->dst->set_value_func is 0.  Probably
we are executing some invalid opcodes that's not caught at generation.  Opcode
seems to be 0x19F1.

0001 1001 1111 0001
MOVE.b 100 111 110 001
MOVE.b Address with index (A0), #Imm

Yeah, moving into immediate value.  Definitely bogus.  So the cause is
antecedent... but these bugs are hard to track down.  At the very least, we
should /not/ crash on bogus instructions.

* [2017-06-29 jeu.]
** Tackling Z80 instructions                                         :megado:
Tried to find a test ROM that I could use to not waste too much time debugging
tricky bit errors in strange instructions.

Did find [[http://mdfs.net/Software/Z80/Exerciser/][this]], but couldn't manage to assemble it.  I tried z80asm, crasm, and
binutils-z80.  The first one froze my computer, and the other two gave me 1000
errors for the file.

Tried to look into open source emulators.  FUSE has some tests in assembly, but
they don't look exhaustive, and I don't see the expected output (maybe it's in
the assembly itself, like YAZE and Blargg's tests for the GB CPU?).

So it looks like I'll end up checking traces against working emulators, since
this seems the only available option.

I did find discussion mentioning that the official Zilog manual had errors, so I
should avoid it as a definitive source.  In fact, the "Z80 Undocumented" doc
also mentions errors in the official doc, and it has a handy table with all the
opcodes, their patterns and cycles.  So it should be sufficient.

So:

- [[https://github.com/Emu-Docs/Emu-Docs/blob/master/Shared%2520Components/CPU%2520Z80/z80-documented.pdf][Sean Young's Z80 doc]], the PDF version for reading
- And the [[https://github.com/Emu-Docs/Emu-Docs/blob/master/Shared%2520Components/CPU%2520Z80/z80-documented.pdf][text version]] for easier extraction

[hours later]

Wrote a parser for the opcode list.  I should be able to generate code for the
disassembler now.  There are a bunch of weird instructions, like this one:

: DDCB d 9F   LD A, RES 3, (IX + d)*

They are weird to parse, not weird to understand.  Luckily, the '*' at the end
stands for "Undocumented", so they are unlikely to be used in games.

* [2017-07-03 lun.]
** Network troubles resurfaces                                         :arch:
Remember the MTU weirdness?  Well, I've been having weird network slowdowns for
months, but only on /some/ sites.  Like, I was trying to download GNU global
from the GNU FTP.  2 hours remaining.  I usually don't bother with Youtube
videos since most of them never load fast enough.  But checking a random web
page (like the arch wiki page on Network): loading fine.

At first, I was just blaming my ISP (we had had troubles multiple times
already).  But then I noticed that Youtube was working flawlessly under
Windows...

So, this time, I tried to set the MTU to 1480, and GNU Global downloaded in 3
seconds:

: ip link set enp5s0 mtu 1480

Will have to make this permanent...

Hmm, trying to set the MTUBytes in the systemd profile as I did previously
/does/ set the MTU to 1480 on boot... but then the network doesn't work /at
all/.

Not setting it, I have a connection.  Then if I ~pacup~, the link goes very slow
after a few seconds.

If I set the MTU to 1480 by hand, then it works flawlessly.  So I should set the
MTU sometime after boot?  Like, on login?

Seems to work with a systemd unit that runs after network-online.target:

: cat /etc/systemd/system/set-mtu.service

#+BEGIN_EXAMPLE
[Unit]
Description=Set MTU to fix Ethernet slowdowns
Wants=network-online.target
After=network-online.target

[Service]
ExecStart=/usr/bin/ip link set enp5s0 mtu 1480

[Install]
WantedBy=multi-user.target
#+END_EXAMPLE

The MTU is set to 1480 after login, and no connection slow down are apparent.

Until next time...

* [2017-07-06 jeu.]
** Bug squashing in Megado                                           :megado:
Most ROM segfaults now.  Let's see what Valgrind says.

If I just launch a ROM and exit cleanly, here's the leak summary:

#+BEGIN_EXAMPLE
==18211== LEAK SUMMARY:
==18211==    definitely lost: 5,431,384 bytes in 92,807 blocks
==18211==    indirectly lost: 12,580,050 bytes in 260,314 blocks
==18211==      possibly lost: 23,062,657 bytes in 7,735 blocks
==18211==    still reachable: 2,150,599 bytes in 1,050 blocks
==18211==         suppressed: 0 bytes in 0 blocks
#+END_EXAMPLE

:(

Okay, let's clean that up.

Oh, that was easy.  A bad copy/paste was calling instruction_make instead of
instruction_free!

#+BEGIN_EXAMPLE
==19985== LEAK SUMMARY:
==19985==    definitely lost: 234,720 bytes in 17 blocks
==19985==    indirectly lost: 0 bytes in 0 blocks
==19985==      possibly lost: 23,105,485 bytes in 8,216 blocks
==19985==    still reachable: 15,545,480 bytes in 211,460 blocks
==19985==         suppressed: 0 bytes in 0 blocks
#+END_EXAMPLE

Similarly, we forgot to free the renderer in genesis_free.

#+BEGIN_EXAMPLE
==20385== LEAK SUMMARY:
==20385==    definitely lost: 72 bytes in 3 blocks
==20385==    indirectly lost: 1,088 bytes in 3 blocks
==20385==      possibly lost: 3,777,335 bytes in 34,201 blocks
==20385==    still reachable: 9,798,474 bytes in 177,064 blocks
==20385==         suppressed: 0 bytes in 0 blocks
#+END_EXAMPLE

And we forgot to free metrics in renderer_free.

#+BEGIN_EXAMPLE
==20476== LEAK SUMMARY:
==20476==    definitely lost: 0 bytes in 0 blocks
==20476==    indirectly lost: 0 bytes in 0 blocks
==20476==      possibly lost: 3,777,335 bytes in 34,201 blocks
==20476==    still reachable: 9,798,474 bytes in 177,064 blocks
==20476==         suppressed: 0 bytes in 0 blocks
#+END_EXAMPLE

Okay that's a start.

Hmm, invalid read when freeing:

#+BEGIN_EXAMPLE
==20476== Invalid read of size 8
==20476==    at 0x410730: instruction_free (instruction.c:412)
==20476==    by 0x403C3E: main (main.c:37)
==20476==  Address 0x1 is not stack'd, malloc'd or (recently) free'd
#+END_EXAMPLE

instr is.. 0x1.  That's weird.

Damn, that's a bad fix on my part... trying to instruction_free(opcode) -_-'

#+BEGIN_EXAMPLE
==23202== LEAK SUMMARY:
==23202==    definitely lost: 760 bytes in 6 blocks
==23202==    indirectly lost: 3,026 bytes in 9 blocks
==23202==      possibly lost: 0 bytes in 0 blocks
==23202==    still reachable: 162,436 bytes in 474 blocks
==23202==         suppressed: 0 bytes in 0 blocks
#+END_EXAMPLE

We were not properly disposing of ImGui.

#+BEGIN_EXAMPLE
==24629== LEAK SUMMARY:
==24629==    definitely lost: 0 bytes in 0 blocks
==24629==    indirectly lost: 0 bytes in 0 blocks
==24629==      possibly lost: 0 bytes in 0 blocks
==24629==    still reachable: 122,782 bytes in 452 blocks
==24629==         suppressed: 0 bytes in 0 blocks
#+END_EXAMPLE

Hmmmm not sure about these:

#+BEGIN_EXAMPLE
==24957== 1,872 bytes in 8 blocks are still reachable in loss record 84 of 92
==24957==    at 0x4C2FB55: calloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)
==24957==    by 0x40120BD: _dl_check_map_versions (dl-version.c:293)
==24957==    by 0x4015B18: dl_open_worker (dl-open.c:286)
==24957==    by 0x4010563: _dl_catch_error (dl-error.c:187)
==24957==    by 0x4014DA8: _dl_open (dl-open.c:660)
==24957==    by 0x8D22F08: dlopen_doit (dlopen.c:66)
==24957==    by 0x4010563: _dl_catch_error (dl-error.c:187)
==24957==    by 0x8D23570: _dlerror_run (dlerror.c:163)
==24957==    by 0x8D22FA0: dlopen@@GLIBC_2.2.5 (dlopen.c:87)
==24957==    by 0x537ED38: ??? (in /usr/lib/x86_64-linux-gnu/mesa/libGL.so.1.2.0)
==24957==    by 0x5381C14: ??? (in /usr/lib/x86_64-linux-gnu/mesa/libGL.so.1.2.0)
==24957==    by 0x5358603: ??? (in /usr/lib/x86_64-linux-gnu/mesa/libGL.so.1.2.0)
#+END_EXAMPLE

#+BEGIN_EXAMPLE
==24957== 8,176 bytes in 1 blocks are still reachable in loss record 90 of 92
==24957==    at 0x4C2DB8F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)
==24957==    by 0x7DA8D21: ??? (in /usr/lib/x86_64-linux-gnu/libX11.so.6.3.0)
==24957==    by 0x7DA90B5: _XrmInternalStringToQuark (in /usr/lib/x86_64-linux-gnu/libX11.so.6.3.0)
==24957==    by 0x7DBAB4F: XrmInitialize (in /usr/lib/x86_64-linux-gnu/libX11.so.6.3.0)
==24957==    by 0x7D97D02: ??? (in /usr/lib/x86_64-linux-gnu/libX11.so.6.3.0)
==24957==    by 0x7D97FBD: XGetDefault (in /usr/lib/x86_64-linux-gnu/libX11.so.6.3.0)
==24957==    by 0x95400CF: _XcursorGetDisplayInfo (in /usr/lib/x86_64-linux-gnu/libXcursor.so.1.0.2)
==24957==    by 0x9540118: XcursorSupportsARGB (in /usr/lib/x86_64-linux-gnu/libXcursor.so.1.0.2)
==24957==    by 0x953E82D: XcursorImageLoadCursor (in /usr/lib/x86_64-linux-gnu/libXcursor.so.1.0.2)
==24957==    by 0x586379C: _glfwCreateCursorX11 (in /home/fmdkdd/proj/megado/deps/glfw/build/src/libglfw.so.3.3)
==24957==    by 0x586346F: createHiddenCursor (in /home/fmdkdd/proj/megado/deps/glfw/build/src/libglfw.so.3.3)
==24957==    by 0x58638D0: _glfwPlatformInit (in /home/fmdkdd/proj/megado/deps/glfw/build/src/libglfw.so.3.3)
#+END_EXAMPLE

Doesn't look like anything we can solve.  If these are created by GLFW, we seem
to already cleanup GLFW properly.  But as they are "still reachable", these are
not leaks, and will be disposed of when we exit anyway.

Besides, these are certainly not the cause of our segfaults.

** Tracking the segfault                                            :megado:
Still segfaulting, by the way.  Valgrind doesn't catch any erroneous reads, even
though we are probably overwriting the opcode_table pointer.

Indeed, at start opcode_table is

: $1 = (Instruction **) 0x7ffff7f43010

When we crash:

: $3 = (Instruction **) 0x7f00f7003000

Who is writing to it?

: (gdb) watch opcode_table

#+BEGIN_EXAMPLE
Old value = (Instruction **) 0x7ffff7f43010
New value = (Instruction **) 0x7ffff7f43000
vdp_get_sprites_scanline (v=0x115ac40, scanline=131, data=0x6a247c <sprites_scanline>) at megado/vdp.c:818
818	            for (uint8_t sprite_x = 0; sprite_x < total_width; ++sprite_x)
#+END_EXAMPLE

???

Writing to sprite_x certainly wouldn't overwrite opcode_table.  Maybe the
breakpoint is showing the instruction /after/ the write.  The end of the loop
body is:

#+BEGIN_SRC c
                data->drawn[scanline_x] = true;
                data->colors[scanline_x] = v->cram[palette_index * 16 + color_index];
                data->priorities[scanline_x] = priority;
#+END_SRC

And scanline_x is 327.  And data->drawn/colors/priorities all have a size
of 320.

#+BEGIN_SRC c
                if (scanline_x < 0) // TODO right bound
                    continue;
#+END_SRC

Yes, TODO indeed.  I don't know the correct right bound, but it certainly cannot
be larger than the data buffers.

** Sanitize reads/writes                                             :megado:
Is there a better way than using GDB to track these down?

Apparently [[https://stackoverflow.com/a/24287919][yes]], clang and GCC both support:

: -fno-omit-frame-pointer -fsanitize=undefined

They instrument the code, so they slow it down a bit.  But for debugging, they
are quite useful:

#+BEGIN_EXAMPLE
megado/m68k/cycles.c:96:46: runtime error: index 8 out of bounds for type 'uint8_t [2][12]'
megado/m68k/cycles.c:112:28: runtime error: index 8 out of bounds for type 'uint8_t [2][12]'
megado/m68k/cycles.c:104:28: runtime error: index 8 out of bounds for type 'uint8_t [2][12]'
megado/m68k/cycles.c:82:32: runtime error: index 8 out of bounds for type 'uint8_t [2][12]'
megado/m68k/cycles.c:83:32: runtime error: index 8 out of bounds for type 'uint8_t [2][12]'
megado/m68k/instructions_shift.c:35:26: runtime error: index 12 out of bounds for type 'uint8_t [2][12]'
#+END_EXAMPLE

Wow hey look at that.  There are funky reads even before the segfault.

i->size is a Size enum, with values -1/8/16/32, but calculation table indexed by
size has only two lines.

Some other associated fixes...

Doesn't seem to make much of a difference for games, but at least now it's
(more) correct.

* [2017-07-13 jeu.]
** Progress on generating the Z80                                    :megado:
I've been generating the disassembly code, and I now parse all the required
information from the z80_ops.txt file.  (In other words, I have a full model of
the Z80 instructions, heh)

Now, what do I do with it?  For the disassembly, there are two problems
currently:

1. opcodes xxCB which have two extra arguments, and do not fit in the opcode
   table.
2. mnemonics are represented as constant strings, hence we have "LD D,n" instead
   of "LD D,1A" at runtime

To solve #2, we can provide a function in the disassembly table that fetches and
computes the extra arguments to return a fully decoded instruction.

If we reduce the opcode table to 256 entries, we would solve #1 as well, by
generating functions for these problematic xxCB opcodes.

But now that I think of it, why have an ops_table and a disasm_table?  There is
a great overlap between the two.  The disassembly will have to fetch any extra
arguments, just like the operation.  The dissasembly will have to increase the
PC, just like the operation.  In fact, the operation just has extra side effects
on memory and registers, while the disassembly constructs and returns a string.

* [2017-07-15 sam.]
** Comparison of JS game engines for JAMMING                             :js:
Last time we jammed, we used only a physics engine in JS, and wrote most of the
rest from scratch/code we lifted from sparkets.

The upside: we had complete control, and were not overwhelmed by unfamiliar
libraries/frameworks (though we had no experience with /this/ particular physics
library).  Easy to code, easy to put on Github, use our own tools for editing,
etc.

The downside was.. spotty result on other machines than the one we tested with.
Had to hack around a bunch of stuff like cameras, a sprite engine, animations,
GUI...

Physics is important.  We have code that does basic collision detection, but if
we want to push that forward, we would have to code the functionality rather
than code the gameplay... That's time lost in a jam.

And some things are especially dreadful to code: coherent key management across
browsers / touch support for mobile / gamepad support.

I wanted to research alternatives.

*** Unity
I never liked Unity for one simple reason: many LD games are made with Unity,
and require the unity player extension to work!  When exported to Linux
binaries, they usually work, though I wonder why they only managed scripting
languages.

In any case, I tried it.  There's a Linux build (though it's not advertised on
the Download page).

First of all, it's huge; a 7Gb+ install.  Had to make some room on my system
partition...  Anyway, it works.

After following the Space Shooter tutorial, here are my impressions:

I like:
- the simplicity of the entities/components: create entities, add components
  like Renderer/RigidBody/Script.  Scripts can then be reused by other entities.

  Save an entity as a prefab, and instantiate it from elsewhere.  The game
  controller is just another entity.

- the live editing: edit a script, variables are now tweakable in the editor.

  Drag and drop prefab in the hierarchy, and you can immediately see how the
  object behave.

  Press play and start playing: variables can still be tweaked at runtime.

- it builds to HTML5/WebGL.  No need for the unity player extension.

  It took a bunch of time to build the HTML5 output, but when I tried it, it
  worked well, without any surprises.

I don't like:
- the unresponsiveness.  Maybe it's due to the Linux build that's in beta, but
  the editor feels slow; especially when editing scripts using MonoDevelop and
  waiting for Unity to compile/serialize and notice the new public variables.

- MonoDevelop: it's a really subpar editor.  Code completion is nearly useless,
  no online documentation, no inline error notification...  I'm sure one can use
  their editor of choice, but how does it integrates with Unity?

- the fact that it generates blobs files that are not plain text, and do not
  play well with Git.

  I value portability and readability, even for one-off projects like a jam.

- the scary privacy terms.  Basically, Unity can spy on you using their desktop
  app.  Of course they do it to "improve the product", but that's still not okay
  in my book.

Overall, I think it's a decent tool, just not my taste.  The live editing
functionality, we can emulate half of it with Dat.GUI.  The drag and dropping in
the hierarchy is nice, but I get the feeling that it doesn't necessarily hold
for games that are more procedural.  Again, we can add buttons to Dat.GUI to
spawn some entity.

The entity-component system is nice, but we find it in other engines.

I think Unity is a decent choice, especially when you want to target many
platforms.  If you know you aim for the web and the web only, then using
libraries would be more up my alley.

*** Phaser
I think it's the go-to engine for 2D web game development.  It's all
encompassing: physics, audio, asset loading, sprite support, particle system,
camera, input...

There are even three different physics engine, depending on the kind of game
(arcadey physics, physics for sprites or full-on simulation).

Outright, I don't like the marketing of Phaser: it's targeted at gimmicky games
with childish graphics.  And when you look at the examples... well let's they
are not the cream of the crop.

Phaser is more library than framework: you call the functions at your own
leisure.  You explicitly call game.physics.arcade.overlap for instance.  But I
guess the overall experience is simpler if you stick to the included
dependencies and not bring your own physics engine.

There are lots of examples and documentation.

It's a bit weird to me that you create "sprites" first, and the physics engine
seem to generate a bounding box based on the sprite size.  But it looks like you
can easily tweak the bounding box in any case.

I like:
- the low amount of boilerplate
- the solid performance (but 2D is usually faster than 3D, so...)
- fully open-source.  We can use tools like Git, text editors of choice...

I don't like:
- there doesn't seem to be any entity/component separation.  Just objects that
  have properties that you have to update yourself.

  Okay for a smallish game, but things will still get messy quickly.

Overall, seems it's really well-suited for sprites and tile-based games.  So,
platformers and 80's arcade stuff.  Though it can work for [[https://supernapie.itch.io/dead-sticks][minimalist puzzle
games]].  I guess having picking and physics baked in helps to get started
quickly.

I wish it had 3D support though.

*** BabylonsJS
Trying an open-source 3D game engine.

It looks to me like it's more a rendering engine than a game engine.  The input
management is... weirdly verbose:

#+BEGIN_SRC js
scene.actionManager.registerAction(new BABYLON.ExecuteCodeAction(BABYLON.ActionManager.OnKeyUpTrigger, function (evt) {
   if (evt.sourceEvent.key == "r") {
       ...
   }
}));
#+END_SRC

There's audio functionality and physics, so I guess it /is/ a game engine after all.

But there are "game objects": just shapes in a scene graph.  Any logic you add
is your own.

I like:
- straightforward to use, well documented
- decent default shaders, lighting and shadows
- physics engines (plural)
- 3D!  That opens a bunch of possibilities.  Even if we can do 2D stuff with it,
  it seems a bit heavy-handed.

I don't like:
- maybe a bit on the heavy side.  Or maybe just JS+3D engines is a bad combo,
  since I keep getting atrocious GC pauses that crush my FPS to low twenties
  every few seconds...
- not a full-featured game engine

Overall, I would consider it over Three.js, since it has physics and easy-to-use
rendering features.

But the performance is not that great.  Maybe we hit native JS limits here.
Unity compiles to asm.js, and I didn't have any frame drops.  For 3D projects, I
would rather go with a native solution anyway, or compiling to JS at worst.

*** PlayCanvas
I tried a simple example, and took a look at the docs and examples.  To me, it
seems they are trying to develop a credible alternative to Unity on the web, and
focus and cloud integration/collaboration.

The editor looks really solid.  (Sadly, you have to create an account to use it,
and their privacy terms says that they are basically your info to advertisers).
Too bad it's not open source.

The engine, however, is open.  From the examples, it really looks like something
close to Unity, with entities and components.

#+BEGIN_SRC js
 // create box entity
 var cube = new pc.Entity('cube');
 cube.addComponent('model', {
     type: 'box'
 });

 // create camera entity
 var camera = new pc.Entity('camera');
 camera.addComponent('camera', {
     clearColor: new pc.Color(0.1, 0.1, 0.1)
 });

 // create directional light entity
 var light = new pc.Entity('light');
 light.addComponent('light');

 // add to hierarchy
 app.root.addChild(cube);
 app.root.addChild(camera);
 app.root.addChild(light);
#+END_SRC

I like:
- entity-component system
- easy-to-use rendering features/shadows/physics
- just write plain text code

I don't like:
- the editor being closed source (though you don't have to use it)
- the proprietary model format.  You have to upload any 3D asset /to their
  servers/ to convert it to their JSON format.  Granted, it's just JSON, so not
  that opaque.  But still, that's preposterous, and I hope [[https://developer.playcanvas.com/en/engine/][the doc]] is actually
  wrong on that.

Overall, it has the parts I liked from Unity, and is native to the web.  But it
shares the scarily closed attitude, with the editor being closed source and the
proprietary model converter...

** Verdict
Well, there is no clear outlier.  For 2D, Phaser does not tick all my marks, but
I would try it for a jam.

Otherwise, I really like what rezoner has done with Playground.js and
CanvasQuery, e.g.: [[http://store.steampowered.com/app/329320/QbQbQb/][QbQbQb]] or [[http://wilds.io/][wilds.io]].  I would be interested to try a
playground+canvasQuery or three.js cocktail, with a side of p2.js on top.  I'm
sure it's a killer combo for puzzle games.

For 3D... I'm afraid the performance of JS engines scares me too much to go with
something like BabylonJS.  Three.js is barebones, but at least it runs decently.
Otherwise, there's WhitestormJS, a wrapper around three.js that integrates
physics.

* [2017-07-16 dim.]
** Toying with THREE.js                                               :js:3d:
Finding out how to:

- draw text
- mouse picking
- path finding

*** Drawing text
So after a few hours of messing around, I have achieved the effect I wanted.

THREE.js has no embedded facility for drawing 2D text.  The manual advises to
use the DOM for that.  For an UI, it makes sense: overlay divs over the WebGL
canvas and use that for buttons / text.  You get picking for free, the browser
is already there anyway, and you don't have to reimplement all that stuff in
THREE.

However, I wanted to have text drawn on top of objects in the canvas, kinda like
player names.  Since the objects live in the canvas, it's easy to add the text
to their group and benefit from the scene graph to take care of all the
transformations.  We could use the DOM for that, but then you'd have to
export the projection matrix of objects and of the camera... messy.

So, that leaves drawing text inside THREE.  One of the suggested way is to draw
the text to a canvas, blit that canvas to a texture, put that texture on a
mesh/sprite and put it in the scene.

That works, with some gotchas.  You have to measure the text before hand, in
order to know how large the texture should be to hold the full text.  It might
make more sense to create textures for each letter, and stitch them in
order... it looks like a number of textures vs. number of vertices tradeoff.

Anyway, textures size are power of twos, so you have to be careful here.
Especially as most fonts are antialiased by default (and there's no way to
render them without antialiasing, in the canvas or in the browser).  If you use
a small and upscale it in your scene, you will see all the antialiased pixels
and it will ... basically look like crap:

[[file:data/three-font-fail.png]]

This is the default font blown up by 3, drawn at 8pt to the canvas.  (Here I am
using NearestFilter for the texture magnification, but it still looks like crap
with Linear)

Now, drawing it larger doesn't necessarily solves the problem:

[[file:data/three-font-fail2.png]]

Here it is drawn at 80pt.  it's legible, but not necessarily clean, and kerning
is off.  It's better with the linear filter:

[[file:data/three-font-linear.png]]

But the edges are too smooth, too round.  As if we had applied a font shadow.

Here it is rendered at an exact 24pt, no texture scaling:

[[file:data/three-font-correct.png]]

That's perfect legibility... but it only works if the text is never scaled.

And actually, that's not at all what I wanted.  See, I want old school, crispy
clear fonts, not fancy curvy serifs.

I can blow the resolution up (and use image-rendering: optimizeSpeed):

[[file:data/three-font-crispy.png]]

Pixels!  That's actually.. not too bad.  But the antialised font blown up like
this are not what I want, so we'll have to resort to bitmap fonts:

[[file:data/three-font-crispier.png]]

This is is 8pt Dina, blown up 3 times with NearestFilter all the way.  No alpha
in these pixels.  Extra crispy.

This fit more the vibe of the cube.  We can also smear butter over the screen
for this retro SNES-over-composite vibe:

[[file:data/three-font-success.png]]

Now here, since the font has no antialiasing, the linear filter is done on white
pixels, so it is still legible, just blurry.

*** Picking
THREE has a Raycaster facility.  However, no-one told the mouse coordinates had
to be in normalized device coordinates (-1,1,1,-1), and I was using screen
coordinates for my orthographic camera...

Anyway, it works fine: it gives all the objects intersecting the ray.  I wonder
if I can get all objects in an area...  It seems with an Octree I could do a
rough search.

[[HTTPs://stackoverflow.com/q/20169665][Another suggestion]] is to render the scene to a texture, with a unique color for
each object, keep the pixels corresponding to the selected area, and translate
back from colors to objects.  Clever; and the GPU does most of the work.

*** Pathfinding
For pathfinding, one way is to [[https://github.com/nickjanssen/PatrolJS][use navigational meshes]].

* [2017-07-20 jeu.]
** Trying out afl-fuzz for megado                                    :megado:
It's a generic fuzzer: it tries to generate input that cover different paths in
the binary in order to make it crash.

Setting it up was a bit of a pain.  First I wanted to compile the dependencies
to megado statically.  I figured, since we already hardcode the
environment... that would make invoking the binary easier.

After that, running the fuzzer is a matter of:

: make CC=afl-gcc USER_FLAGS=-DTIMEOUT=1000
: env AFL_I_DONT_CARE_ABOUT_MISSING_CRASHES=1 AFL_SKIP_CPUFREQ=1 afl-fuzz -i roms/ -o outdir -m 500 build/megado-bin @@

Unfortunately, after a bunch of warnings about non-interesting test cases, I get
to the main window of afl-fuzz, and it looks like it will spend... at least some
hours to get a result.

That's because running the emulator on a ROM is pretty slow.  When to stop?
Here I stop after 1000 cycles, which is really not that many instructions.  And
the fuzzer already complains our tests case take too long.

I guess afl-fuzz is not really suited for testing large binaries like this,
especially an emulator.

Maybe if we split the M68k interpreter as a dynamic lib, we could fuzz this
separately using this tool.

Or maybe there are settings that could help.  Let's RTFM.

#+BEGIN_QUOTE
Note that afl-fuzz starts by performing an array of deterministic fuzzing
steps, which can take several days
#+END_QUOTE

Hmm...

#+BEGIN_QUOTE
At minimum, you want to allow the fuzzer to complete one queue cycle, which may
take anywhere from a couple of hours to a week or so.
#+END_QUOTE

Okay... we'll probably not be running this on Travis then.

#+BEGIN_QUOTE
Your CPU will run hot and will need adequate cooling. [...] when fuzzing on less
suitable hardware (laptops, smartphones, etc), it's not entirely impossible for
something to blow up.

[...] you shouldn't be fuzzing on systems where the prospect of data loss is not
an acceptable risk.

[...] with very heavy I/O, the lifespan of many HDDs and SSDs may be reduced.
#+END_QUOTE

Figures.

Okay, I'll probably skip the fuzzer.  But that gives me another idea...

* [2017-07-22 sam.]
** Investigating cargo check --lib bug                           :cargo:rust:
https://github.com/rust-lang/cargo/issues/3624

`cargo check --lib` will give warnings only the first time, but `cargo check
--bin foo` will give them every time.

(For later: what's the behavior for examples/benches/tests?)

It seems this is a freshness issue.  For some reason, compilation of binary
targets always happen, hence we get warnings.  But library targets are not
compiled, and we get no warnings.

cargo uses values for "Dirty", "Fresh" and "Freshness" in the compile function.
What are the exact meaning of these terms in this context?

#+BEGIN_SRC rust
/// Indication of the freshness of a package.
///
/// A fresh package does not necessarily need to be rebuilt (unless a dependency
/// was also rebuilt), and a dirty package must always be rebuilt.
#[derive(PartialEq, Eq, Debug, Clone, Copy)]
pub enum Freshness {
    Fresh,
    Dirty,
}
#+END_SRC

In the compile function, "dirty" and "fresh" relate to closures that will carry
on the work in each respective case.  And "freshness" tells which one should be
used for this compilation unit.

Trying this:

#+BEGIN_SRC rust
        if unit.profile.check && unit.target.is_lib() {
            freshness = Freshness::Dirty;
        }
#+END_SRC

This does get the warnings each time, but it also recompiles every library,
regardless of their freshness.  Here is a run of `cargo check --lib` on cargo
itself:

#+BEGIN_EXAMPLE
 Compiling utf8-ranges v1.0.0
   Compiling glob v0.2.11
   Compiling semver-parser v0.7.0
   Compiling dtoa v0.4.1
   Compiling void v1.0.2
   Compiling matches v0.1.6
   [...]
    Finished dev [unoptimized + debuginfo] target(s) in 12.59 secs
#+END_EXAMPLE

Compared to the `0.1` seconds the same call takes without this modification, I
don't think the warnings are worth waiting this long.

But we shouldn't be compiling all libs, surely.  Only the crate lib for `cargo
check --lib`.  But how to target that?

@ehuss replied on the PR and got the right idea there:

#+BEGIN_SRC rust
if unit.profile.check && unit.pkg.package_id() == cx.ws.current_opt().unwrap().package_id() {
     freshness = Freshness::Dirty;
}
#+END_SRC

I don't know if I would have found that...

Anyway, it works.  Too bad we now have to actually compile stuff to get warnings
even though the files are fresh.  Seems wasteful.

* [2017-07-24 lun.]
** Getting my own domain name                                :dns:0xc0de:ovh:
So, since I helped M set up their VPS and domain on OVH, I figured: maybe it's
time I get my own domain.

I'm rather happy using Gmail and Github for hosting most of my stuff, but should
I ever switch (or, rather, should they ever turn evil... or /eviler/), users
wouldn't notice if everything was seemingly hosted by my domain.

Plus, one place to put everything I want.

But I still wanted to keep using those services, just behind my domain.  Turns
out, this can be done.

Buying the domain on OVH is easy enough.  Choosing the name was the hardest
part.  It's a bit cheeky, but I'm rather happy with it.

Now, to configure the DNS.  First thing I cared about was Email.  I know that
OVH gives a basic plan for my mail with a domain purchase... but I didn't want
to have /yet another/ email account.  Rather, I wanted to keep using Gmail, but
send and receive email from @mydomain.

*** Sending and receiving email from a custom domain                   :mail:
Turns out, there is a way to do that, but it's not perfect.

To /receive/ email sent to me@mydomain, I need an MX record and a redirect
server.  When mail is addressed to me@mydomain, the mail transfer agent looks up
the MX record of mydomain to know the address of the server to send the mail
to.  It doesn't even care about anything in front of the '@'.

So far, the MX record is already set up to point to the redirect server of OVH.
So now the OVH mail server gets my mail, but I need it to go to me@gmail.  Well,
OVH provides an easy setup for that, and there's even [[https://docs.ovh.com/fr/fr/web/emails/guide-des-redirections-emails/][a guide]].

They take care of forwarding the mail to gmail at no extra cost.  You can
forward up to 1000 addresses per domain, so I should be good for a while.

The only downside is that it adds a server in the chain, so it's an additional
potential point of failure.  Crucially, it could hold up mail, or even drop it
without me knowing.  So far I haven't had any issues, but I'll monitor the
delivery times.  To mitigate the issues, I can keep giving the me@gmail address
to critical services (like, the French Tax Office).

Now, to /send/ mail from me@mydomain, it's a tad more complex.  Traditionally,
SMTP servers did not care about the From: field of a mail.  It's very convenient
as long as people act responsibly.  Of course, the Internet has been overrun by
jerks since 1989, so tighter restriction on From: fields had to be enforced.

First of all, the Gmail interface doesn't let you change the From field when
writing a mail.  You have to go to Accounts, and add another email address.
They require SMTP credentials for this server, even if it's theirs (go
figure...).  And, crucially, it won't work if you have 2-factor authentication.

You have to generate an app password and use that.

Now, you can send email from me@mydomain, and correspondents won't ever know you
sent your email from Gmail—unless of course they routinely peruse the headers,
but that's fair game.

So, that works from the Gmail interface.  But what if you want to send your
email from, say, Thunderbird?  Well, apparently, you can't.  I mean, you can put
anything in the 'From' field, of course, but the mail will most likely appear as
'Sent from me@mydomain on behalf of me@mydomain'.

I read that this feature is supported, but when you have a Google Apps account
(hint: it's not free).  Tricky fellows.

Well, alright.  I can keep using the webmail; the Thunderbird has no integration
for conversations anyway.  (At this point, I'm realizing that Gmail might be a
proprietary extension of email that's only loosely compatible with open
protocols... that would make an eventual switch easier to stomach).

There's one more thing though: SPF.  I'm not sure it's essential, but it helps
to not have your mails be classified as spam.  SPF records (which are actually
TXT DNS records) are used to tell the outside world that, yes, it's okay if your
receive mail from mydomain that has been sent by Google.  Gmail has [[https://support.google.com/a/answer/178723?hl%3Den&ref_topic%3D2759192][a doc on that]].

At this point, I have a custom email address, and I'm rather happy about it.  (I
used to have a snazzy @poulet.org email... but after a while I think my account
just went down the drain, and I never dared ask the admin about it).

*** Using my custom domain for my Github pages                   :github:dns:
So, I wanted to have fmdkdd.0xc0de.fr point to fmdkdd.github.com.  This is easy:
add a CNAME entry to the DNS zones file.  OVH has a GUI for that.

Beware though, as the GUI can be tricky: it's supposed to be a pretty-printed
table of the entries in the zones text file, but I've seen first-hand that
sometimes it didn't show entries that were in the zones file, and vice-versa.
Compounded by my total lack of knowledge of the field, this had me puzzling for
a while.

Anyway, just adding the CNAME entry from fmdkdd.0xc0de.fr -> fmdkdd.github.com
was not enough.  You have to tell github that fmdkdd.0xc0de.fr is now the
canonical name (the C in CNAME).  Luckily, Github has a guide on that as well,
but it's only a single settings in the admin page for the project anyway.

Once both sides are configured, going to fmdkdd.0xc0de.fr correctly loads what
fmdkdd.github.com previously hosted.  And going to fmdkdd.github.com redirects
to fmdkdd.0xc0de.fr (301 Moved Permanently).

Good.  As an added effect, every gh-pages of other projects I had, which were
hosted under fmdkdd.github.com/foo, are now redirected the same way.

There's only one downside with this setup: I've lost HTTPS support.

See, Github pages are served using HTTPS, and that's very nice.  Although,
honestly, it's not all of that useful for my projects pages since... I just
serve dumb HTML or client-only JavaScript apps.  Unless I'm mistaken, not much
information to leak there; not very worthwhile to man-in-the-middle either.

But, still, having HTTPS would be sweet.  Seeing as HTTP is getting closer and
closer to drop off the face of the web.

Well, turns out that [[https://github.com/isaacs/github/issues/156][I'm not the only one]].

Someone in this thread suggested Netlify, so I investigated.

This a free service for deploying and hosting static pages with a content
delivery network.  It's actually pretty sweet, and easy to use.  You can login
with your Github account through OAuth.  Point to a repository, give deployment
instructions, and they continuously deploy your branch to their CDN.

And of course, they support SSL for custom domains with Let's Encrypt.

That changes the previous setup, however.  First, I have to create a Netlify
site, say potato.netlify.com (they have random names by default).  Let's say
this builds my fmdkdd.github.com project (which is still /also/ deployed at
fmdkdd.github.io).  Now, I have to point fmdkdd.0xc0de.fr to
potato.netlify.com.  Then, when I'm sure the DNS are setup properly, I enable
HTTPS.  Bingo!

But now I have an issue: I have a bunch of gh-pages that are still deployed on
Github... and fmdkdd.github.io/foo still redirects to fmdkdd.0xc0de.fr/foo, but
it's a 404, since fmdkdd.0xc0de.fr points the netlify deployed site, and it only
contains my webpage.

Solutions:

1. Github supports setting a CNAME per-project.  So I could setup deployment of
   all my projects on netlify, and add a CNAME in my DNS and in Github to
   foo.0xc0de.fr for each project.

   A bit cumbersome, but now everything would be using SSL.  Also, Netlify
   deployments are easier to setup than Github's (they can actually build stuff,
   whereas Github just copies the contents unless you use Jekyll).

   And in fact, I don't even need to deploy on Github anymore, I can move
   everything to netlify.  Less branches on Github, less hassle with CNAME on
   Github's side.

2. Setup a mega project that's deployed as one website on Netlify to replicate
   the hierarchy fmdkdd.github.io/foo1 fmdkdd.github.io/foo2, etc.

   The mega project would have all the individual projects as submodules,
   and... okay not, that's probably a bad idea.

   Besides, there's something a bit strange with the fmdkdd.github.io/foo1
   scheme: what happens if the fmdkdd.github.com has a foo1 folder?

3. Forego SSL.

I think I'll go with 3 for now.  We'll see if Github eventually implements SSL
for custom domains.  If I ever feel like going through all my projects to setup
the deployments again, I might tackle #1, but now is not the time.

Hmm, it looks like even with the 'simple' setup, Github is making this hard on
me here.  Going to fmdkdd.github.io/foo redirects to fmdkdd.0xc0de.fr/foo, even
though fmdkdd.github.com redirects to 0xc0de.fr, and not to the subdomain...

So I'll have to put explicit CNAME everywhere?  Might as well deploy directly to
Netlify, so I can skip this hassle on Github.  To keep the old URLs active, I
just have to push 301 redirect pages to my gh-pages branches.

Okay, later.

[Update the day after]

Actually, the problem arises when I try to access https://fmdkdd.github.io/s3c:
this is redirected to https://fmdkdd.0xc0de.fr/s3c by Github, but there's
nothing there (since the canonical name is supposed to be 0xc0de.fr), plus it's
HTTPS.

Going to http://fmdkdd.github.io/s3c redirects to http://0xc0de.fr/s3c.

Actually, it seems I only have the issue in my browser.  Wget goes to 0xc0de.fr
with the https link just fine, and so does my Firefox on Android.

Hmm, maybe Firefox has a DNS cache or something?  Clearing the DNS does nothing.

Actually, this does not happen for all of my project pages.  This is quite
puzzling.

Using "Forget about this site" for https://fmdkdd.github.io/s3c fixes it.
Shrug.

Another thing that might be useful one day: since I'm running my own DNS server,
I can use `unbound-control flush 0xc0de.fr` for faster turnaround when tweaking
things in my DNS zones.

Even better, I guess I could tweak the zones directly in my local DNS server,
and once I find something working, I can update my OVH Zones.

* [2017-08-24 jeu.]
** Trying to tackle the cargo caching warning PR                 :cargo:rust:
Heads up: compiling rustc from scratch takes around 1h on my machine and 4Gb
disk space.

Actually, I don't even know if extracting the diagnostics from rustc is a good
first step.  I could just try to save rustc output received by cargo to a file,
then replay if the output is fresh.  /Then/ we would see what kind of issues
arise from that.

Hmm, just tried a very simple patch to save the diagnostics to a file, and that
built cargo fails with:

: error: unknown crate type: `metadata`

and indeed, it calls `rustc` with:

: Running `rustc --crate-name cargo_targets src/lib.rs --crate-type metadata

whereas the standard cargo uses ~lib~ as crate-type, as I would expect.  Doesn't
look like my patch is guilty here.

Okay got it, I based my new branch of an 8-month old commit... I did find
suspicious that my previous PR fix wasn't in there... anyway.  Updating.

Proof of concept of saving diagnostics to a file and loading them on a fresh
unit works.  It's /very rough/, but it works.

Next step:
- separate saved diagnostics per unit
- ensure modifying the crate triggers a recompilation/not modifying gives us
  saved diagnostics

* [2017-08-30 mer.]
** Step by frame                                                     :megado:
I was trying to implement a step_frame feature... but decided against it as it
is quite tricky to get right, and the sole reason of using a debugger is to
/find/ bugs, not create them.

What's tricky is the interaction of step by frame with breakpoints: stepping by
a whole frame is easy enough, but when you hit a breakpoint you want to stop the
emulation right here.  However, if you stop the M68k, what happens to the other
components in the system?  Should the Z80 catch up?  Should the VDP?  Should the
sound?

Say, you run the m68k for 100 cycles in genesis_frame, then hit a breakpoint.
Conceptually, the Z80 should run for 50 cycles to be in sync.  If it doesn't,
then when we resume emulation (by step, or by frame, or running), the m68 will
run for 488 cycles, then the Z80 will run for 244.  So the m68 will still be 100
cycles ahead.

Should we still draw a scanline if the m68k stops at 100 cycles?  Probably not:
vdp_draw_scanline has side effects, and should only be called after the proper
number of cycles has elapsed in the m68k.

I guess the correct way to solve these issues would be to have a debt of master
cycles to run: genesis_frame runs the m68k for 488 cycles say, but it might exit
early, so get the actual number of cycles run.  Then add this debt to the other
chips, and allow them to catch up.

The VDP should also behave in this way, with a run_cycles function that takes
the number of elapsed cycles, and do something if enough have elapsed.

* [2017-08-31 jeu.]
** YM2612 frequency calculations                                     :megado:
Got the YM2612 to output sound, but the frequencies seem off.

Maybe I should just try to output a plain 440Hz sine wave, and see if that's
indeed what I get.  If I do get it, then I need to implement modulation through
the operators.  If I don't get it, then I need to fix the frequency calculation.

So according to my calculations, I should output 440.53Hz (A4), but Audacity
spectrum analysis reports a 391Hz peak (G4).

Let's see.  I'm emitting one sample every 8.7 YM2612 clock.  In one second, at
44100, there are:

: 8.69665873016 * 44100 = 383522.965 YM2612 clocks in one second
or
: 7670453 / 20          = 383522.65

A 440Hz tone has 440 periods in one second, so:

: 383522.65 / 440 = 871.64 YM2612 clocks per period

But when I'm using 871 as freq number, I output a 488Hz tone, not 440Hz.  What
am I missing?

Hmm... Okay.  Reverse calculations: I know that a freq number of 1084 should
output a 440Hz tone, according to the formula in the YM2612 manual:

: freq number = (144 * note * 2^20 / Master_freq) / 2^(block - 1)

and the master frequency of the YM2612 is 7670453 according to [[https://segaretro.org/Sega_Mega_Drive][this]].

So:

: 1084 * 440 = 476960 YM2612 clocks per second
: 476960 / 44100 = 10.8154195011 clocks per samples

And I get... a 477Hz tone.  Grmbl.  But wait a minute, the spectrum appears to
not be very reliable when reporting the peak tone, I see variations of around
~20Hz.

Furthermore, if I generate a 440Hz tone and use the spectrum, it reports between
406Hz and 496Hz...  Looks like I have wasted time!

Listening to the intervals is better.  Hears like my 440Hz is too low.  But
fudging the number of samples means we don't have the same length with the PSG!

Actually, the frequency of the YM2612 is not a multiple of the PSG freq!  So the
two sound very bad when played together right now.

Haha! It's a bit better now: we can recognize the melody.  I did not notice
until now that the freq number were growing proportionally to the frequency
numbers... which is absurd!  I was using the freq number to load the internal
counter, but of course, if the frequency is higher, the counter needs to be
smaller.

It's still off, but at lest I'm on the right track.

So I found the bug: in ym2612_clock, when reloading the sample counter, we were
not counting the channel clock that had happened.  Off by one!  But on the scale
of 9 clocks, it mattered a lot.

Now my calculations match: when asking for a 440Hz tone, I know I need a freq
number of 1176:

: 2048 - 1176 = 872 clocks/period
: 872 / 8.697 = 100.264 samples/period
: 44100 / 100.264 = 439.839 period/sec (Hz)

Pretty close.

But!  Sonic still sounds bad.  Probably because the freq numbers used by the
program do not match mine.  According to the formula:

: freq_number = (144 * note * 2^20 / master_freq) / 2^(block - 1)

So according to this formula, 440Hz corresponds to the freq number 1084.  But,
1176 is what gets me nearer to 440Hz.  So, the master frequency is off in this
case.  Let's compute it backwards, assuming 1176 matches a 440Hz tone:

: 1176 = (144 * 440 * 2^20 / master_freq) / 2^3
: master_freq = 7061838.36737 Hz

Strange frequency... but alright.  Let's use that.  Doesn't sound better, at all.
In fact:

: 2048 - 1084 = 964 clocks/period
: 964 / 8.697 = 110.843 samples/period
: 44100 / 110.843 = 397.860 Hz

So the clocks per sample constant (8.7) is wrong?

: 44100 / (964 / x) = 440
: x / 964 = 440 / 44100
: x = 9.61814058957

And if the master cycles per clock is 20:

: 9.61814058957 * 44100 * 20 = 8483200 Hz

and if the frequency stays at 7670453, the cycles per clock is at:

: 9.61814058957 * 44100 = 7670453 / mpc
: mpc = 18.083866937

Not a round number.  Let's hear it.  Still bad.

Okay, maybe I should go on implementing the rest of the frequency modulation,
since without detunes/multiples and modulation, it's hard to know whether this
is the expected sound.

* [2017-09-03 dim.]
** YM2612 reference posts on spritesmind                             :megado:
Nemesis explanations on the workings of the YM2612 are a gold mine:

- [[http://gendev.spritesmind.net/forum/viewtopic.php?p%3D6114#p6114][Post about the operator unit as whole]]
- [[http://gendev.spritesmind.net/forum/viewtopic.php?p%3D6177#p6177][Post about the phase generator]]
- [[http://gendev.spritesmind.net/forum/viewtopic.php?p%3D5716#p5716][Post about envelope and SSG register]]

This [[http://gendev.spritesmind.net/forum/viewtopic.php?f%3D2&t%3D2227][aggregating post]] for the overall MD research is also priceless.

* [2017-09-05 mar.]
** Additional YM2612 reference                                       :megado:
- [[http://gendev.spritesmind.net/forum/viewtopic.php?f%3D24&t%3D1883][Frequency tables]]
- [[http://gendev.spritesmind.net/forum/viewtopic.php?f%3D24&t%3D1387&hilit%3Dfrequency][Some discussion on timing]]

** Some YM2612 progress                                              :megado:
Following the tremendously useful resources above, the YM2612 does not sound bad
now.  A tad too slow, but it's mostly there!

[[file:data/2017-09-05-sonic1.ogg][Here's the Sonic 1]] title screen and demos.  And [[file:data/2017-09-05-phantasy-star-4.ogg][here's Phantasy Star IV]].

* [2017-09-06 mer.]
** Potential culprit for the wrong frequency of the YM2612           :megado:
So, after double-checking the frequency numbers, the output of the YM2612 still
sounds too slow, by about 15~20%.  I'm not sure what is causing it, but here are
potential causes:

1. We don't account for actual cycles emulated by the M68.  We assume it runs
   for 488 cycles, and run the YM2612 for that many cycles as well.

   I've changed it so that we run the YM2612 for the actual number of emulated
   cycles, so now on average we run for 488 cycles before Hblank.

   The alternative is to synchronize everything to elapsed emulated time, though
   it's prey to floating point inaccuracies.

   Since we always ran ahead of 488 (often 496), in practice it could have a
   small impact (~1%) on the timing, but that's not enough to explain the 15%
   disparity I'm hearing.

2. Dropping samples from 53267Hz to 44100Hz.  The YM2612 maximum output
   frequency is the former, but we actually write a file at 44100Hz sample
   rate.

   The way we do that currently is we skip one out of every 5 clocks of the
   YM2612 when sampling:

   : -C---C---C---C---C---C-        <- C: YM2612 clock
   : -S---S---S---S---.---S-        <- S: write sample

   So the sampling interval is actually not uniform along time.  We should have
   this instead:

   : -C---C---C---C---C---C-        <- C: YM2612 clock
   : ----S----S----S----S---

   I guess it can mess up reconstitution of the waveform since it assumes a
   uniform sampling rate.  However, dropping sample is what I did in Boyo/GBS to
   downsample the APU and it sounded okay.  Even now in YM2612, apart from the
   slowness of the YM2612, it's close to what the MD emits.

   However, 53267/44100 ~= 1.208, so it could be the culprit here.

   But the strange thing is that I /can/ output at 53267Hz directly, by emitting
   a sample every clock.  I tried that, and Audacity correctly reports the
   sample rate, but there is no difference to be heard between the two.

   One issue here is that I'm doing the sampling test in the clock, so we are
   tied to the clock frequency.  It's okay because sampling frequency is lower
   anyway, so we don't miss anything.  And since we are not pushing the samples
   in a WAV, it does not matter /when/ exactly between clocks we sample, since
   the channel output is exactly the same between two FM clocks (that will not
   be true once envelope is implemented though).

   I think what I could check is the actual sampling frequency: how many samples
   I get in one second of emulated time, how many FM clocks, and how many cpu
   cycles; to make sure everything matches up.

   In one second I should have: 7670453 M68k cycles, 53267 YM2612 clocks, and
   44100 samples.  Since nothing is synced to time yet, I can count until
   7670453 M68k cycles and check the other counts align.

Here is a trace of these count on Sonic 1:

|------------+----------+---------+----------+--------------|
|       M68k |   YM2612 | M68k/YM |  Samples | M68k/Samples |
|------------+----------+---------+----------+--------------|
|    7670462 |    53303 |  143.90 |    44130 |       173.82 |
|    7670461 |    53276 |  143.98 |    44107 |       173.91 |
|    7670462 |    53267 |  144.00 |    44100 |       173.93 |
|    7670457 |    53291 |  143.94 |    44120 |       173.85 |
|    7670462 |    53463 |  143.47 |    44262 |       173.30 |
|    7670455 |    53728 |  142.76 |    44482 |       172.44 |
|    7670468 |    53597 |  143.11 |    44373 |       172.86 |
|    7670455 |    53824 |  142.51 |    44561 |       172.13 |
|    7670458 |    54042 |  141.94 |    44742 |       171.44 |
|    7670459 |    54054 |  141.90 |    44751 |       171.40 |
|    7670454 |    54058 |  141.89 |    44755 |       171.39 |
|    7670463 |    54058 |  141.89 |    44755 |       171.39 |
|    7670462 |    54058 |  141.89 |    44755 |       171.39 |
|    7670457 |    54054 |  141.90 |    44751 |       171.40 |
|    7670460 |    53887 |  142.34 |    44613 |       171.93 |
|    7670459 |    53672 |  142.91 |    44436 |       172.62 |
|    7670458 |    54666 |  140.31 |    45258 |       169.48 |
|    7670461 |    54654 |  140.35 |    45248 |       169.52 |
|    7670460 |    54395 |  141.01 |    45034 |       170.33 |
|    7670465 |    54420 |  140.95 |    45055 |       170.25 |
|    7670462 |    55254 |  138.82 |    45745 |       167.68 |
|    7670455 |    55317 |  138.66 |    45797 |       167.49 |
|    7670454 |    54919 |  139.67 |    45467 |       168.70 |
|    7670457 |    54694 |  140.24 |    45282 |       169.39 |
|    7670458 |    54177 |  141.58 |    44853 |       171.01 |
|    7670459 |    53383 |  143.69 |    44196 |       173.56 |
|    7670456 |    53295 |  143.92 |    44123 |       173.84 |
|    7670457 |    53264 |  144.01 |    44098 |       173.94 |
|    7670456 |    53275 |  143.98 |    44106 |       173.91 |
|    7670463 |    53343 |  143.80 |    44163 |       173.69 |
|    7670460 |    53641 |  143.00 |    44410 |       172.72 |
|    7670461 |    53509 |  143.35 |    44300 |       173.15 |
|    7670462 |    53773 |  142.65 |    44519 |       172.30 |
|    7670457 |    54022 |  141.99 |    44725 |       171.50 |
|    7670456 |    54062 |  141.88 |    44758 |       171.38 |
|    7670459 |    54050 |  141.91 |    44749 |       171.41 |
|    7670458 |    54062 |  141.88 |    44758 |       171.38 |
|    7670465 |    54058 |  141.89 |    44755 |       171.39 |
|    7670454 |    54058 |  141.89 |    44754 |       171.39 |
|    7670463 |    54054 |  141.90 |    44752 |       171.40 |
|    7670456 |    53550 |  143.24 |    44334 |       173.02 |
|    7670463 |    54113 |  141.75 |    44801 |       171.21 |
|    7670454 |    54388 |  141.03 |    45028 |       170.35 |
|    7670459 |    54392 |  141.02 |    45031 |       170.34 |
|    7670456 |    53867 |  142.40 |    44597 |       171.99 |
|    7670463 |    55241 |  138.85 |    45734 |       167.72 |
|    7670458 |    54852 |  139.84 |    45412 |       168.91 |
|    7670459 |    54317 |  141.22 |    44969 |       170.57 |
|    7670460 |    54070 |  141.86 |    44765 |       171.35 |
|    7670461 |    53383 |  143.69 |    44196 |       173.56 |
|    7670454 |    53299 |  143.91 |    44127 |       173.83 |
|    7670455 |    53267 |  144.00 |    44100 |       173.93 |
|    7670456 |    53264 |  144.01 |    44097 |       173.95 |
|    7670459 |    53307 |  143.89 |    44133 |       173.80 |
|    7670454 |    53586 |  143.14 |    44364 |       172.90 |
|    7670463 |    53601 |  143.10 |    44377 |       172.85 |
|    7670456 |    53724 |  142.78 |    44478 |       172.46 |
|    7670455 |    53959 |  142.15 |    44673 |       171.70 |
|------------+----------+---------+----------+--------------|
| 7670458.80 | 53933.74 |  142.23 | 44651.97 |       171.80 |
|------------+----------+---------+----------+--------------|
#+TBLFM: @III=vmean(@II..III);%.2f

So one interesting observation is that while we are consistently over the M68k
cycles target (which is expected because we are unlikely to exactly get 7670453
cycles), we are also consistently /under/ the 144 cycles per YM2612 clock and
173 cycles per sample targets.  And these cycles per X figures account for
the extra M68k cycles over the 7.67Mhz target.

However, the differences are on the order of 1%, not 15%, so I'm not sure it's
the root cause here.

* [2017-09-07 jeu.]
** Using SDL for outputting audio                                    :megado:
We are using GLFW for handling the window, but I guess I can use SDL to handle
only audio.

Using SDL_QueueAudio, I'm able to queue samples as soon as they are ready in the
YM2612, and SDL handles draining them to the audio device at the requested
sample rate.

At first, audio output was lagging severely behind the video output: at least 3
seconds behind, with Vsync on.  And unexpectedly, with Vsync off, the audio is
playing at the same speed, while the video is 3 times faster.

I double checked the constants, and ended up tweaking the number of M68k CPU
clocks we use in genesis_frame based on the master clock:

There are 3420 master clocks per scanline.
The NTSC master clock is 53693175 Hz.
H32 mode is 256 pixels wide -> 2560 master clocks for pixels + 860 master
clocks for HBlank.

M68k divides the master clock by 7, thus:
- 2560 / 7 ~= 365 cycles before vdp_draw_scanline
-  860 / 7 ~= 122 cycles during Hblank

And using these numbers of cycles synced up the audio and video pretty well.  It
did not occur to me that the slower tempo of the WAV output was caused by a
larger slice of emulated M68k.  Conversely, shortening the cycles slice in
genesis_frame hurries the tempo without altering the frequencies of the note.

I understand that larger time slices will take more time to react to key on/key
off changes, but I don't understand how shorter time slices end up playing the
notes quicker.

Better make sure the timings are proper anyway, as the framerate seems slow to
me in Vsync.

53693175Hz master clock rate
3420 master clocks (MC) per scanline
- 2560 MC for the pixels + 860 MC for Hblank

224 lines (in NTSC progressive scan)

: 3420 * 224 = 766080 master clocks per screen

There are 896040 MC per frame, so:

: 896040 - 766080 = 129960 MC for Vblank

The NTSC refresh rate is 59.9227434043Hz, pretty close to 60Hz, so with Vsync
turned on in the emulator, we should be pretty close to actual NTSC speed.

I ought to double check what I get per frame.

Also, why is the audio not running faster with Vsync off?  Actually, the audio
is not synced to the running speed at all, it just sounds good with vsync on
because the timings align.

Ah, I see.  With vsync on, the audio queue is draining at just the right speed,
but with vsync off, its filling fast.  So we are in fact pushing samples into
the queue as fast as the emulation is going, but we are not /playing/ them fast
enough.  But that makes sense, because we are not running the console at 60Hz
anymore, but at 200Hz, so the sampling rate should follow.

But, the sampling rate cannot follow!  Whereas we can pump video frames at
200Hz, if the screen supports only 60Hz, the extra frames will be dropped, here
everything in the audio output queue is played, so we must drop samples if we
want to synchronize with the video output.

Hmm, trying to resolve this issue using SDL callback instead.  Didn't work.  The
idea was that the SDL audio callback would ping us every 11ms (with a 512
samples buffer), and then we would resample all the samples we had accumulated
in that time to the 512 samples buffer, so it would fit to 44100Hz.  The timing
works, but the result sounds like shit, as we keep underunning the accumulated
samples buffer.  The number of accumulated samples available is really not
consistent between callback invocations.

One difficulty is that we don't know how fast we are supposed to be running the
emulation, so we don't know how many samples we need to pick from the buffer.
Draining the whole buffer leaves us dry for the next callback.

I'll revert that and leave the audio working on vsync, for now.

Got the PSG and YM2612 to output together by using the two stereo channels.  I
can't just mix both together by adding their channel outputs, since the PSG is
not normalized (centered around 0).  There are still audio skips, and the
downsampling is bad, but it's heartwarming to finally hear the catchy tunes in
our own emulator in real time!

* [2017-09-15 ven.]
** Syncing to audio                                                  :megado:
After hours of toiling away at the problem, it works!

Okay so, running by video frame slice meant that CPU and video timing was right,
but audio was not, since it meant we were emulating 16ms slices, which amount to
~730 audio samples at 44kHz all at once.

So we actually have to emulate on slice of audio frames, instead of video
frames.  That means emulating enough of the Genesis to produce exactly one audio
sample, sample the PSG and YM2612 at this time, and queue the samples.

In the process, it meant I had to add a vdp_run_cycles function to catch up the
VDP based on the number of master cycles.  We could probably factorize some code
with draw_scanlines, but for the moment I wrote it to do the same thing as when
draw_scanlines was called by genesis_frame.

But now code of each subsystem is more homogeneous, as they are all based on the
number of master cycles elapsed.

And the number of emulated master cycles is decoupled from wall time, so
speeding up/slowing down the emulation now also speeds up/slows down the audio
and video.  It's a nice effect.

Next step is to make sure that debugging works with these changes.

* [2017-09-21 jeu.]
** Tasks before merging sdl-audio back into master                   :megado:

1. Fix the speed throttling.

   Measuring lag on one audio frame is not robust enough.  We need an accurate
   measure of "the machine is too slow".  Alternatively, find a way to run as
   fast as possible, but not faster.

2. Make sure debugging does not mess up the master cycles timing.

   That includes stepping, breakpoints and rewinding.

3. Fix the AppVeyor build.

These two tasks need to be resolved before merging back.  Unfortunately, hacking
on the YM2612 is much more satisying at the moment.

** Fixing frequency calculations                                     :megado:
To get the note:

: freq_number = (144 * note * 2^20 / Master_freq) / 2^(block - 1)

: fnum * 2^(block-1) = 144 * note * 2^20 / master_freq
: fnum * 2^(block-1) * master_freq = 144 * note * 2^20
: note = fnum * 2^(block-1) * master_freq / 2^20 / 144

Well, not sure about the resulting values anyway.

** Additional info on the YM2612                                     :megado:
[[http://gendev.spritesmind.net/forum/viewtopic.php?p%3D7967#p7967][Corrections on the envelope generator]].  Crucially, the envelope generator clocks
every 3 FM clock, not with a weird ratio.

[[http://gendev.spritesmind.net/forum/viewtopic.php?p%3D5650#p5650][CSM mode]].  A variant of special mode for channel 3.

** Trying to implement the envelope generator                        :megado:
Well, I'm still missing some pieces.  The bad part of following the docs is that
when they don't have all the answers, I'm essentially blind.

Also, I'm not sure the operator modulation is correct.  Most tracks I have
listened to use algorithms 5, 6 or 7, and there, no modulation (except maybe
feedback) happens.  But algorithm 0 is all noisy if I implement modulation
following the info from Nemesis.

Checking by ear for these details is essentially useless.  I need some ground
truth, from a console or another emulator.

* [2017-10-05 jeu.]
** Playing GYM files                                                 :megado:
So, it turns out, [[http://vgmrips.net/wiki/GYM_File_Format][GYM files]] are much simpler than GBS files.  GBS files are a
trace of CPU instructions that pertain to the playing of audio samples, so to be
able to play them you need to implement the GB sound generator /and/ the GB CPU.

GYM files, on the other hand, are just a trace of the register writes to the PSG
and YM2612.  No need to emulate the CPU, which makes them great for testing the
accuracy of the YM2612 and PSG against other GYM players.

One downside of GYM files is that if they were captured in inaccurate emulators,
then the output might not match the Genesis.  [[http://vgmrips.net/wiki/VGM_Specification][The VGM format]] is more popular,
and probably has more accurate rips.  The specification looks slightly scarier,
as it handles many different sound chips (including the GB DMG and NES APU!),
but it's still based on recording register writes, so a boon for testing.

The GYM only has 4 different instructions, so it's trivial to implement.  Right
now I can play [[https://www.emuparadise.me/music/genesis.html][many songs]] from this directly.  And I should be able to compare
the state of our PSG and YM2612 emulation to those of other players, like [[https://bitbucket.org/mpyne/game-music-emu/][GME]].

[later]

SEEEEEEEEEEGAAAAAAAAAAAAAAAAAAAAA!

I finally got to hear it emulated!  Since GME (through DeaDBeeF) was able to
play the SEGA logo correctly, I looked into the GME code.  Turns out, it's a
rather simple tweak to the YM2612: when the DAC is enabled, we play the value in
the register DAC_data instead of channel 6.  (Also, that's probably why channel
6 is mostly unused in the ROMs I've seen playing).

But!  In Megado, we never seem to see any DAC data written to the YM2612
registers.  Since the YM2612 holds only one DAC value, and these needs to be
pumped out at 44100, or 735 per video frame, maybe ROMs are using some DMA
transfer that's not implemented yet for this.

Anyway, in the GYM file, I could see the writes going to the DAC, that meant I
could play them.  However, due to the way the GYM format is set up, you get a
bunch of DAC writes in one frame (around 240 for the SEGA logo), and need to
play them back all during the frame.

So, the GYM player buffers all the DAC writes itself, and writes them back to
the YM2612 when we are emulating one video frame.

The DAC samples also need to be played evenly spaced out in the frame, or you
get something else entirely.

I believe drums samples in most tracks are also played through the DAC, so,
great progress on this front!

* [2017-10-12 jeu.]
** Checking that debugging does not mess up timings                  :megado:
I was thinking of redoing genesis_step to add a temporary breakpoint to the next
instruction, and run instead of step.

But we can't actually know what the next instruction will be without executing
at least partially the current one.  It could be a jump.

So I guess we have to call m68k_step manually, and account for elapsed cycles.

Well, actually, I don't need to account for anything.  Because calling m68k_step
returns the number of cycles we would have needed to pass to m68k_run_cycles, so
we would have added, only to subtract after, so the remaining cycles would have
not changed after this operation.

Breakpoints are still broken though.

Okay, I just needed to account for early exits in m68k_step (and the loops in
the stack) due to breakpoints.

Checking rewinding now.  Apart that they did not save PSG or YM2612 data, they
look fine.

One last thing: I don't like that we can't distinguish between m68k_step
returning 0 cycles because the instruction is bugged out, and returning 0 cycles
because of a breakpoint or error condition.

Simplest thing would be to use negative values as exceptional conditions.  But I
think we have valid instruction which take around 150 cycles, so we need to
change the return type to int16_t at least.

** Fixing throttling                                                 :megado:
The previous test of looking at the length of time since the last frame (dt) and
cutting down the speed of emulation was not robust enough.  It prevented the
emulator from slowing to a crawl and being unresponsive, but it was also
responding too quickly to instanteneous frame drops.

Instead, I went with another solution: determine a maximum time allocated for
the emulation, and break early if we overshoot it.  That way, we always try to
take not longer than the previous update call.

So what happens when we ask for a speed setting that's too high for the machine?
We abort the loop early, and leave the audio->remaining_time positive.  That
means we have not emulated enough to catch up, so we won't have enough audio
samples to feed to the audio device, and we'll have clicks.  But the emulator
stays responsive.

** Looking into OSX build on Travis                                  :megado:
Adding an OSX build to the build matrix is easy enough.  But then you have to
wait an eternity for the build backlog to clear, so I don't think that's
feasible.  I won't have the patience to iterate on the travis.yml (adding brew
commands, etc) if I have to wait 30min to 1 hour between builds.

I've also looked at alternatives to bundling the dependencies as sub modules.
Not much success.  The canonical way is, at least on Linux, to not bundle them,
and to just use the libraries installed on your system.  Of course, this only
works for libraries that are packaged by your distribution... which imgui isn't.

So once you have to deal with one dependency that's not packaged, why not
bundle them all?  It also simplifies reproducibility.

I might add a toggle in the Makefile to allow a build to use system libraries
instead of submodule deps, but that's about it.

** Trying to fix AppVeyor build                                      :megado:
[[https://stackoverflow.com/q/43441273][This]] [[https://stackoverflow.com/q/45474857][is]] [[https://stackoverflow.com/q/45452145][terrible]].

* [2017-10-19 jeu.]
** Taking another look at lsp-mode for RLS                     :lsp:rust:rls:
The setup is still a bit rough on the lsp-mode side.  I've sent patches to
improve the situation and documentation.

There was a bug with cleaning up overlays from Flycheck, I've patched that too.

More distressing is that not all diagnostics make it to lsp-mode.  Might be
related to [[https://github.com/rust-lang-nursery/rls/issues/393][this RLS issue]].

Also, lsp-mode is a bit slow (<1sec) to start when you open a buffer.  And it's super
slow (~5sec) when exiting Emacs.

My understanding is that it sends a "shutdown" message to the LSP server and
waits for the answer, to avoid killing the process and giving it a chance to
cleanup.  So lsp-mode is not to blame here, RLS is.

* [2017-12-04 lun.]
** Nil-checker redux                                            :types:elisp:
Going back to this idea.  Checking only for Nil is not the most useful, since
currently there is nothing that prevents you from writing dumb code like this:

: (car 1)

even though that's a runtime error.

Of course, no-one would write such an obvious error.  However, if you write:

#+BEGIN_SRC elisp
(defun f (l)
  (car (car l)))
#+END_SRC

Then this function can fail if ~l~ is a list of numbers.  Or, more egregiously,
if the list /contains/ a number.  Because lists are not necessarily homogeneous
in Elisp.

*** Type predicates
Also, type predicates are common in Elisp code, and a type checker that does not
account for them is practically useless:

#+BEGIN_SRC elisp
(if (listp x)
    (car x)
  (print x))
#+END_SRC

Here, the type checker should know that in the ~then~ branch of ~if~, ~x~ must
be a list.

Well, I guess that would be caught by a standard HM checker, since ~car x~
already implies that ~x~ is a list.

However:

#+BEGIN_SRC elisp
(when (null x)
    (max x)
#+END_SRC

Here, ~max x~ implies that ~x~ is a number.  This is compatible with ~null x~,
since ~null~ can take anything as argument.  But this will obviously fail at
runtime, since ~(max nil)~ is an error and ~x~ must be ~nil~, since the
predicate ~(null x)~ returned true.

One way to type that is to add temporary constraints on branches: here ~(null
x)~ adds the constraint ~x = nil~ to the branch, and ~x != nil~ to the
alternative (but ~when~ has no alternative).

It could potentially catch impossible branches:

#+BEGIN_SRC elisp
(when (and (null x) (not (null x)))
  (print "Not gonna happen"))
#+END_SRC

Because the ~and~ would result in an unsatisfiable set of constraints.

*** Type constraints as return types
Now, we could hardcode type constraints on built-in predicates, like ~null~,
~stringp~, etc.  But what if we want to define a custom predicate?

#+BEGIN_SRC elisp
(defun p (x)
  (and (or (markerp x) (numberp x)))

(when (p x)
  (+ x x))
#+END_SRC

In this case, it's obvious that after ~(p x)~, ~x~ is either a number or marker,
and the addition can only succeed.

But for the type system to know that, the predicate ~p~ should propagate the
constraints from the built-in ~markerp~ and ~numberp~ to its return type.

*** Union types
Another difference from HM is that functions arguments can be unions of types
rather than a single type.  ~max~ accepts numbers and markers, at the same time:

: (max 0 (make-marker))

So the correct type signature would be:

: max :: {number, marker} -> {number, marker} -> {number, marker}

Where {number, marker} is an union of the two types ~number~ and ~marker~.

Whereas, in a HM-style system, you would have to use an explicit distinct union:

: max :: Either(Number, Marker) -> Either(Number, Marker) -> Either(Number, Marker)

On the signature, it does not make much of a difference, but in the code, you
would now have to use an Either constructor.

And of course, that gets quickly tiring when you want to construct arbitrary unions.

*** Variable arity
But in fact, ~max~ can take a variable number of arguments: at least one, but up
to n.  This could be written as:

: max :: {number, marker} -> {number, marker}... -> {number, marker}

The dots indicate that this type is the ~&rest~ where all remainder arguments
go.

*** Modules
The type checker would also need to handle definitions from other files.  The
byte compiler already understands ~require~ calls when compiling.  The type
checker could do the same.

But I don't foresee any complication from loading modules.  It should be
equivalent to having all definitions in the same file.

* [2017-12-05 mar.]
** Using Docker for testing Flycheck                        :flycheck:docker:
Seeing as it was relatively painless to use Docker to run Gitit, I wonder if
that would help us get our integration tests running without too much hassle.

Trying to set up a simple image from debian:latest... apt-get update seems to
take forever.

Looks related to [[https://bugs.launchpad.net/ubuntu/+source/apt/+bug/1332440][this bug]], which talk about MTU... And indeed, it seems the
default network bridge that Docker uses for container have the MTU set to 1500!

To override it,

: systemctl edit docker.service

#+BEGIN_EXAMPLE
[Service]
ExecStart=
ExecStart=/usr/bin/dockerd --mtu 1480 -H fd://
#+END_EXAMPLE

: systemctl restart docker.service

After that, I can toy with a simple Dockerfile:

#+BEGIN_SRC dockerfile
FROM debian:latest

RUN apt-get update
RUN apt-get install -y emacs25-nox

# Install Cask
RUN apt-get install -y curl python
RUN curl -fsSL https://raw.githubusercontent.com/cask/cask/master/go | python
ENV PATH="/root/.cask/bin:${PATH}"

# Install Make
RUN apt-get install make
#+END_SRC

And I'm good to run tests against a /local/ version of Flycheck, with, e.g.:

: docker run --rm -v flycheck:/root/flycheck -w /root/flycheck 3a7cfe4842d7 /bin/bash -c "make init && make integ"

This spins up the image above, with Emacs and Cask installed, and runs ~make
init && make integ~ on the host ~flycheck~ directory (i.e., my local version).

~docker run~ takes only one command... so using bash allows to pass an arbitrary
long list.

So, where to go from there?

I could build a Dockerfile that includes all the checker tools.  From that, I
could build an image that contains everything, and we could presumably run that
in a CI.  It would probably be huge though, on the order of several Gb.

Also, one downside of that, is that the image is... frozen?  So it will contain
the version of checkers at the time it is built.  If we want to test again other
version of checkers, we would need to update the image.

When do we need to run the integration tests?  Presumably, if you are adding a
new checker, you might not even need to run the tests.  If you are modifying a
checker that has tests, then you want to only run the tests for that language or
checker.  If you change Flycheck internals, then maybe a full run is warranted.

Since we are running on Travis, already inside containers, it doesn't seem to
make much sense to launch another Docker instance inside it.

So, maybe we could just tweak the Travis file to also run the integration tests
conditionally, and crucially installing only the required checker tools.

That would keep the CI times reasonably low, and we would actually run the
integration tests.

Now, I know that if I have to modify the Travis file, I will have a very bad day
(or /days/) if I have to wait around for testing each modification on Travis
itself.  But maybe with Docker I can test my changes locally.

I found [[https://docs.travis-ci.com/user/common-build-problems/#Troubleshooting-Locally-in-a-Docker-Image][this]].  It's not I wished for exactly, but it's close.  If I can run the
image Travis uses, then I can at least test commands locally before sending them
to Travis.

For testing the travis.yml directly, I can run [[https://github.com/travis-ci/travis-build][travis-build]] in another
container, and it should output the build script used by Travis.

* [2017-12-26 mar.]
** Improving s3c                                                        :s3c:
Fixed the //: delimiter showing all values of the current iteration on the first
run.

This was due to having no characters after the delimiter, which meant the `from`
and `to` markers were identical, and this ended up inserting the text and never
erasing the rest of the line.

The fix is to use `null` as the character value, which CodeMirror takes to mean
"until the end of the line".

But now, I would still like to have that functionality.  But property this
time, with another delimiter.

Okay, done.  This is nice!  I also added the ability to customize the timeout,
so I can actually run some AdventOfCode solutions to the end now.

Although, since the execution is async, there might not be a point to having a
timeout anyway.

I also added visual feedback for when an evalution is running, since with if the
timeout is large, it can be jarring to not see anything going.

Run into a bug with uglify-js@3.3.2, the latest version.  Somehow, mangling or
compression produced invalid code...  Reverted to 3.2, and it worked fine.

Hmm, trying to have a distinct syntactic highlighting for delimiters while I'm
at it.  I'm doing exactly like [[https://codemirror.net/addon/search/search.js][here]] and it seems I'm not advancing the stream.

Ah, wait, I wasn't doing /exactly/ like in the search addon.  My regexp was
lacking the 'g' flag.  So presumably, it was not restarting after one match, and
we where always skipping to the end?

Anyway, it works now.  Found some nice colors to play with.  Nice progress
today.

* [2017-12-27 mer.]
** Adding Typescript support                                            :s3c:
I think I want to use s3c for my updated JS course.  If I want to use
Typescript, s3c better support it.

On the syntax highlighting front, it seems the latest versions of CodeMirror
include TS support in the JS mode.

On the evaluation front, I think I just need to run the code through the TS
compiler first.  But the tricky part might be to not lose any evaluation
markers...

Okay, so including [[https://github.com/Microsoft/TypeScript/blob/master/lib/typescriptServices.js][this file]] and calling ts.transpile on code generates plain
JS.  Indeed, I run into issues with markers, because the positions in the
compiled JS code do not match the position of the source.

But ~transpile~ also does not produce any compilation error, which is quite
useless.  I need to run the compiler to report errors /and/ keep track of
markers position after the compilation.

Looking into the typescript-services file, I found:

: createTypeChecker
: emitFile seem to be able to get diagnostics
: createProgram as well (that's what the playground seems to be doing)
: transpileModule calls createProgram
: transpile calls transpileModule

I managed to get diagnostics from transpileModule, but only for syntax errors,
not type errors.  Going through the debugger in the playground, and it seems it
doesn't spout out type errors that way either.  But they do appear; probably
because the playground uses some code from VS Code, notably the typescript mode.

But this code is minified.  Can't seem to find where this happens.  Probably
_doValidate, but the Firefox debugger seem to choke.

* [2017-12-31 dim.]
** Fixing a Flycheck rust bug                           :flycheck:rust:cargo:
[[https://github.com/flycheck/flycheck/issues/1378][Namely]].

Somehow, nightly cargo changed the ~file_name~ part of span.  They seem to be
relative to where the Cargo.toml is.

- Test whether this is relative to the manifest, or the CWD of cargo
- Fix the rust integration tests that are broken because of the ~group~ property
- Fix the bug, make sure it works with stable and nightly

*** Fixing the Flycheck rust integration tests
All the rust tests currently fail because of the added ~group~ property.  This
is the relevant code:

#+BEGIN_SRC elisp
  (let ((expected (mapcar (apply-partially #'apply #'flycheck-error-new-at)
                          errors)))
    (should (equal expected flycheck-current-errors))
#+END_SRC

We create error objects from lists by applying the arguments to the constructor,
then we just call ~equal~ to check if the created errors are the same as the
current errors.

This fails because we don't provide a value for the ~group~ property, so it
stays ~nil~, and is then compared to the non-nil value produced by the
rust-cargo/rust checkers.

Trouble is, the group property produced by the checkers is a ~make-symbol~, so
we can't easily get that value back to make it equal in the tests.  I mean,
that's part of the point.

So, either we create an interned symbol for the group property in a predictible
fashion amenable to tests.  Or, we must define an equality predicate that
doesn't take the group property into account...

In the second case, we might still want a way to test if errors belong to the
same group.

One way to do that would be to modify ~-should-syntax-check~ to accept group of
errors and call the verification on that.

But since we don't actually do anything in Flycheck with error groups, it's okay
if we don't test them for now.

Tried to use the following function:

#+BEGIN_SRC elisp
(defun flycheck-ert-error-equal (err1 err2)
  (seq-every-p (lambda (slot)
                 (should
                  (equal (cl-struct-slot-value 'flycheck-error slot err1)
                         (cl-struct-slot-value 'flycheck-error slot err2))))
               (seq-difference (mapcar #'car
                                       (cl-struct-slot-info 'flycheck-error))
                               '(cl-tag-slot group))))
#+END_SRC

But it makes the ert errors basically unusable, since ERT provides no useful
info without an accompanying error explainer.  There is one for ~equal~, of
course.

So, maybe I should just fix the somewhat serious bug first, and come back to
this later.

*** Fixing the bug with relative paths
The fix to set the working directory seems to work for nightly and stable.

Testing it out, it looks like stable cargo returns filepaths relative to the
CWD, whereas nightly cargo returns filepaths relative to the manifest.  So the
fix is sound, and backwards-compatible.

* [2018-01-12 ven.]
** Fixing an s3c crash with Chromium                           :s3c:chromium:
Students ran into reproducible crashes under Chromium.  Firefox handles the same
snippets fine.

Trouble: s3c never actually saves the content of the editor in case of a crash.

Seems to be occurring when a timeout happens?

Reduced the snippet to:

#+BEGIN_SRC js
function f() {
  let n = [];
  while (true) {
    n.push(undefined);
  }
}

f()
#+END_SRC

100% guaranteed crash under Chromium 63.0.3239.132.

Interestingly, this doesn't crash:

#+BEGIN_SRC js
function f() {
  let n = [];
  while (true) {
    n.push();
  }
}

f()
#+END_SRC

I'm not even trying to print the result or anything.

Trying to print the heap size using ~window.performance.memory~: it doesn't look
like it's a memory issue.  Even though we are building a large array.  At least,
~window.performance.memory~ is not reporting anything close to the max heap
size.

I guess that leaves me with the option of saving before calling ~reval~, to
avoid losing work.

* [2018-01-22 lun.]
** Running a specific test for Orgzly                 :android:gradle:orgzly:
Been trying to add plain timestamps to Orgzly.  Wrapping my head around Android
development and patterns.

I think the Provider class in the project is responsible for interacting with
the DB, and specifically expose info from it thanks to queries.  I found a test
class ProviderTest, but it's not picked up by ~gradlew test~.  I guess it's run
by the connected tests, which I can run on the emulator.  But there are 650
such tests, and they are taking a loooong time (i.e., more than ten minutes).

[[https://stackoverflow.com/a/35585778][Found]] a way to run a specific test.  This is convoluted, but it works:

: ./gradlew connectedPremiumDebugAndroidTest -Pandroid.testInstrumentationRunnerArguments.class='com.orgzly.android.provider.ProviderTest'

Also, [[http://books.goalkicker.com/AndroidBook/][this book]] on Android programming created from the defunct StackOverflow
Documentation project is helpful.  But maybe not as helpful as [[https://developer.android.com/reference/android/database/MergeCursor.html][the official
documentation]].

* [2018-01-30 mar.]
** Progress for adding plain timestamps on Orgzly      :android:orgzly:
Now that I've added the DbNoteContentTime table, I want these notes to appear
the Agenda view!  I figured that AgendaFragment is built from the following
query:

: ProviderContract.Notes.ContentUri.notesSearchQueried

If the query contains an ~ad~ keyword, then the AgendaFragment is used.  That's
in DisplayManager:

#+BEGIN_SRC java
// Display agenda or query fragment
if (query.getOptions().getAgendaDays() > 0) {
    fragment = AgendaFragment.getInstance(queryString);
    tag = AgendaFragment.FRAGMENT_TAG;

} else {
    fragment = SearchFragment.getInstance(queryString);
    tag = SearchFragment.FRAGMENT_TAG;
}
#+END_SRC

Then, AgendaFragment runs the query on the DB through NotesClient.  That's from
QueryFragment.onCreateLoader:

: return NotesClient.getLoaderForQuery(getActivity(), mQuery);

That method uses the following URI:

: ProviderContract.Notes.ContentUri.notesSearchQueried(query),

which calls ~Provider.runUserQuery~, which adds a WHERE clause:

: if (query.getOptions().getAgendaDays() > 0) {
:     selections.add(DatabaseUtils.WHERE_NOTES_WITH_TIMES);
: }

and ultimately runs the query on DbNoteView:

: return db.query(DbNoteView.VIEW_NAME, null, selection, selectionArgs, null, null, sortOrder);

The resulting cursor is then passed to AgendaFragment.onLoadFinished, and used
to build the list displayed to the user.

So, I managed to extend WHERE_NOTES_WITH_TIMES to include notes which have
content times as well.  I tested that by calling notesSearchQueried directly,
and it returns the correct note.

However, the cursor does not include the content times.  That's because the
DbNoteView table doesen't have these columns, and does not join them.  The
author has stated that we should not modify the view itself, because it should
be a one-to-one mapping.

In any case, the code that makes use of the cursor in AgendaFragment has to be
modified, because currently it's only looking for scheduled and deadline times
when computing whether to display.  So maybe we can solve the problem by just
adding logic to AgendaFragment to look into DbNoteContentTime as well for all
notes that are present?

Haha!  It seems to work.  At least, by tinkering a lot, I managed to get notes
with plain timestamps into the list shown by the Agenda query.

However, I seem to get duplicate entries... and the notes are not matching the
timestamps.  Mild victory.

Ah, wait, I left the debug cause that was pulling all notes...  Yeah, that's
better.

It's too bad I'm not seeing the actual times, but I guess that could be
arranged later.

* [2018-02-14 mer.]
** Diagnosing a strange Flycheck macro bug                   :flycheck:elisp:
[[https://github.com/flycheck/flycheck/issues/1398][Namely]].

Using a ~define-checker~:

#+BEGIN_SRC elisp
(progn
  (with-eval-after-load 'flycheck
    (flycheck-define-checker foo
      ""
      :command ("foo")
      :error-patterns ((error line-start))
      :error-filter (lambda (errors))
      :modes c++-mode))

  (package-initialize)
  (add-to-list 'load-path "~/proj/flycheck")
  (require 'flycheck))
#+END_SRC

This fails when loading flycheck with:

: (error ":error-filter (function (lambda (errors))) of syntax checker foo is not a function")

The :error-filter property is indeed turned into this:

: (function (lambda (errors)))

However, when evaluating the expression directly, it raises no errors.

If I macroexpand the definition, I get this for :error-filter:

: :error-filter #'(lambda (errors))

which should be the same as ~function~, as I understand it.  If replace the #'
by ~function~, it works fine when evaluating the expansion.

Actually, evaluating this in ~emacs -Q~:

#+BEGIN_SRC elisp
(progn
  (package-initialize)
  (add-to-list 'load-path "~/proj/flycheck")
  (require 'flycheck)

  (flycheck-define-checker foo
    ""
    :command ("foo")
    :error-patterns ((error line-start))
    :error-filter (lambda (errors))
    :modes c++-mode))
#+END_SRC

also triggers the error.  But only the first time it is evaluated!

When stepping the definition through the debugger, I'm seeing that
~define-command-checker~ is getting ~(function (function (lambda errors)))~ at
some point.  Though that doesn't seem to be an issue, as it reduces to
~(function (lambda errors))~.

However, stepping through, I can see that:

: (functionp (function (lambda (errors))))

returns ~nil~!  Even though, when evaluating the expression, it returns ~t~.

Can reproduce with this small standalone snippet:

#+BEGIN_SRC elisp
(progn
  (defun gen-check (&rest props)
    (unless (functionp (plist-get props :filter))
      (error "%s is not a function" (plist-get props :filter))))

  (defun com-check (&rest props)
    (apply #'gen-check props))

  (defmacro check (&rest props)
    (let ((filter (plist-get props :filter)))
      `(com-check ,@(when filter `(:filter #',filter)))))

  (check :filter (lambda (errors))))
#+END_SRC

First time you evaluate it, it errors, but the second time it doesn't.

Reducing it further:

#+BEGIN_SRC elisp
(progn
  (defmacro m (f)
    `(functionp #',f))

  (m (lambda ())))
#+END_SRC

Ultimately, it comes to that.  If you evaluate this snippet once, it returns
~nil~ the first time, and ~t~ the second time henceforth.

If you remove the #', then all evaluations return ~t~.

Removing the #' in Flycheck works... but not quite, because we now have macro
calls which need to add the #' back.  Once that is done, then the original macro
call in ~with-eval-after-load~ works as expected.

Tricky!

* [2018-02-18 dim.]
** Comparing interpreter/VM and JIT                                  :jit:vm:
On a simple language of arithmetic expressions.  Triggered by [[https://xavierleroy.org/mpri/2-4/machines.pdf][this course]] that
states that we should usually get the following ratios:

: interp: 25
: vm    :  5
: jit   :  1

Here are the results I got on a reasonably long expression.  Without
optimizations:

: test bench_interp ... bench:       8,448 ns/iter (+/- 102)
: test bench_vm     ... bench:      64,889 ns/iter (+/- 5,917)
: test bench_jit    ... bench:         410 ns/iter (+/- 12)

With optimizations:

: test bench_interp ... bench:       4,030 ns/iter (+/- 138)
: test bench_vm     ... bench:       4,165 ns/iter (+/- 104)
: test bench_jit    ... bench:         362 ns/iter (+/- 3)

Ratios for the optimized version are:

: interp: 11
: vm    : 12
: jit   :  1

I was surprised by the VM trash performance compared to the interpreter,
especially without optimizations.  At first I was worried the compiler would
take my expression and unroll the interpreter code for that specific program.

I added a parser to construct the expression program from a string, and the
ratios are the same.

So, at best, it seems the VM is still less performant than the interpreter.

The JIT does not benefit much from optimizations, which is to be expected.  If
we actually optimized the generated machine code, it would just output a
constant.

It would be interesting to see how these numbers compare for a more complex
language.

After watching [[https://youtu.be/knqlWboqf_U][this video]] on partial evaluation, I wanted to include that in the
comparison.  However, I'm not sure that I will see the same improvements.
Returning a closure will indeed skip the overhead of decoding and reordering,
but I don't know how much the compiler can specialize from all these nested
closures.

I added partial evaluation, and also added benches from a term that's directly
in the source.

Results without optimizations:

: test bench_interp              ... bench:       8,515 ns/iter (+/- 116)
: test bench_interp_static       ... bench:       8,547 ns/iter (+/- 37)
: test bench_jit                 ... bench:         409 ns/iter (+/- 4)
: test bench_jit_static          ... bench:         412 ns/iter (+/- 6)
: test bench_partial_eval        ... bench:       5,644 ns/iter (+/- 49)
: test bench_partial_eval_static ... bench:       5,683 ns/iter (+/- 86)
: test bench_vm                  ... bench:      64,943 ns/iter (+/- 467)
: test bench_vm_static           ... bench:      64,974 ns/iter (+/- 451)

With optimizations:

: test bench_interp              ... bench:       3,582 ns/iter (+/- 106)
: test bench_interp_static       ... bench:       3,556 ns/iter (+/- 155)
: test bench_jit                 ... bench:         369 ns/iter (+/- 16)
: test bench_jit_static          ... bench:         360 ns/iter (+/- 8)
: test bench_partial_eval        ... bench:       4,042 ns/iter (+/- 50)
: test bench_partial_eval_static ... bench:       4,022 ns/iter (+/- 35)
: test bench_vm                  ... bench:       4,191 ns/iter (+/- 34)
: test bench_vm_static           ... bench:       4,242 ns/iter (+/- 68)

So: without optimizations, the partial evaluator is faster than the
interpreter.  With optimizations, the compiler does a better job on the
interpreter than on the closure returned by the partial evaluator.

But the JIT is still one order of magnitude faster, and that's by generating
straightforward machine code.  No optimizations in there.

* [2018-03-05 lun.]
** Testing an hypothesis on shared books                                :sim:
Someone put up a shelf at the school where people are supposed to leave books
for others to take.  It has been a while now, and I can see that some books
leave, while some stay.  It got me thinking: will this shelf, in the long run,
contain only books that no-one want?  Or, at the least, will the quality of
books decline and plateau?  Or does the quality of books it contains fluctuate
over time?

If we model books as positive integers, the shelf and people can both be seen as
a lists of numbers (books).  A person taking a book from the shared shelf is
then equivalent to moving a number from one list to another.  Furthermore, we
can assign a quality as a real number from 0 to 1 to each book.  Over time, if
people randomly exchange books with the shared shelf, then, what happens?

There are quite a few variables involved:

- The number of books.  In real life this is not constant, but increasing.
- The number of people.  Same as above.
- The probability of taking a book from the self.
- The probability of leaving a book on the self.
- The distribution of book qualities

The probabilities of taking or leaving a book can be unique to each (person,
book) couple, modeling individual preferences.

* [2018-05-04 ven.]
** Github added HTTPS for custom domains                         :github:dns:
[[https://blog.github.com/2018-05-01-github-pages-custom-domains-https/][At last!]]

I've simply updated my A records to point to their new IP addresses.  Now I get
HTTPS and CDN.  No need for Netlify.

I've also added a 301 redirection from www.0xc0de.fr, since using the CNAME
record breaks SSL.

And since you can enforce redirection to HTTPS, I don't even need to update all
my URLs!

* [2018-05-07 lun.]
** Running Flycheck integration tests with Docker           :flycheck:docker:
*** The plan
So, I've been working on running these damn integration tests on our CI once and
for all.

My first attempt with a Vagrantfile only allowed us to run the whole suite on
local machines, not on Travis.

My second attempt, a few weeks ago, was to create an ~install-deps.sh~ script
that essentially does what the provision script of the Vagrantfile did.  The
idea would be to use this script on Travis to install all tools, and to use it
to provision the VM locally.

It's not working as well as I hoped.  Travis has an old 14.04 Ubuntu image, and
I guess they will stick to it at least until expiration (at least 19.04).  So,
if I install GHC from that, I get an old version.  If I want a newer one, I must
ditch the package manager.  If I do that for each tool... the provision script
becomes a nightmare to maintain.

Ideally, I want to run with /the same tools/ on Travis and locally.  Or at
least, get a way of reproducing the Travis build locally without too much
hassle.

Travis does not allow us to run VMs using Vagrant.  However, it does let us run
Docker images.

If I create a Docker image containing all the tools, then, in theory, Travis
should be able to pull it and run the integration tests from there.  Then,
anyone can do the same thing locally.

The upshot is: less mucking with Travis, since the whole CI build would be
reproducible locally in Docker.  And, of course, integration tests on CI.

I'm afraid that some tools will still be hassle to install on Docker.  However,
having /some/ integration tests not running on CI is better than /most of them/
not running.

Now, as I understand it, Docker images are immutable.  That means that once
built, anyone pulling the image would have the exact same versions of the tools.
[[*Using%20Docker%20for%20testing%20Flycheck][Initially]], it bugged me.  Having to rebuild the Docker image to update all the
tools seemed like a hassle.

However, I think it can be a benefit.  Immutable images means that the only
thing that changes between CI runs is /flycheck/.  If the CI breaks, then it's
assuredly because of changes in our code.  Fewer false positives (Travis may
still have some hiccups though).

Then, I /think/ we can run a cron job on Travis to build the image, say, daily
or weekly.  In that job, we would /also/ run the test suite, and push the new
versions if everything is green.  If there is a failure, then /we know/ it's
because of new versions of tools (or Emacs snapshot), and not because of changes
in Flycheck.

So, the immutability of Docker images will help us seggregate our CI failures.

In order to do all that, I should:

1. Check that Travis can run our Docker image
2. Check that Travis can /build/ our Docker image and push it to hub
3. Check that Docker can build an image with all our tools

From what I understand of these technologies, the above should be feasible.

The largest unknown is that I need to run the CI on different Emacs versions.  I
think it means having as many Docker images as there are Emacs versions, as
[[https://hub.docker.com/r/silex/emacs/][here]].  Hopefully, there's a way to do that without heavy duplication between
Dockerfiles.

*** The execution
[[https://github.com/Silex/docker-emacs][These images]] look like good starts.  They are based on 16.04; I would have
preferred latest Debian.  We will quickly see if that's an issue.

So, after a few hours of tweaking... it seems the experiment is a success!

Travis can build and run the image just as well as I can locally.  There is no
difference between the two environments.  Exact same results for ~make integ~.

Since pushing a Docker registry is documented in Travis, I suppose that should
mostly be a matter of creating an account and following the doc.

The Docker image with around half the tools is 4GB.  Much smaller than the
20GB VirtualBox VM I had previously.  Startup is quite faster as well, once the
image is built.

Concerning the multiple Emacs versions, one solution is to have multiple
Dockerfiles, with one tag per Emacs version (as done in the base
silex/docker-emacs images).  Of course, only the base tag would change, so we
can use ~cat~ or something to generate the actual Dockerfiles.

Then build and push that to the hub in a cron job.

There's still work ahead, but so far this solution ticks all the boxes.  The
only downside so far is having to use 16.04 as base.  But, I'm getting the
impression that for tools where the latest versions is most commonly used,
only a rolling release will do.  Even the latest Debian will contain outdated
Rust and Go versions soon enough.

But basing the whole thing on Arch would require compiling Coq from
scratch... not a fan.  Verilator didn't work as well.

We'll see how difficult it is to get all the tools in the Dockerfile.

One thing I've noticed is that there are Docker images for many larger tools
already.  Unfortunately, I cannot include or merge them in mine.  However, I can
easily lift their instructions for my build.  That saves some time figuring
these out.

* [2018-05-08 mar.]
** Fixing Flycheck integration tests                               :flycheck:
For the longest time, the JS tests have been annoying me by outputting empty
lines.  I finally pinpointed the culprit: empty ~(message nil)~ calls, which in
interactive mode will clear the echo area, but in batch will add a newline.

One solution is to set inhibit-message to t.

Using python-flake8 from APT works, but it the version looks a tad out of date.

Using it from pip is better.  However, pylint has some additional errors that
are truncated by ERT...

#+BEGIN_SRC elisp
(list-elt 10
  (array-elt 4
    (different-atoms ... ...)))
#+END_SRC

Seriously, how is this useful for debugging?

Found the culprit, in ert-run-tests-batch:

#+BEGIN_SRC elisp
(let ((print-escape-newlines t)
      (print-level 10)
      (print-length 30))
  (ert--pp-with-indentation-and-newline
   (ert-test-result-with-condition-condition result)))
#+END_SRC

This is not even configurable.  You leave me no choice:

#+BEGIN_SRC elisp
(advice-add 'ert--pp-with-indentation-and-newline :around
            (lambda (orig &rest args)
              (let ((print-length nil)
                    (print-level nil))
                (apply orig args))))
#+END_SRC

In the long run, we may want to customize that runner with a nicer
pretty-printer and color.

But at least, now it doesn't get in the way of fixing bugs.

Argh, spent 10 minutes trying to figure out why the markdown tests where
suddenly failing with no errors, although they were running fine just a moment
before.

I added proselint to the Docker image, and proselint has priority in
markdown-mode if installed.

So two things: first, maybe our tests should make sure that the checker being
tested is actually the one being run.  Second: proselint should come after
markdownlint.

* [2018-05-09 mer.]
** Getting most tools in the Dockerfile                            :flycheck:
So, yesterday I was at:

: Ran 171 tests, 129 results as expected, 42 skipped

I think I can get that last number down a little.  There are easy picks, and
then there are largely-used checkers that we need to run tests for.

Obscure checkers that I can't install will have to wait.

Hmm, erlang-rebar3 is behaving mysteriously.  First, checks fail with a very
strange error name.  Adding debugging statement in Flycheck makes these error
names disappear.

Then it nearly passes all the tests, it just fails on projects due to the errors
from other files showing up.  I add these in the expected errors, and now it
crashes on all tests...

Off you go.

** Multi-stage builds are a game-changing                            :docker:
[[https://docs.docker.com/develop/develop-images/multistage-build/][Multi-stage builds]] allows one to pull from an image, do whatever you want (e.g.,
compile these pesky Haskell linters using their own GHC version), then create a
new container one another image and pull what you want from the first container.

The second container only contains what has been copied, and not all that has
been installed in the first one.  The first one is completely discarded.

I see at least two ways of exploiting this.  First, it means that I don't need
to base my Dockerfile containing the tools on the emacs image.  I can base it on
debian/ubuntu/arch, and install all the tools.  That's it, that's the
flycheck-tools image.

Then, to run the tests, I build images based on flycheck-tools that extract the
Emacs installation from the different emacs images by copying /usr/local.
That's flycheck-tools-emacs25, flycheck-tools-emacs26, etc.

Although, I'm doubtful that I can be based on ubuntu 18.04 and just use an Emacs
compiled for 16.04.  If the dependencies are not the same, it will likely
break.  I can easily test it however.

So yes it breaks if I just copy the Emacs binary.  However, I can add a ~FROM
silex/emacs:25~ at the end (which comes will all the Emacs dependencies) and do
the reverse: copy the tools, with their eventual runtime dependencies.

If anything breaks, I can use ubuntu:16.04 as the starting image for building
the tools.  Problem solved.

The second thing I can use multi-stage builds for is to build the final image
without pip, unzip, gem, etc.  I only need whatever is needed to /run/ the
tools, and not build them or compile them.  Moreover, it means I don't need to
be scared of installing multiple GHC versions via stack just for building
linters.  It will certainly take more time to build the image, but the
flycheck-tools image is built only once for several Emacs versions, and not for
each integration test run.

But wait, there is more!  With multi-stage, I can pick /tools/ from existing
Docker images.  That means I don't even have to waste time build them on the CI,
and write the commands that do.  Just COPY --from=hadolint.

Okay, so after many hours, I'm still not done, but progressing.

I've opted to ditch the silex:emacs images, as 1) they are built on an old ubuntu,
2) I need to build Emacs after my flycheck-tools image anyway, and 3) I want a
lean Emacs binary with few runtime dependencies.

Compiling Emacs is not much more complex than other tools... so it's not a
hassle.  For bonus points, I can create a lean-emacs image, from which I can
then pull in a flycheck-integ-test image, which builds on the flycheck-tools
one.

That way, I never need to update the emacs images of stable releases, just the
snapshot.

* [2018-05-10 jeu.]
** Running integration tests on several Emacs with Docker   :docker:flycheck:
It works!

And I didn't even have to generate one Dockerfile per Emacs version using
templates.  Docker supports variables, on top of environment variables from sh.

There is /one/ downside: older Emacs versions, like 24.5 and 25.1 segfault when
dumping Emacs.  I've tried with CANNOT_DUMP=yes, and Emacs fails to build.

There is a workaround though: we can install emacs24-nox, as it's still in the
Ubuntu repositories.  It would just slightly complicate the script.

Maybe building them on Travis will have different results... one can hope.

* [2018-05-11 ven.]
** Building Emacs 24.5 with Docker                    :docker:emacs:flycheck:
So, building them on Travis makes no change.  Somehow, I prefer that, because it
means using Docker means builds do /behave/ the same on different machines.

But!  24.5 and 24.4 succeed with ubuntu 16:04.  And they can be run under 18:04
without troubles apparently.  So, I can do that.

* [2018-05-15 mar.]
** Sound troubles                             :arch:pulseaudio:alsa:timidity:
So, I plugged speakers into the jack in the back of my PC.  They work fine under
Windows.  Under Arch... no sound.  Using DeadBeef, I was able to play some sound
directly using the ALSA device, but not using PulseAudio.

Sound under Linux is very confusing, with ALSA being both a kernel thing and a
userland tool, and PulseAudio being "on top of ALSA" but somehow also showing in
~aplay~, ...  Anyway.  After some annoying tracking down and debugging, where
disabling the HDMI sound card did nothing, turns out the culprit was timidity!
Installing that steals ALSA, and pulseaudio cannot use it.

The fix is described [[https://wiki.archlinux.org/index.php/Timidity#Daemon][here]].  Now both work.

* [2018-06-04 lun.]
** Rationale for writing a book on emulation                 :emulators:book:
The missing text on how to write an emulator.

I have seen many people asking for help on how to write an emulator.

The topic is enticing.  They want to, partly driven by nostalgia (for older
systems) or bravado (for the latest ones), partly by the technical challenge.
There is something magical when finally seeing a game load for the first time,
after having working on your own emulator for weeks or even months.

But they don't know where to start.

They ask many questions: which platform to emulate?  What programming language
to use?  What to start emulating, the CPU, the graphics?  Which ROM is the best
to start with?  Can you test each part independently?  How do you know if the
emulator is /truely correct/?  How do you know which parts of ROM are code, and
which are data?

Now, most of the time, people give CHIP8 as answer to the first question.  There
are tons of tutorials on CHIP8.  The spec is tiny; few instructions,
straightforward to implement.  Still a full machine.  You get all the thrills of
writing an emulator with fewer headaches.

But the other questions have no definite answers.  Well, in truth because there
are no definite answers.  But newbies /need/ definite answers in order to
progress.  They need solid ground to build upon.  Then, later, when they
eventually realize that actually it wasn't all that clear-cut and you could have
done otherwise; it's okay.

So a book providing clear guidelines to follow would be a boon to them.  "I want
to write an emulator!  -> Follow this book, then come back when you've finished
it".  The book makes decisions for you, guides you through writing your first
emulator, and teaches you what you need to emulate other systems.

Now, I do not know everything about emulation.  I've written or helped on a few
emulators: CHIP8, GB, NES, MD.  All 2D systems from the 8bit to 16bit era.  My
emulators are not the most accurate, nor the most performant, nor the
better-tested; my code is not the most modular, nor the most readable, nor the
best enginereed.  But I've seen enough to guide someone through writing their
first couple of emulators.

This book is not for everyone.  People who have a background in electrical
engineering, or in low-level embedded programming, have, I think, fewer
difficulties jumping into emulator development.  They will grok the technical
documentation easily, without needing an introduction to how CPU pipelines work,
or how chips communicate using data lines on a global clock.

Not having an EE background, I spent a lot of time reading the technical
documentation for early consoles, wrapping my head around how clocks and cycles
interacted, around the jargon of "level-triggered signals".

There's reading and understanding the technical documentation, and then there's
implementing it in code.

Knowing what an opcode does or where a data line goes won't immediately give you
clues as how best to implement them.  There are straightforward ways, then there
are sophisticated ways.

One tricky, and crucial thing, is timing.  If you don't know how to time the
overall emulator (emulating all components), you might get no results at all.
No video or audio feedback.  If, on the other hand, you learn to think correctly
about timing from the start, you will save you many hours of debugging
headaches.

Talking about audio.  This is one of the less documented area.  In fact, I'm
sure many people leave audio out of their first emulator because they have no
clue about how to implement it.  For video in 2D systems, everyone knows it's a
2D array of pixels.  You give each pixel a color, you refresh the display 60Hz
and that's it.  Unlike video, audio has no a universal mental model.

Most people will know sound is made of waves, but that gives them no clue on how
to emulate the audio chip of a GB.  So having a book that touches every area of
the system is great.

Now, the system to pick is interesting.  Starting with CHIP8 is a now brainer.
It's small, but real.  It has many pedagogical virtues.  Unfortunately, it is
too small to understand how to deal with larger real systems like the GB, the
NES or the MD.  The CHIP8 CPU has few opcodes, so there's no need for templates
or macros or code generation.  The CHIP8 audio is a single beep, so no
opportunity to talk about oscillators, envelopes, LFSR noise, and mixing
multiple voices.

And of course, real systems are problematic to use in a book due the dubious
legality of talking about them in technical details.  Patents have expired, but
copyright hasn't.

Ideally, we want a stepping stone.  A system that has the characteristics of
real 2D consoles from the 8bit era, without the legal hazard.

I could design a fantasy system, strongly inspired by the consoles of the 8bit
era.  It would have a CPU with 256 opcodes, a sprites- and tiles-based video
system, an audio system with pulse channels and even synth channels.

It would have no irregularities, no weird bugs or corner cases, no legal hazard.
However, it wouldn't be a real system.  People often want to write a GB or NES
emulator, not to emulate a fantasy system they have never heard of.  And more
importantly, a fantasy system would have /no games written for it/.

Testing different games and making sure the emulator runs more and more of them
is an interesting aspect of emulator development.  This fantasy system would
have none of that.  Unless of course I, or other people, also write a game
catalogue for it.  But this is probably out of my time budget for this project.

And it's harder to convince people to read and use the book if what they really
want is a guide for writing a /GB/ emulator specifically.

* [2018-06-05 mar.]
** In search of legal systems to emulate                    :emulators:boook:
So, [[https://www.nintendo.com/corp/legal.jsp][Nintendo's position on emulation]] is rather straightforward:

#+BEGIN_QUOTE
How Does Nintendo Feel About the Emergence of Video Game Emulators?

The introduction of emulators created to play illegally copied Nintendo software
represents the greatest threat to date to the intellectual property rights of
video game developers. As is the case with any business or industry, when its
products become available for free, the revenue stream supporting that industry
is threatened. Such emulators have the potential to significantly damage a
worldwide entertainment software industry which generates over $15 billion
annually, and tens of thousands of jobs.

What Does Nintendo Think of the Argument that Emulators are Actually Good for
Nintendo Because it Promotes the Nintendo Brand to PC Users and Leads to More
Sales?

Distribution of an emulator developed to play illegally copied Nintendo software
hurts Nintendo's goodwill, the millions of dollars invested in research &
development and marketing by Nintendo and its licensees. Substantial damages are
caused to Nintendo and its licensees. It is irrelevant whether or not someone
profits from the distribution of an emulator. The emulator promotes the play of
illegal ROMs , NOT authentic games. Thus, not only does it not lead to more
sales, it has the opposite effect and purpose.

How Come Nintendo Does Not Take Steps Towards Legitimizing Nintendo Emulators?

Emulators developed to play illegally copied Nintendo software promote
piracy. That's like asking why doesn't Nintendo legitimize piracy. It doesn't
make any business sense. It's that simple and not open to debate.
#+END_QUOTE

Needless to say, I'm not writing a book on how to build emulators for Nintendo
consoles in this climate.


[[https://www.pcgamer.com/the-ethics-of-emulation-how-creators-the-community-and-the-law-view-console-emulators/][This article]] seems to resume the current status of the legality of writing
emulators.  Basically: reverse engineering is protected under fair use.  So, if
you can prove all your code was obtained by reverse engineering the hardware,
you are fine.  As of now.  Under US copyright law.

If you have looked at the code of other emulators... then you better show that
to the best of your knowledge, this code was obtained purely by
reverse-engineering.  That's more tricky of course, since emulators are seldom
written in a vacuum.

If you have looked at official code that is running on the console, and directly
copied that, then that's clear-cut copyright violation.

So, what about going off documentation?

The article states that writing code from official copyrighted documentation is
illegal.  Dolphin emulator writers have a policy of not using anything which
looks remotely close to being obtained through illegal channels.  Better safe
than sorry I guess.

But this does not seem to follow from copyright law as described.  US copyright
law clearly states (as reminded in the article) that procedures and processes are
not copyrightable.  Only their expression is protected.

#+BEGIN_QUOTE
in no case does copyright protection for an original work of authorship extend
to any idea, procedure, process, system, method of operation, concept,
principle, or discovery, regardless of the form in which it is described,
explained, illustrated, or embodied in such work."
#+END_QUOTE

So, if you read a document that describes how VRAM is initialized in a certain
system that's clearly a process.  When you translate that into code, there are
many equivalent ways to do the initalization.  Maybe one of them will look like
the expression of the process in the document.  But others may be completely
different.  It might be hard to convince a judge of this distinction, but at
least you have a solution in this case.

I guess also that verbatim copying of any large part of protected documentation
is a bad idea.

On the other hand, with a document that was written after reverse-engineering
the system you should be clear.  Well, of course, that document is also
protected by copyright, and its owners can sue you.  To my knowledge, not many
documents describing the workings of the GB/NES/MD have a permissive license.
The authors freely shared them, and compiled from other such document, because
that is part of the culture.  Explicit waiving of copyright was probably seen as
unnecessary.  But such is the world we live in.

[[https://www.afjv.com/news/5894_technique-et-legalite-des-emulateurs-de-jeux-video.htm][This article]] on French copyright and emulation is rather bleak.  French
copyright law has the same exception on reverse engineering, but only if you are
a "legitimate user of the system", and the reverse engineering was done "for
interoperability purposes".  Intellectual curiosity does not seem to be in
scope.

The [[https://www.legifrance.gouv.fr/affichCodeArticle.do;jsessionid=51628CBF73CDA8A9F7F54DFE28625FE5.tplgfr40s_2?cidTexte=LEGITEXT000006069414&idArticle=LEGIARTI000006278919&dateTexte=20180605&categorieLien=cid#LEGIARTI000006278919][L122-6 article]] itself is preposterous.  The way I read it, and unless
there's an exception somewhere, all reproductions of a software falls under
copyright.  Downloading, loading in memory and execution are /explicitely/
mentioned.  So, without a proper license grant from the owner, even downloading
some binary is illegal.  Same for the source code.

Ah but it seems there's indeed an exception when the acts (of downloading,
executing, etc.) are made for the purpose of using the software:

#+BEGIN_QUOTE
Les actes prévus aux 1° et 2° de l'article L. 122-6 ne sont pas soumis à
l'autorisation de l'auteur lorsqu'ils sont nécessaires pour permettre
l'utilisation du logiciel, conformément à sa destination, par la personne ayant
le droit de l'utiliser, y compris pour corriger des erreurs.
#+END_QUOTE

That's [[https://www.legifrance.gouv.fr/affichCodeArticle.do;jsessionid=51628CBF73CDA8A9F7F54DFE28625FE5.tplgfr40s_2?cidTexte=LEGITEXT000006069414&idArticle=LEGIARTI000028345224&dateTexte=20180605&categorieLien=cid#LEGIARTI000028345224][L122-6-1]].

And oh well that's interesting:

#+BEGIN_QUOTE
La personne ayant le droit d'utiliser le logiciel peut sans l'autorisation de
l'auteur observer, étudier ou tester le fonctionnement ou la sécurité de ce
logiciel afin de déterminer les idées et principes qui sont à la base de
n'importe quel élément du logiciel lorsqu'elle effectue toute opération de
chargement, d'affichage, d'exécution, de transmission ou de stockage du logiciel
qu'elle est en droit d'effectuer.
#+END_QUOTE

That seems to allow reverse engineering with the only constraint being that you
are... allowed to do it?  Presumably, it's okay unless you have agreed to a EULA
that forbids it.

Not sure how EULAs apply to second-hand hardware.  If I get my NES from the flea
market, there are no EULAs.  Plug, put cartridge, play.  So according to that,
I'm free to take it apart and reverse engineer how everything works down to the
atom, without asking anyone's permission.

But!  There's more:

#+BEGIN_QUOTE
La reproduction du code du logiciel ou la traduction de la forme de ce code
n'est pas soumise à l'autorisation de l'auteur lorsque la reproduction ou la
traduction au sens du 1° ou du 2° de l'article L. 122-6 est indispensable pour
obtenir les informations nécessaires à l'interopérabilité d'un logiciel créé de
façon indépendante avec d'autres logiciels, sous réserve que soient réunies les
conditions suivantes :

[very narrow set of restrictions follow]
#+END_QUOTE

That's what the article above was referring to.  But I do not agree this applies
to reverse engineering.  It clearly states that it applies to /the reproduction
or translation of the code/.  I.e., exact reproduction of the object code or
direct translations of it in other languages is illegal, but reverse engineering
is the behavior without lifting the code is.

Since reverse engineering is legal, documents created from reverse engineering
surely are not tainted.  Copyright does apply to /their/ verbatim reproduction,
but, again, I can't see how taking the info and processes from documentation and
expressing them in code can be considered copyright infringement.  At very best,
it falls under patent law, but patents before 1998 have all expired.

So, I understand that looking at official documentation is frowned upon, but my
interpretation is that unless parts of the code can be shown to be exactly as
expressed in the documentation, it does not fall under copyright.  It may fall
under patent law, but for older systems, that is not an issue.

Also, intention matters.  Commercial distribution of a competing product would
be judged quite differently than pedagogical material.

** Related work                                              :emulators:book:
While looking for the legality status of emulation, I found [[https://jeux.developpez.com/tutoriels/programmer-emulateur-console/][a very thorough
tutorial on writing a CHIP8 emulator]].  In French, curiously.

Also the [[https://github.com/chip16/chip16][CHIP16 specification]] could be a good fit for a first system.  The audio
is ADSR, closer to what the GB has, but without the quirks.  Since it's a
community project, there are already several games that have been written for
it.  And no legal hazard, although the specification has no explicitly license,
but it's not a behemoth with an army of lawyers.

* [2018-06-07 jeu.]
** Adding an UI to the GYM player                             :gym:emulation:
I wanted to toy with FFT to make a visualizer for each channel of audio for the
GYM player.

Spent a lot of time setting up imGui with SDL, but got it working.

Unfortunately, the way I'm generating the audio to play is not adequate to
visualization.  I'm emulating the GYM data as fast as possible, and queuing the
audio samples to SDL.

When the emulation is done, I just wait with usleep(100) until the queue is
empty.  Since I've added an UI, I'm doing all that work in a separate thread.

But this is not very useful for debugging.  For instance, I can lift code from
megado to show the PSG registers.  The UI refreshes at 60Hz, but the emulating
45sec of audio is done in 5sec.  Looking at the registers this is not very
telling.

And, since I'm queuing audio to SDL, there is no way to get the audio back.

I could modify the playing function to generate enough samples for 16ms, and
show the state of that, more or less like it is done in megado.  But it would
make timing the audio trickier than before.

I found another, arguably better use of imGui for the YM2612 and PSG: a sound
generator!  I can make buttons send commands to the sound chip registers, and
expirement with them.

This requires continuously emulating the sound chips, but at least I'll know
from the start this time.

* [2018-06-20 mer.]
** Looking into the lsp-java situation                     :lsp:java:eclipse:
Can I ditch Eclipse for editing and browsing Java code?

I'm fairly sure that even the LSP won't contain everything that Eclipse is able
to do, so I think the best solution for me would to have an Emacs plugin that is
able to talk to a running GUI Eclipse which I can use as a fallback when things
go south.

If I can do most of my editing and browsing in Emacs, than that's already a
win.  I'll probably have to use Eclipse for debugging and so on, but that's
okay.  As long as I don't have to suffer the inferior editing and terrible
window management of Eclipse...

*** lsp-java
First contender.  Setup is easy enough.  Navigation with
~lsp-goto-type-definition~ doesn't seem to work, but ~xref-find-definitions~
does.

Navigation breaks when trying to jump to things that are not in the types which
are not in the current project however.

lsp-ui is a mess, putting overlays all over the place, and even in other
buffers...

The project does not build correctly (probably that jdt-lsp thing is not able to
build Eclipse plugins?).

Browsing javadoc on types and methods is barebones.

At this point, I feel the LSP is just slightly better than GNU Global, because
the latter is not able to make the difference between a variable and a method of
the same name (which is to say, it isn't better than grep).

The situation is dire.

* [2018-06-21 jeu.]
** Working on YM2612 toy and envelope                         :ym2612:megado:
Well, adding the YM2612 registers to the sound toy was easy.  I got a nice kick
out of it.

But then I found out that the envelope was still not properly emulated... which
greatly limits the possibilities!

So I tried to remedy that.  But then I remember why it's such a pain in the
neck: the information is scattered /everywhere/.  There is no single document
gathering the workings of the YM2612 internals.  The best place to look is in
other emu source code, which kind of defeat the purpose.  And it's full of weird
corner cases and bugs, like sometimes there's a cut-off value at 62 and nobody
knows why, but that's the behavior of the chip.  And I don't even know if
whether the corner case has a noticeable impact on the sound or not.

What's fun is when you take the documentation and try to implement based on
that.  So, I have an idea of how to implement an ADSR envelope based on the
counters that you can specify in the YM2612.  But then the doc never mentions
precise timing for how fast the attack phase should increment the sound.  So I
tweak constants until I find something that approximates what it should sound
like.  This I can do.

* [2018-06-28 jeu.]
** Generating the Z80 code                                       :z80:megado:
After much wrangling with strings, I managed to generate all ADD and LD
instructions rather simply with:

#+BEGIN_SRC rust
&ADD => {
  fname = "z80_op_add_{dst}_{src}";
  body = "{src};\n  {dst} += src;"
}

&LD => {
  fname = "z80_op_ld_{dst}_{src}";
  body = "{src};\n  {dst} = src;";
}
#+END_SRC

Of course ADD still needs to handle flags, but that's a start.  Now the Z80
registers are actually moving!

DST and SRC are fragments of C code that do the right thing, depending on the
addressing mode used by the opcode.

My aim here was to be as DRY as possible.  Alas, this approach is not flexible
enough.  The PUSH opcodes already make his awkward:

#+BEGIN_SRC rust
      &PUSH => {
        src = &o.dst;
        dst = &o.src;
        fname = "z80_op_push_{src}";
        body = r#"{src};
  z->ram[z->sp-2] = src & 0x00FF;
  z->ram[z->sp-1] = src >> 8;
  z->sp -= 2;"#;
      }
#+END_SRC

Here I have to swap SRC and DST because PUSH only has one argument, and only the
SRC can used to get a value.

And then there's ~JP cc, nn~.  This one has two arguments alright, but the first
one is a condition, so it's a value to be read, and ~nn~ is /also/ a value to be
read.  So you cannot use DST here, you really want two SRC.

And of course, there's also ~JP nn~, where the first argument is a read.

So, ultimately, the opcode are the ones who determine how the opcode arguments
should be treated: read from, written to, tested against a value...

I think I can salvage this approach by adding new template words beside SRC and
DST, like CC for condition.

* [2018-07-23 lun.]
** Reviewing PR 1308 (hopefully for good)                          :flycheck:
https://github.com/flycheck/flycheck/pull/1308

It starts with a simple feature request: allow Flycheck to run automatically
whenever the user switches to a buffer (after some delay) in flycheck-mode.

The motivation behind the feature is that editing another buffer might affect
the results of check in other buffers (think project-wide checks).

Unfortunately, there were unforeseen complications due to:

1. Detecting a buffer switch was not straightforward.  Emacs provides
   ~buffer-list-update-hook~, but there are surprising corner cases where
   ~current-buffer~ is wrong when that hook is called.
2. An "idle buffer switch" timer had to work with the "idle change" one.  If you
   just switched, but start editing right away, the check should be delayed.
3. The exact behavior of the feature was underspecified.  The user can switch to
   multiple buffers before the delay is up: should all intermediate buffers be
   checked, or only the final one?

Handling all these cases complexifies the code, which makes reviewing the PR
harder.

So let's try to untangle it.  What the PR should do:

1. Whenever the user switches to a flycheck-mode buffer, that buffer should run
   a check after a customizable delay.
2. That behavior only happens when "buffer-switch" is in
   ~flycheck-check-syntax-automatically~.
3. If the user starts typing in the buffer right after switching to a buffer,
   the check should be rescheduled (since the check results would be obsolete).
4. If the user was typing (hence scheduling a check) in a buffer, and the user
   switches to another buffer and back, the check should *not* be rescheduled.

   (In practice, it may be simpler to always reschedule checks, and it is also
   always correct.)

5. If the user rapidly switches to multiple flycheck-mode buffers, checks should
   be scheduled for all buffers.  This behavior can be toggled off, in which
   case only the final flycheck-mode buffer will run a check.

The following table describes the interactions between idle-change and
idle-buffer-switch.  In all cases, the point is that *only one check* should
run.

|                                   | idle-change    | idle-buffer-switch | both             |
|-----------------------------------+----------------+--------------------+------------------|
| Switch to flycheck buffer         | -              | schedule check     | schedule check   |
| Switch, then type                 | schedule check | schedule check     | reschedule check |
| Type, then switch away            | schedule check | -                  | schedule check   |
| Type, switch away and back        | schedule check | schedule check     | reschedule check |
| Type, switch away, back, and away | schedule check | schedule check*    | reschedule check |
| Rapidly switch multiple times     | -              | schedule checks*   | schedule checks* |

(*) Only if flycheck-check-intermediate-buffers is non-nil.

- Schedule check :: create a timer that will call flycheck-buffer-automatically
     after a customizable delay.
- Reschedule check :: cancel any pending check timer and create another one
     using the customizable delay for the latest trigger.

Another table for the interactions between mode-enabled and idle-buffer-switch.
Again, only one check should run:

|                          | mode-enabled | idle-buffer-switch | both        |
|--------------------------+--------------+--------------------+-------------|
| Open new flycheck buffer | defer check  | schedule check     | defer check |
| Enable flycheck-mode     | defer check  | -                  | defer check |

- Defer check :: force a deferred check (which will be called on
     post-command-hook).

So basically, idle-buffer-switch should have no effect on toggling the minor
mode (since whether a check happens at that time is already governed by
mode-enabled).

Path to review:

1. [X] Check that the PR does all the above interactively.

   Observed behavior:

   | Requirement | Correct                            |
   |-------------+------------------------------------|
   |           1 | yes                                |
   |           2 | yes                                |
   |           3 | yes                                |
   |           4 | not rescheduled, but check happens |
   |           5 | yes                                |

   |                                   | idle-change | idle-buffer-switch  | both                |
   |-----------------------------------+-------------+---------------------+---------------------|
   | Switch to flycheck buffer         | -           | 1 check             | 1 check             |
   | Switch, then type                 | 1 check     | 1 check             | 1 check             |
   | Type, then switch away            | 1 check     | -                   | 1 check             |
   | Type, switch away and back        | 1 check     | 1 check             | 1 check             |
   | Type, switch away, back, and away | 1 check     | 1 check             | 1 check             |
   | Rapidly switch multiple times     | -           | all buffers checked | all buffers checked |

   |                          | mode-enabled | idle-buffer-switch | both       |
   |--------------------------+--------------+--------------------+------------|
   | Open new flycheck buffer | 1 check      | -                  | *2 checks* |
   | Enable flycheck-mode     | 1 check      | -                  | 1 check    |

   Conclusion: one redundant check when opening a new flycheck buffer, otherwise
   it's fine.

2. [X] Write tests to ensure it does it in the future as well.

   Couldn't reproduce the failure with idle-buffer-switch and mode-enabled with
   tests, since it seems to be triggered by global-flycheck-mode.

   But the tests cover most of the functionality.

3. [ ] Check the implementation is correct.
4. [ ] Check if the code can be simplified.
5. [ ] Check documentation (docstrings and manual)

* [2018-08-02 jeu.]
** Sketching out a PuzzleScript for abstract strategy games        :abstraga:
[[https://www.puzzlescript.net/][PuzzleScript]] is a fantastic idea.  And the related [[http://tinyworld.spacebar.org/][T in Y World]] is even better,
because rules are part of the field, and thus can be mutated (metaprogramming!).

The core idea to both is to describe the game rules by pattern matching and
replacement.

But pattern matching on a grid needs to look in all four cardinal directions.
They share the same clever solution to describe on one line patterns in
arbitrary directions:

: A>B>X

will match ABX, but not A nor XBA
                        B
                        X

: AvBvX

will match A but not ABX
           B
           X

: AvB>C^D

match AD
      BC

: A)B)X

will match ABX   XBA   A
                       B
                       X

I wonder if the same idea can work for specifying abstract strategy games.  In
some ways they are simpler than puzzle games, in other ways they are more
difficult.

Example games: Aballone, Reversi, Go, Chess, Tak, Quoridor...

Characteristics of abstract strategy games:

- Turn-based
- Fixed play area (grid, square or eventually hex)
- Pieces can be put down, captured, moved, stacked, flipped
- There may be a set number of pieces
- Captured pieces may be played again
- Win condition can be elimination, territory scoring, reaching a position
- Multiplayer

Multiplayer can be tricky to specify.  Roles are usually symmetric (black and
white), but they don't have to be.  Players can pass.  Must decide who starts,
when a turn is over.  What actions can be taken in a turn.

Some games have difficult rules.  The Ko rule of Go requires modeling more than
one time step (and in fact, keeping the whole history).  Scoring in Go has
multiple definitions.

Chess is full of idiosyncracies.  Knight move, prise en passant, roque!

*** Reversi

- A valid move is one where at least one piece is flipped.
- Players alternate by putting a piece or passing.
- The games end after neither player can move.
- After putting a piece (P), flip all the pieces of the opposite color in a
  straight line between P and another piece of the same color.  Straight lines
  include horizontals, verticals and diagonals.

W = White
B = Black

: ?W)B).)B)W=W)W).)W)W

The above rule has two problems (assuming ')' includes diagonals):

- The repetition of flipping is not obvious.  If '.' means "match anything",
  in the output the '.' would be the same as in the input.

  So instead you want to propagate the flip.

- When is it applied?  For Reversi, the rules clearly state that you only flip
  lines that start or end with the active piece.  They should /not/ flip after
  that.

I managed to get something going in PuzzleScript:

#+BEGIN_SRC puzzlescript
title Reversi

========
OBJECTS
========

Background
GREEN

White
WHITE

Wt
WHITE

BLACK
BLACK

Bt
BLACK

player1
RED

player2
BLUE

=======
LEGEND
=======

W = White
B = Black
. = Background
@ = player1
Player = player1 or player2

=======
SOUNDS
=======

================
COLLISIONLAYERS
================

Background
White, Black, Wt, Bt
Player

======
RULES
======

[ action player1 | ] -> [ Wt | player2 ]
[ action player2 | ] -> [ Bt | player1 ]
[ Wt | B | ... | W ] -> [ W | Wt | ... | W ]
[ W | Wt | W ] -> [ W | W | W ]
[ Bt | W | ... | B ] -> [ B | Bt | ... | B ]
[ B | Bt | B ] -> [ B | B | B ]

==============
WINCONDITIONS
==============


=======
LEVELS
=======

........
........
...@....
...WB...
...BW...
........
........
........
#+END_SRC

The 'action' rules let player put a piece down where they are, and switch to the
other player.

The 'Wt' is a white token.  The token is used to make sure only the active piece
starts a flip chain, not just any white piece.

The flip chain is defined like so:

: [ Wt | B | ... | W ] -> [ W | Wt | ... | W ]
: [ W | Wt | W ] -> [ W | W | W ]

The pattern is pretty clear: a token, a black piece, anything in between
(including nothing), and a white piece.  Then the black piece is turned into the
token.  In PuzzleScript, the rule is applied as long as the left-hand part
matches.

So in essence we have a recursive definition that flips one piece at a time.
And the second rule is the base case, which gets rid of the token.

This works, but it's not Reversi yet:

- It doesn't match for diagonals.  Horizontal and vertical lines in any
  direction are flipped, but not diagonals (because PuzzleScript doesn't look
  for them).

- You can put a piece anywhere, not just in valid position.  This requires
  additional work, and I haven't found how to check the tile below the player.

  The rules above assume the move is valid, otherwise bad things will happen.

- There is a bug!  When propagating the token, we do it one cell at a time, but
  we do not make sure to /stick to the initial direction/.  That is, the token
  will flip white pieces in any direction adjacent to it, but not necessarily in
  a straight line.

To wit, in this configuration:

#+BEGIN_EXAMPLE
..@
WBB
.BW
.W.
#+END_EXAMPLE

If I put a white piece down where the player ('@') is, all black pieces are
turned white.  Here is replacement step by step ('t' for the white token):

#+BEGIN_EXAMPLE
..t
WBB
.BW
.W.

..W
WBt
.BW
.W.

..W
WtW
.BW
.W.

..W
WWW
.tW
.W.

..W
WWW
.WW
.W.
#+END_EXAMPLE

As long as there is a white piece in a straight line from the token, it
keeps flipping them.

I think the solution is to fix the flipping direction of the token after the
first match.  That means we have to create separate tokens and separate rules
for each direction, which is already more verbose.

E.g.:

: down [ Wt | B | ... | W ] -> [ Wd | B | ... | W ]
: down [ Wd | B | ... | W ] -> [ W | Wd | ... | W ]
: [ W | AnyW | W ] -> [ W | W | W ]

The first rule now only matches in the down direction, and we transform the
token to a 'white down token'.  After that, we have the same recursive
definition as before, but now it only matches in the down direction.

For the base case, the direction does not matther, so we can use just one.

Too bad however that we have to write down all the rules for all the directions.

* [2018-08-06 lun.]
** More PuzzleScript Reversi                          :abstraga:puzzlescript:
On the way home, it hit me that I could use the 'horizontal' and 'vertical'
keywords to cut down on the verbosity of the previous solution.

So now I have:

#+BEGIN_SRC puzzlescript
[ action player1 | ] -> [ Wt | player2 ]
[ action player2 | ] -> [ Bt | player1 ]

horizontal [ Wt | B | ... | W ] -> [ W | Wh | ... | W ]
horizontal [ Wh | B ] -> [ W | Wh ]
vertical [ Wt | B | ... | W ] -> [ W | Wv | ... | W ]
vertical [ Wv | B ] -> [ W | Wv ]
[ W | AnyWt | W ] -> [ W | W | W ]

horizontal [ Bt | W | ... | B ] -> [ B | Bh | ... | B ]
horizontal [ Bh | W ] -> [ B | Bh ]
vertical [ Bt | W | ... | B ] -> [ B | Bv | ... | B ]
vertical [ Bv | W ] -> [ B | Bv ]
[ B | AnyBt | B ] -> [ B | B | B ]
#+END_SRC

Wt is the white token that is put down.  If it's next to a black piece in a
horizontal line ending with a white piece, we propagate the token.  But this
time, we put down a white /horizontal/ token.  That one can only propagate
horizontally due to the rule:

: horizontal [ Wh | B ] -> [ W | Wh ]

(Bonus simplification: we don't actually need to check that we are going toward
a white piece, since the horizontal token would not be there if we weren't)

We can do the same for vertical, and for black pieces.

More verbose, but it fixes the previous solution's defect.  To wit:

#+BEGIN_EXAMPLE
..@
WBB
.BW
.W.

..t
WBB
.BW
.W.

..W
WBv
.BW
.W.

..W
WBW
.BW
.W.
#+END_EXAMPLE

However, it's not correct yet.  There is another bug:

#+BEGIN_EXAMPLE
@BW
B..
W..

WhW
B..
W..

WWW
B..
W..
#+END_EXAMPLE

One token can only propagate in one line!  We should propagate to /all lines/
that end with a white piece instead.

Luckily, it's a simple fix.  The trick is to not discard the white token until
there are lines that can be flipped.  That is:

#+BEGIN_SRC puzzlescript
horizontal [ Wt | B | ... | W ] -> [ Wt | Wh | ... | W ]
horizontal [ Wh | B ] -> [ W | Wh ]
vertical [ Wt | B | ... | W ] -> [ Wt | Wv | ... | W ]
vertical [ Wv | B ] -> [ W | Wv ]
[ AnyWt | W ] -> [ W | W ]
#+END_SRC

If we keep the token, we make sure it is still around for the vertical rule to
match.  So:

#+BEGIN_EXAMPLE
tBW
B..
W..

thW
B..
W..

thW
B..
W..

thW
v..
W..

tWW
v..
W..

WWW
v..
W..

WWW
W..
W..
#+END_EXAMPLE

The fact that a rule is executed as long as the left-hand part matches is used
for all rules: when we have two horizontal lines, the first rule places two
horizontal tokens; when we several black pieces in a row, the second rule
applies to propagate that token; finally, all temporary tokens are turned
into white pieces by repeated application of the AnyWt rule:

#+BEGIN_EXAMPLE
WB@BW

WBtBW

WhtBW    ; Wt | B -> Wt | Wh

WhthW    ; idem

WWthW    ; AnyWt -> W

WWWhW

WWWWW
#+END_EXAMPLE

In fact, we can simplify the clearing up rule even further:

: [ AnyWt ] -> [ W ]

Since we know by construction that any leftover white token is in fact just a
white piece, once the rules propagating the tokens have executed, we can turn
all tokens into white pieces, regardless if they are next to white piece.

So what's missing?  Diagonals would make a playable Reversi, but one where you
only play valid moves.  I feel that defining validity in the rules is
primordial: the rules describe what can happen sure, but they also state what
/cannot/ happen.  As it stands, I can play wherever I want, but it's not
Reversi.

Diagonals would be trivial to do if PuzzleScript had a dedicated keyword (maybe
one keyword for both directions: bottom-left to top-down and top-left to
bottom-right).  I think we can keep using the token idea to get to diagonals in
two steps:

#+BEGIN_EXAMPLE
..W
.B.
t..

..W
aB.
t..

..W
.d.
t..

.aW
.d.
t..

.aW
.W.
t..

..W
.W.
t..
#+END_EXAMPLE

Push a token in one direction, say up.   That token looks for a black piece to
its right.  Keep doing the same.

It might work on an empty board, but I think we'll run into issues with a full
board, since it looks like we can only have one piece per cell?  It wouldn't
prevent us from using the technique, it would just be super tedious since we
would have to create one temporary token for each type of token that can appear
below it, and have rules do the proper replacement.  Anyway, let's try it.

#+BEGIN_EXAMPLE
t..
.B.
..B

t..
aB.
..B

t..
ad.
..B

t..
.d.
..B

ta.
.W.
.aB

t..
.W.
.ad

t..
.W.
.ad

t..
.W.
..d

t..
.Wa
..W

t..
.W.
..W
#+END_EXAMPLE

Ahah!  I've got propagation on diagonals working with:

#+BEGIN_SRC puzzlescript
vertical   [ Wt | . ] -> [ Wt | Wa ]
horizontal [ Wa | B ] -> [ Wa | Wd ]
+          [ Wa ]     -> [ Background ]
+up        [ Wd | . ] -> [ Wd | Wa ]
+down      [ Wd | . ] -> [ W  | Wa ]
#+END_SRC

(Could be made simpler, but I tried to follow the logic of the orthogonal rules,
where multiple diagonals can match).

So first rule is just: step above and below of Wt.  The exploratory token 'a',
if next horizontally to a black piece, turns the B in a white diagonal token.
After that, we discard all exploratory tokens.  Then, we do the same thing with
Wd instead of Wt, and we do that until the group matches.

I've had to split the Wd rules into up and down, since I needed to expire the Wd
token after both directions were explored.  E.g.:

: vertical [ Wd | . ] -> [ W | Wa ]

will produce just one Wa token before expiring Wd.  Instead, if we write:

: vertical [ Wd | . ] -> [ Wd | Wa ]

Then we explore both directions, but we still have a Wd token that we need to
expire (otherwise we will explore its neighbouring cells again, which is
useless, and might regress infinitely).  We could add a rule that discards the
Wd token, like we did for Wa.

I believe that's a valid use case for grouping rules, since we want to loop
here.

But!  It's not enough for Reversi.  It flips white pieces in diagonals,
/regardless/ if there is a white piece at the end of the diagonal.  Using the
same method, we would in fact have to do two propagations: one would explore all
diagonals until the end, and if they encounter a white piece, then they back
propagate and do the flipping.  Like so:

(flattening the diagonal on a line because it's easier to see):

#+BEGIN_EXAMPLE
tBBBW

taBBw

taaBw

taaaW

taaWW

taWWW

tWWWW
#+END_EXAMPLE

In fact, we could do the same thing for horizontal and vertical lines.  Step one
cell at a time, until you hit a white piece, and propagate back if you do,
flipping all the black pieces.  Or leave the pieces black if you don't find a
white piece.

We don't /have to/ do it that way for horizontal and vertical lines, because
PuzzleScript allows us to match a whole line.  But for diagonals, we have to do
it one (half-) step at a time.

So I'm pretty sure it's doable, but very tedious.  I feel like I'm in a
Zachtronics game: dealing with very low-level, fine-grained contraptions to
achieve even the most trivial effect.

The point was to find a system for expressing game rules, and for Reversi I'm
already specifying /how/ to apply the rules very finely (with cell-to-cell
propagation).

Maybe we would get more mileage out of PuzzleScript if we could define and reuse
abstractions, so we could express rules at a higher level, but still have the
ability to express very low-level mechanisms if we needed to.

I want to think about restricting moves to valid ones first.  But in essence, in
order to know if the move is valid, we have to know if we would end up flipping
something.  So we have to do a flip check!

* [2018-08-07 mar.]
** Reversi in ideal PuzzleScript                                   :abstraga:
Doing a flip check is in fact more complex than what I used previously for
starting a flip.  The left-hand part:

: horizontal [ Wt | B | ... | W ]

matches tBBBW, but also matches tB.BW!  The ellipsis matches anything, and we
cannot match for repeated Bs.

So doing something like this:

: horizontal [ action player | B | ... | W ] -> [ Wt | B | ... | W ]

does not suffice for a flip check.

(As an aside, I don't know where to put the player now!  I cannot write ~player
on B~ even though with the previous rule, the player tile was moved
automatically away, without touching whatever was below)

If we were to do it in PuzzleScript, we would have to go tile by tile, until we
eventually a white piece, and then allow the move.  Or we don't hit any, in
which case the move cannot proceed (we don't put down a white token, and none of
the remaining rules apply)

In ideal PuzzleScript, we could write:

: [ action player | B | B... | W ] -> [ Wt | B | B... | W ]

This would match any valid move, in any direction.  There is at least one black
piece next to the piece played.

Now since the move is valid, the propagation setup can be simplified:

: horizontal [ Wt | B ] -> [ Wt | Wh ]
: vertical   [ Wt | B ] -> [ Wt | Wv ]
: diagonal1  [ Wt | B ] -> [ Wt | Wd1 ]
: diagonal2  [ Wt | B ] -> [ Wt | Wd2 ]

This sets up tokens on the black pieces next to the played piece. These will
propagate, but only in the direction specific to the token.

Then we have the actual propagation:

: horizontal [ Wh | B ]  -> [ W | Wh ]
: vertical   [ Wv | B ]  -> [ W | Wv ]
: diagonal1  [ Wd1 | B ] -> [ W | Wd1 ]
: diagonal2  [ Wd2 | B ] -> [ W | Wd2 ]

This flips the pieces one by one, but only in the direction given by the token.
We have to separate the two diagonals, since in a square grid we have four axes.

The propagation phase stops matching because we have reached the white token, so
we can just clean up every temporary token:

: [ Wt or Wh or Wv or Wd1 or Wd2 ] -> [ W ]

And same thing for black.

There is repetition that could be abstracted with macros.  For setup:

: setup(dir) := $dir [ Wt | B ] -> [ Wt | W$dir ]
: setup(horizontal)
: setup(vertical)
: setup(diagonal1)
: setup(diagonal2)

For propagation:

: flip(dir) := $dir [ W$dir | B ] -> [ W | W$dir ]
: flip(horizontal)
: flip(vertical)
: flip(diagonal1)
: flip(diagonal2)

And we could go further by bundling all the valid axes:

: axes := { horizontal, vertical, diagonal1, diagonal2 }
: setup(a) for a in axes
: flip(a) for a in axes

or even

: setup(a); flip(a) for a in axes

But the verbosity is not so bad so we don't need the abstractions.

All that's left is passing, and the winning condition.

If you cannot move, you must pass.  This switches to the next player.  Checking
if there is a valid move is expensive.

With the rules above, we don't need to.  Either we add another action to the
language (another input button), or we add a special "Pass" tile that the player
can move onto.  Doesn't really matter.

: [ action2 player1  ] -> [ player2 ]

: [ action player1 on pass ] -> [ player2 ]

Ending condition is that neither player can move, which again is expensive
(because the board is not necessarily full).  Alternatively, we could say that
both players have to pass.  If the latter, we must keep track of the fact that
the previous player has passed or not.

Trying the former:

: [ Background | B | B... | W ] -> [ P | B | B... | W ]
: [ Background | W | W... | B ] -> [ P | W | W... | B ]
: [ no P ] -> end
: [ P ] -> []

If there is any valid move, we put a token there.  We do that for both players.
If there aren't any valid move, we end the game.  Otherwise, we cleanup these
tokens.

If instead we detect two pass in a row:

: [ action player1 on pass ]  -> [ player2 on pass ]
: [ action player2 on pass ]  -> [ player1 on pass ]
: [ action player1 on pass1 ] -> end
: [ action player2 on pass1 ] -> end

'pass' and 'pass1' are two different tiles.  We convert the first to the second
to keep track of a player passing in the previous round.

The tricky part is to reset that tile when a player actually plays, because the
action happens far from the pass tile.

So instead we have to keep track of that state on the player itself.

: [ action player1 on pass ] -> [ player2pass on pass ]
: [ action player2 on pass ] -> [ player2pass on pass ]
: [ action player1pass on pass ] -> end
: [ action player2pass on pass ] -> end
: [ action (player1 or player1pass) | B | B... | W ] -> [ player1 on Wt | B | B... | W ]
: [ action (player2 or player2pass) | W | W... | B ] -> [ player2 on Bt | W | W... | B ]

Or maybe we can actually match any state like this:

: [ pass1 ] [ action player1 on pass ] -> end
: [ pass ]  [ action player1 on pass ] -> [] [ player2 on pass ]

Which would be more direct.

After the game ends, we need to determine a winner.  PuzzleScript only has a
winning condition section, which does both at the same time, since there's only
one player.

For Reversi, the winner is the player with the highest score.  That is, the highest
number of pieces of his color on the board.

A straightforward solution is to count.  A less straightforward but more adapted
to pattern matching is to remove one black piece and one white piece at the same
time, until only one color remains on the board.  The remaining color wins.
There might be draws.

*** Rules for interaction versus rules for proving stuff
These rules, and a proper PuzzleScript semantics, describe in fine details the
rules of Reversi.  In fact, they do more: they provide an interactive, playable
Reversi inside PuzzleScript.

But I have no guarantee that the rules are, in fact, correct with respect to the
official rules of Reversi.

Having the game rules spelt out mechanically allows us to play the game, good.
But actually we could have played the game much faster by drawing a chess board
and cutting 64 pieces of paper, black on one side, white on the other.

Even for explanatory purposes: it's faster to change the rules and play another
round with humans, than figure out how to express these new rules under whatever
system you have.  Unless your system is so particularly well-suited to your
domain (which PuzzleScript isn't).

Interpreting the rules wasn't difficult.  For most games, the difficulty is in
interpreting the corner cases, where the rules do not go.  For the game
designer, the difficulty is in finding out about these corner cases.

The benefit of having a mechanical implementation of the game rules thus lies in
ensuring that some situations cannot happen.

But if you start with the questions, you might want to use a different
formalism.  A mathematical modelisation for instance could be less verbose and
still let us answer interesting questions.  But the PuzzleScript rules are
constructive and may give us the sequence of moves that lead to a specific board
state (that way, we can for instance know if a board is legal or not).

Let's say we want to know whether the game can get stuck.  That is: reach a
state where there is no valid action for any player, thus preventing the game to
progress and reach the end condition.

Now, Reversi rules simple enough that the answer is obviously no.  Players
always have the ability to pass.  Two passes in a row ends the game.  So you can
always end.

Are there situations where the board is not full, but no valid moves exist?
(Meaning both players have to pass to end the game.)  That's not obvious from
the rules, but the answer is yes.  The best way to prove that is to find such a
case.

The empty board is such a case.  There are no valid moves on it.  However, the
empty board is not a legal position.

Similarly, it's easy to see by playing a bit that when a line of pieces of the
same color touches the edge of the board, the opposite color can never flip it,
so it's never valid to play on the row.

By trying to stick to the edges, it may be possible to derive a stuck case using
only legal moves.  One may be able to answer that question with a mathematical
argument (using symmetry as in the 15 puzzle maybe?), but I feel that it's less
effort to find a counter example.

However, in the event the rules did not allow for a stuck case to occur, proving
that it is indeed the case could be tricky.

With mechanical rules, we might be able to compute all possible states, and
check if we get stuck.  The benefit of this approach is that you get potentially
all sequences of moves that lead to a stuck game.  The downside is that you may
not be able to answer all questions if the game is not amenable to exhaustive
state enumeration.

Can we have draws?  Trivially, yes: player 1 passes, player 2 passes, draw.

Can we have draws where the game ends by the two players passing only because
there are no valid moves left?  I'm tempted to say yes, by symmetry: if player 2
plays the mirror move of player 1, they should end up in a draw.  However, it's
not obvious whether player 2 can always play a move to mirror player 1; the
board may have changed such that the move is not valid.

For instance:

#+BEGIN_EXAMPLE
1         2         3         4         5
........  ........  ........  ........  ........
........  ........  ........  ........  ........
........  ........  ........  ........  ....B...
...BW...  ..WWW...  ..WWW...  ..WWW...  ..WWB...
...WB...  ...WB...  ..BBB...  ..WWB...  ..WWB...
........  ........  ........  ..W.....  ..W.....
........  ........  ........  ........  ........
........  ........  ........  ........  ........
#+END_EXAMPLE

Here after move 4 the board is asymmetric, and if black playing the mirror move
does not restore this symmetry.

But white could have played 4b instead, and symmetry would have been maintained:

#+BEGIN_EXAMPLE
1         2         3         4b         5b
........  ........  ........  ........  ........
........  ........  ........  ........  ........
........  ........  ........  ........  .B......
...BW...  ..WWW...  ..WWW...  ..WWW...  ..BWW...
...WB...  ...WB...  ..BBB...  ..WBB...  ..WBB...
........  ........  ........  .W......  .W......
........  ........  ........  ........  ........
........  ........  ........  ........  ........
#+END_EXAMPLE

Thus, if one can show there is always a valid move that maintains symmetry, then
there can be such draws.  But to me it's not obvious whether this second
property holds.

I would sooner resort to exhaustive enumeration to be sure.

But at least, I think it shows that having mechanical rules can help in
answering questions about the game.  So it's valuable.

If you have the rules in mechanical form, then players can check if their
current board is legal. Then they can check what they can do a in a given
situation (what are the legal moves?).  And they can check what would happen in
some specific situations that the manual does not cover.

This works only if the rules are complete.  How do you ensure they are though?

If you have English rules and mechanical rules, which is the sole source of
truth?  How do you ensure they actually say the same thing?  You don't!

* [2018-08-09 jeu.]
** Simpler rules                                                   :abstraga:
Before going to bed, it hit me than in an ideal PuzzleScript, I could vastly
simplify the rules, and instead of this:

#+BEGIN_SRC puzzlescript
# Valid move
[ action player | B | B... | W ] -> [ Wt | B | B... | W ]

# Setup
horizontal [ Wt | B ] -> [ Wt | Wh ]
vertical   [ Wt | B ] -> [ Wt | Wv ]
diagonal1  [ Wt | B ] -> [ Wt | Wd1 ]
diagonal2  [ Wt | B ] -> [ Wt | Wd2 ]

# Propagate
horizontal [ Wh | B ]  -> [ W | Wh ]
vertical   [ Wv | B ]  -> [ W | Wv ]
diagonal1  [ Wd1 | B ] -> [ W | Wd1 ]
diagonal2  [ Wd2 | B ] -> [ W | Wd2 ]

# Cleanup
[ Wt or Wh or Wv or Wd1 or Wd2 ] -> [ W ]
#+END_SRC

write:

#+BEGIN_SRC puzzlescript
[ action player | B | B... | W ] -> [ Wt | B | B... | W ]
[ Wt | B | B... | W ] -> [ Wt | W | W... | W ]
[ Wt ] -> [ W ]
#+END_SRC

The first rule makes sure we have a valid move, and the second flips whole lines
in any direction as long as it matches.  The third cleans up the token.

That's rather terse, and requires only two small extensions to PuzzleScript.

* [2018-09-06 jeu.]
** Screenshot to clipboard                                            :arch:

: import png:- | xclip -selection clipboard -t image/png

This allows me to paste the image directly in, e.g., Impress.  For fast editing
of a slideshow.

* [2018-10-05 ven.]
** Checking out the competition                                    :flycheck:
*** Sublime Text
Opens fast.

Zooming fully in incurs slow down.  But arguably that extreme zoom level is not
useful.

Opening a Rust project: syntax highlighting works.  Code folding for most
construct, except ~struct~.

There's a command to build with cargo, similar to compile-mode.  Except there's
no parsing of the compile output for errors.

No inline errors out of the box.

Auto-completion that uses words in the buffer.

No goto definition/reference out of the box for Rust.

Ctrl+P is pretty fast, but similar to ivy/helm.  Except it shows off by opening
the currently selected file as you type.

Goto-definition/reference works for structs and functions in C, but not for
struct members or local variables.

Installing a package is seemless.  I installed rust-enhanced, and now got Goto
definition working without having to reload the buffer.  It has false positives
though (and won't jump to anything from std).

Saving the file now gives me inline errors.  Except inline errors are all
visible at once, which can be spammy.

**** Overall impression
+ Fast
+ Decent out-of-the-box experience for common languages
+ Useful tools (find/replace, macros)
+ Friction-less installation of extensions with decent defaults

- No built-in code intelligence
- Proprietary

I looked at the [[https://www.sublimetext.com/docs/3/api_reference.html][plugin API]] and at some [[https://github.com/bradrobertson/sublime-packages/blob/master/Default/][example plugins]].  The upside is that it's
just Python, so it's easy to use.  Doesn't look as powerful as elisp, or as
well-documented.  The API is not too small, but rather 'focused' on the
essentials: buffers, regions, editing events...

'Focused' is apt to describe Sublime as well.  It provides a slim but decent
editing experience (multi-region, macros) and even customizability.  All in a
modern package (phantoms can include HTML/CSS, not weighted down by having to be
compatible with terminal emulators).

What we can we learn?  I wish Emacs was as snappy, and that we had more liberty
with the display.  But this is not new.

One thing I noticed in the Transpose command is the overloading: if the cursor
is between characters, it transposes letters, but if it is at the end of word,
it transposes words.  And if multiple selectors are enabled, it transposes
between these cursors.  Same command, different effects depending on the
context, like 'dwim' commands.  Efficient use of keybindings.

Also, the command palette is overloaded: you can use it to run commands, but
also jump to files, or to symbols.  Again, saves you from memorizing multiple
shortcuts.

*** VS Code
There is a Welcome tab, and an Outline view.  I'm getting an Eclipse vibe.  With
the minimap it looks like Eclipse and Sublime had a child.

No goto definition out of the box for Rust.  I can install extensions, but there
are several so I need to go on the web to find out which is better.

Same auto-completion as Sublime (word-based).  Built-in folding.

Goto def for C not built-in.

It's pretty, with shadows and animations.  There are icons for everything.

Not as fast as Sublime.  Opening folders has a noticeable delay.

Trying a JS project like boyo.

Goto definition works, and correctly disambiguates between homonyms.  There's
even type inference.  Not perfect though, but probably better for TypeScript.

Documentation on hover.  I can also trigger it on a key, but I have to press Esc
to do anything?

There's this weird restriction where if you open a folder, you are closing the
previous one.  So you can't jump to another project unless you open two VS code
instances?

Sublime had the same behavior, but at least by default it doesn't close the
previous "folder".

Using RLS works.  It's not much faster than calling cargo check on save though.

**** Overall impressions
+ Good discoverability
+ Quite good out-of-the-box JS experience
+ Integrated debugger
+ Open source

- A bit sluggish
- Mouse-focused
- Basic editing facilities (multi-cursor but no macros?)

It might be prettier than Sublime, but it does less without extensions.  All
bells and whistles.

Again, the ability to have arbitrary HTML/CSS for dialogs lets you mix fonts in
a way that's not possible to replicate in Emacs without dropping terminal
support.

Looking at [[https://github.com/editor-rs/vscode-rust/blob/master/src/components/cargo/CargoManager.ts][plugins like this]], I'm in awe of peope willing to put up having to
write that code.  100 points for elisp here.
*** Summary
Both Code and Sublime share a good subset of features: syntax highlighting,
auto-completion, goto definition/find references, multi-cursor editing, folding,
file tree, version control and of course the signature minimap.

As if all of these were 'must-have'.  I don't see the point of folding.  But
Emacs has narrowing that supersedes folding, and you can open multiple windows
on the same buffers to look at whatever you want.

A file tree is useless for opening files: a fuzzy file search is faster 99% of
the time.  However, the tree can be convenient for lightweight file operations.

I've nevre found a use for multi-cursor editing, but maybe it's a cause of not
knowing what I'm missing out.

Auto-completion is quite useful.  And Emacs supports it out of the box.  Of
course, what Sublime and Code both do better is /discoverability/.  With a
window showing you the completion, so you /know/ that it is there and you can
use it.  Emacs completion mechanism is hidden behind a shortcut, so you might
completely never find out it exists!

Version control integration is useful.  Magit is king, of course.  But it should
even go further than that.  When opening a project, I want Github integration:
handling pull requests and issues directly in Emacs, because Github has a slow
interface and it requires a context switch.

Looking at these editors, it has given me a couple of ideas for what to improve
in my Emacs config.  I have no desire at all to switch, but I understand why
people who try Emacs, Sublime and Code will bounce off Emacs pretty hard.  Emacs
looks dated and feature-poor.  Looking through the menus, you might discover
some weird stuff, like the games, but no syntax highlighting for PHP.

For most advanced configuration, you need to go through either the weird
customize interface, or have to write Elisp.

Once you get past these hurdles, it's the most powerful editor out there.  But
it means we are losing many potential users.

* [2018-10-14 dim.]
** Making firp deployable                                       :firp:django:
After a fresh clone, using a virtualenv and

: pip install -r requirements.txt

Then,

: python manage.py runserver

fails with:

: FileNotFoundError: [Errno 2] No such file or directory: 'secret_key'

We need to put default values in the repo, and add a local settings file.

No we are missing the 'captcha' module.  Actually we were importing two captcha
libraries, so probably the first one is useless.

Now the app is complaining we have unapplied migrations.

: python manage.py migrate

After that, going to the index page fails because the DB is empty.  The fix is
to correctly make all migrations before hand, then apply them.

* [2018-12-11 mar.]
** Revamping my JS course                                       :teaching:js:
The big things happening in JS right now are:

- TypeScript + VS Code, which greatly improves the /tooling/ around JS.
  Types, auto-completion, debugging...

  Does not change anything about the /runtime/ though.

- React (and React-inspired frameworks).  'Solve' the MVC problem by letting the
  dev write the presentation declaratively, and not care (too much) about the
  details of updating parts of the view.

  That one is really more related to web programming though.

- Async/await to simply asynchronous calls.

  This I can use.  It gives me an opportunity to talk about the execution model
  (single-threaded, but with the ability to write asynchronous code).

  Asynchronous code is relevant: its the foundation of nodejs, but it's also
  very important in web apps.  An AJAX call is asynchronous; any event handling
  in the browser in asynchronous.

  Promises and async/await were added to deal with asynchronous code.  At its
  heart the model is simple.

*** Using s3c for promises                                              :s3c:
Didn't work.  It's because I was killing the worker right after evaluating the
code, and not waiting for the event loop to be empty.

I don't think there is (or at least didn't find) a way to figure whether the
event loop is empty.

But not killing the worker works, and using the timeout mechanism already in s3c
is enough.

Took me way to long to find the cause though, because I forgot to ~make~ the s3c
bundle when testing...

*** Notes about promises                                           :promises:
[[https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Using_promises][This guide for now]].  Interesting tidbits:

Promise.all and Promise.race are pretty cool combinators for promises.
Coordinating asynchronous events can quickly get dirty when done by hand.

On timing:

#+BEGIN_QUOTE
To avoid surprises, functions passed to then() will never be called
synchronously, [...]

Instead of running immediately, the passed-in function is put on a microtask
queue, which means it runs later when the queue is emptied at the end of the
current run of the JavaScript event loop, i.e. pretty soon:
#+END_QUOTE

So it's not a setTimeout(_, 0): it doesn't put the task at the end of the queue,
instead it doesn't wait until the next tick.  So:

#+BEGIN_SRC js
console.log('before')
setTimeout(_ => console.log('timeout'), 0)
Promise.resolve().then(_ => console.log('promise'))
console.log('after')
#+END_SRC

yields:

#+BEGIN_EXAMPLE
before
after
promise
timeout
#+END_EXAMPLE

There is a potential latency gain when the event queue is long.

* [2018-12-12 mer.]
** Strange behavior with Promises in workers                    :promises:js:
When trying to upgrade s3c to work with Promises, I encountered a strange
behavior.

Evaluating the following code:

#+BEGIN_SRC js
Promise.resolve().then(_ => aoreisnt())
#+END_SRC

triggers an error in the JS console:

: Unresolved promise rejection: aoreisnt is not defined

But evaluating it inside s3c does not show any error.  The worker.onerror
callback is not triggered by it.

In fact, having a worker with just that line above does /not/ trigger an
Unresolved promise rejection in Firefox.  It /does/ produce an

: Uncaught (in promise) ReferenceError: aoreisnt is not defined

in Chromium, but that error is /not/ a worker error that can be caught using the
onerror callback.

So, in fact, there appears to be no way of catching this error from the spawner.

* [2018-12-24 lun.]
** Trying out Rust for a cross-platform GUI app                    :rust:gui:
Ek.  So, Electron is the easy choice I would be the most familiar with which
would give me the same behavior in all platforms.  Upsides: familiarity,
consistent UX and fine-grained control using HTML+CSS.  Downsides: bundles Blink
and V8, which eats loads of RAM and gives you huge binaries.

Also, I would have prefered doing it in Rust.  Found [[https://github.com/Boscop/web-view][webview]] which is kinda the
same thing as Electron, but instead of bundling Blink, it uses the webview
that's available natively on the platform.  Upsides: same control as Electron,
but without the bloated binary.  Downsides: still eats loads of RAM (we /are/
running a browser view), and now you have to worry about platform differences.

I tested webkit2gtk and MSHTML.  The latter does not support ES6 syntax.  Both
are also rather slow when displaying 10 images in a window...

I tried [[https://github.com/vurtun/nuklear][nuklear]].  There are rust bindings.  Somehow, I find the font rendering
blurry.  The UI feels snappy, but it uses even more RAM than webview, and of
course more CPU (because it's an immediate UI).  No cross-platform differences
though.

I also tried [[https://github.com/LeoTindall/libui-rs][libui]].  Looks more interesting than nuklear, as it's using native
UI toolkits behind the scenes, but it's /very incomplete/.  The rust bindings
don't have a way to include an image (which the upstream only added in August).

So it looks like the sanest solution is to use webview.  It would be great if
webview supported using EdgeHTML on Win10 instead of IE.  Hopefully the app will
not feel too sluggish.

* [2019-01-08 mar.]
** Fixing a bug with s3c and lambda syntax                              :s3c:
In the following code, the evaluation comment does not bind to anything:

#+BEGIN_SRC js
let f = x => x //:
f(1)
#+END_SRC

Now, I was expecting the evaluation marker to show ~1~, since it's the value of
the preceding expression.  It does work if I use a block for the lambda:

#+BEGIN_SRC js
let f = x => {
  x //: 1
}
f(1)
#+END_SRC

So one solution is to transform all lambda calls to have a block ending with a
~return~, in order to preserve the semantics.

But wait, when you add the ~return~, the evaluation marker does not behave as
expected:

#+BEGIN_SRC js
let f = x => {
  return x //:
}
f(1)
#+END_SRC

Still empty.  Well, let's look at the AST then:

#+BEGIN_EXAMPLE
ArrowFunctionExpression
- BlockStatement
  - ReturnStatement
    - Identifier 'x'
#+END_EXAMPLE

There is no ExpressionStatement anywhere before the marker, so we cannot bind to
anything.  In fact, this happens with any declaration:

: var f = 0 //:

Well, for this example it's a bit silly to expect a value, since a ~var~ has
none.  The same could be argued for ~return~: it's not an expression, and thus
has no value.  In fact, the ~return~ doesn't bind to markers in standard
functions as well:

#+BEGIN_SRC js
function f(x) {
  return x //:
}
f(1)
#+END_SRC

So we could try to bind the marker to the argument of the return.

I did just that.  More complicated than expected because of the way the code
worked.  But in the end it allows us to use a marker on a return, which is a
good thing.

However, the issue with arrow functions is still not fixed, because there's an
ambiguity.  Should the marker bind to the function expression, or to the body
expression?  Should we expect:

#+BEGIN_SRC js
f = x => x //: function
f(1)
#+END_SRC

or:

#+BEGIN_SRC js
f = x => x //: 1
f(1)
#+END_SRC

I prefer the latter, because the former does not give any useful information.
It's likely that using a marker in an arrow function is for probing at the body,
not at the arrow function itself.

But it may introduce a precedent: should we expect the markers to always report
the value of the nearest expression?  What of:

#+BEGIN_SRC js
x = 10
f = x + 1 //:
#+END_SRC

Should the marker show '11', the value of the right-hand of the assignment, or
'1', the value of the nearest expression (the literal '1')?

More special cases... On the other hand, if I special-case arrow functions, I
can also special-case variable declarations to yield:

#+BEGIN_SRC js
let x = 1 //: 1
#+END_SRC

Because currently the marker will not bind to anything.

Essentially, the problem is a mix of assigning a value to statements in JS, and
coming up with helpful values to show when placing the marker.

Wait, what if we have:

#+BEGIN_SRC js
a = x => x //: ??
#+END_SRC

Do we show the value of ~x~, or the right-hand side of the assignment?  The
former would be more consistent, but it basically means that anywhere arrow
functions may appear, we need to look for them first, and bind the markers to
their body.

I'm warry of doing this, since then we have to make sure the arrow function is
next to the marker physically...

It gives me an idea: maybe we can actually walk back from the location of the
marker until we hit a node.  Then we would have to determine the parent
expression that would give the marker its value.  It might yield more intuitive
results using the "trailingComments" method currently.

In any case, it's too complex a refactoring for what I wanted to do today.  I'll
ship the ~return~ patch and stop here.

It's only a minor inconvenience anyway.

* [2019-02-01 ven.]
** Turing quote on emergent system properties                         :quote:
Once, as I attended a talk by a prominent researcher in programming languages,
I heard something that didn't seem right.  He said that if you are given the
grammar of a language, then you know everything about that language.

I beg to differ.  The grammar does not give you one clue about the semantics.
Yes, you know how to combine the syntactic elements to form valid sentences, but
that is just the start.

To use a programming, you need to know its idioms, how some tasks are usually
written, and ultimately, to construct a mental model of its semantics in order
to achieve your goals.

Anyway, I learned that day that prominent researchers could be dead wrong.

This quote by Turing always reminds me of that event:

#+BEGIN_QUOTE
The view that machines cannot give rise to surprises is due, I believe, to a
fallacy to which philosophers and mathematicians are particularly subject.  This
is the assumption that as soon as a fact is presented to a mind all consequences
of that fact spring into the mind simultaneously with it.  It is a very useful
assumption under many circumstances, but one too easily forgets that it is
false.  A natural consequence of doing so is that one then assumes that there is
no virtue in the mere working out of consequences from data and general
principles.
#+END_QUOTE

However, there is maybe one interesting observation to salvage from the
speaker's comment: it makes me think about the usefulness of isomorphic
languages; languages that have different syntaxes and grammars, but isomorphic
semantics.

* [2019-03-22 ven.]
** Trying out Haxe                                                     :haxe:
I was looking for a programming language in which I could prototype, but also
reasonably take that prototype into a full product without having to rewrite it
in another language.

I wanted something reasonably performant, ideally able to generate native
binaries.  C is nice, but not so fast at prototyping, and also lacks nice
language conveniences like pattern matching or actual types.  Rust is too
verbose and cumbersome to prototype with.  JS is too loose to be used for a real
product, and also lacks niceties.  Typescript has better features but again it's
restricting the output.

I looked at getting back to some Lisp.  Looked briefly at Clojure, but I don't
think it's suited for games.  Too much mutable state.

Then I remembered about Haxe.  It's main purpose is to be a game programming
language.  It's used to ship real games on desktop, mobile and consoles.  The
language has nice features, and the syntax is close enough to JS so it should be
easy to pick up and prototype with, while leaving the possibility of compiling
to native code.

There are a few libraries for games.  The mature ones are mostly about graphics,
but at least there's choice.

Tried out Heaps, which can compile to HTML5 and native code.  Both work nicely,
although the tooling is a bit rough.  Compiling to C requires finding out the
right gcc invocation.  Also it didn't seem to work correctly without the latest
Haxe 4.0 (+ Hashlink 1.9) which is currently a preview release.

It's all open source.  The community looks small, but focused on games and game
tools.

Will try to play with it some more.

* [2019-03-30 sam.]
** Table of contents                                         :emulators:book:
To have a good start with emulation, here is a first draft:

*** Contents
Intro
1. What you'll learn
   - how emulators (and interpreters/VMs) work
   - how 8bit/16bit machines work (sprites systems, sound generators)
2. What you won't learn
   - how to emulate modern machines

Part I: The first emulator (CHIP8/CHIP16)
1. Overview
   - what's in an emulator
   - how we develop it
2. The fetch-decode-execute loop
   - nothing without a ROM
3. Arithmetic and control instructions
   - Registers, memory layout
4. Graphics
   - sprites, layers
   - pixel pipeline
5. Sound
   - how sound is produced and heard
   - timing
6. What's next
   - increasing correctness (testing)
   - adding cool features (save states, rewind, networked multiplayer)
   - optimizing

Part II: Beyond
1. Ways to implement opcodes
   - big switch
   - big table
   - generated code
2. Debugging
   - Debugging non-working games
     - Reproduce
     - Gather data
     - Compare against hardware/other emu
     - Check specs
   - Adding debugging tools
     - A CPU debugger
     - A view into the graphics system
3. Testing
   - Test components separately
   - Test games with input record & replay
4. Optimizing
   - Profiling
   - Threaded code
   - Dynamic recompilation
   - Multithreading
     - run graphics and sounds in parallel

5. Reverse engineering hardware (guest chapter?)

Appendix (knowledge reader will need but may not have):
- hexadecimal reference
- C basics?
*** Choices
Still on the fence about CHIP16.  CHIP8 is definitely too simple to prepare you
for GB, but you have to start somewhere right?  CHIP8 is good for that because
it's very simple, so you can actually finish it in reasonable time.

However, GB is better because of nostalgia factor, and there are plenty of games
you can run in order to improve the emu.  But Tetris is simple enough to have as
a target for the book (does not need full compatibility).

Programming language.  Rust is trendy, but it's also a barrier to entry for
readers.  C feels like a better choice: larger audience, and Rust enthusiasts
should still be able to follow.  Downsides: have to be careful about
portability.  Multithreading section in particular may be tricky, but I can also
drop that one.  It doesn't have to be exhaustive.

* [2019-03-31 dim.]
** Trying out space invaders                                 :emulators:book:
Pain points:

- How to get ROM.  Dump?  Hard to find a copy, unlike Tetris.  Makes it non-self
  contained.  Don't want to encourage grabbing a ROM of the internet.

  At least providing a checksum ensures we have the same file to work from.

- Implement opcodes as you go along

- Endianness and constructing/desconstructing addresses from parts.

- Disassembler alone is not useful since data is mixed with code.  Even
  implementing only control instructions is not enough, since branches need flag
  info.

- Implementing the opcodes in the naive way has lot of redundancy, so
  error-prone.  Errors that are hard to track down.  Might be better to define a
  mini-DSL using macros (especially to check flags).

  Also, often there is a regularity in opcode that can be exploited: DEC B, C,
  D, E will all share the same opcode, with just two bits changing.

* [2019-04-01 lun.]
** Plugging the YM3438 into megado                            :megado:ym2612:
Found [[https://github.com/nukeykt/Nuked-OPN2][this YM3438 implementation]], which is compatible with the YM2612.  The API
seems simple enough, so I tried to plug it in megado to hear how it sounds.

First difficulty: what exactly is OPN2_Write accepting?  Is it the addresses
used by the MD, or is it something else?  The MD has a small ceremony in order
to write to the YM2612 using only one bus: first write an address (of an
internal register to the YM2612), then data.  In particular, there are two
"parts", corresponding to channels 1-3 and 4-6, you can address.

Contrast that to GYM opcodes, which write directly to part I or part II,
bypassing the indirect addressing of the MD.

It looks like the YM3438 implementation matches what the MD does.  Looking at
[[https://github.com/nukeykt/Genesis-Plus-GX/commit/68e047bd4c68bed4ab0b688051760bf2c1e527f1][this patch of GenesisPlusGX]] was helpful.

I our ym2612 implementation to delegate to YM3438, but it did not produce any
sound.  Looking at OPN2_Write and the patch above, they run differently than we
run the YM2612 in megado.  In megado, the main loop is this:

#+BEGIN_SRC c
// The m68k can halt prematurely due to breakpoint
uint32_t actual_cycles = m68k_run_cycles(g->m68k, cycles);

// Let the other systems catch up
z80_run_cycles(g->z80, actual_cycles);
psg_run_cycles(g->psg, actual_cycles);
ym2612_run_cycles(g->ym2612, actual_cycles);
vdp_run_cycles(g->vdp, actual_cycles);
#+END_SRC

This emulates the m68k first, counts the actual elapsed time in master cycles,
then run all the other systems to catch up.  In practice we run this loop for
one frame of cycles, and it works fine for most things.

But it is incorrect of course: in real hardware, all these systems run in
parallel.

Genesis Plus GX does things differently, at least for the FM chip.  Whenever a
write is done to the FM chip, that chip is immediately emulated to catch up with
the CPU, then the write is actually done.

It's actually the smart way to do it without threading: as long as the CPU does
not touch the FM chip, you may as well ignore the FM.  When the CPU does need to
communicate with the FM chip, then you synchronize the chip.

In fact, the YM3438 is written to work like this.  See OPN2_Write:

#+BEGIN_SRC c
void OPN2_Write(ym3438_t *chip, Bit32u port, Bit8u data)
{
    port &= 3;
    chip->write_data = ((port << 7) & 0x100) | data;
    if (port & 1)
    {
        /* Data */
        chip->write_d |= 1;
    }
    else
    {
        /* Address */
        chip->write_a |= 1;
    }
}
#+END_SRC

It emulates nothing.  It does not even write to the actual register of the FM
chip!  It just latches the address written by the CPU for the ceremonious
protocol of the MD.  This means that, in megado, when emulating the m68k, we
may call this write function multiple times, which erases previous calls,
without hitting the FM chip at all!

The solution is to catch-up the YM2612 whenever we write to it, like Genesis
Plus GX does.  This means we don't even need to catch up the YM2612 in the main
loop anymore.  We can just catch up on read/write.  The same principle can be
applied to other systems as well, but this would require a larger rewriting.

Now, after this fix, it does sound okayish, but not very good.  When looking at
the Genesis Plus patch, I'm seeing that YM3438_Update is buffering all the
samples used by a frame:

#+BEGIN_SRC c
/* FM output buffer (large enough to hold a whole frame at original chips rate) */
static int fm_buffer[1080 * 2 * 24];

void YM3438_Update(int *buffer, int length)
{
  int i, j;
  for (i = 0; i < length; i++)
  {
    OPN2_Clock(&ym3438, ym3438_accm[ym3438_cycles]);
    ym3438_cycles = (ym3438_cycles + 1) % 24;
    if (ym3438_cycles == 0)
    {
      ym3438_sample[0] = 0;
      ym3438_sample[1] = 0;
      for (j = 0; j < 24; j++)
      {
        ym3438_sample[0] += ym3438_accm[j][0];
        ym3438_sample[1] += ym3438_accm[j][1];
      }
    }
    *buffer++ = ym3438_sample[0] * 8;
    *buffer++ = ym3438_sample[1] * 8;
  }
}
#+END_SRC

Instead, what megado does right now is to poll the YM2612 for samples, after we
have emulated enough for a frame.  The megado approach has the advantage of
getting exactly the right number of samples (not too many).  But it has the
downsides that you can't just drop audio samples like you drop video frames: the
sound itself can change dramatically.

So I'll try the same approach: buffer YM3438 samples for a full frame, use a
proper resampler (blip_buf, same as Genesis Plus), and give that to SDL.

Hmm, so I did manage to integrate blip, but the results are actually worse.  So
there's probably something I didn't understand along the way.  Ahhhh. That's
always the annoying part of writing emulators: there's just too much data coming
in and out that so when it goes wrong, it goes wrong /fast/, and you have
garbage everywhere.  It's also tedious to step through it because there's just
too much data.

Maybe I should try blip & YM3438 on the GYM player where there are fewer moving
parts.

* [2019-04-14 dim.]
** Space invaders success                                   :emulation:spinv:
Since I got pretty far today in the cpudiag ROM, I figured I needed to hook the
display.  The SDL2 docs are really not beginner friendly, but there are useful
examples hidden inside.

At first I got garbage:

[[file:data/spinv-fail0.png]]

It looked like I wasn't using the full display width.  And indeed I wasn't:

#+BEGIN_SRC c
for (u32 y=0; y < 256; ++y)
  for (u32 x=0; x < 32; ++x)
    for (u8 b=0; b < 8; ++b)
      if ((cpu.ram[0x2400 + y*32 + x] >> b) & 1)
        SDL_RenderDrawPoint(renderer, x, y);
#+END_SRC

x only goes to 31 here, while the width is 224.  Need to account for b:

:       SDL_RenderDrawPoint(renderer, 8*x + b, y);

[[file:data/spinv-success.png]]

Yeah!  Ah well, it needs to be rotated, as was the original cabinet.

It's interesting to see how much a difference some tweaks to the parameters
make: (x + b, y) yields:

[[file:data/spinv-fail1.png]]

While (x + 8*b, y) gives:

[[file:data/spinv-fail2.png]]

I guess that in both cases you can still see that you we are not using the full
width, so it's a hint to check the x coordinate again.  But still, these tiny
errors can have wide repercussions.

* [2019-06-07 ven.]
** GBS to MIDI                                                :emulation:gbs:
That was one of the initial point, wasn't it?

Well MIDI format is not that complicated, but I need something a bit simpler to
start with.  Can I extract "note on"/"note off" events from the GB APU?

Bit 7 of NR14 should be the trigger, so if we look at that only, and look at
frequencies, we get:

#+BEGIN_EXAMPLE
note on, 658.65326 0.24609375
note on, 494.61133 0.24609375
note on, 524.288 0.24609375
note on, 587.76685 0.24609375
note on, 524.288 0.24609375
note on, 494.61133 0.24609375
note on, 439.83893 0.24609375
note on, 439.83893 0.24609375
note on, 524.288 0.24609375
note on, 658.65326 0.24609375
note on, 587.76685 0.24609375
#+END_EXAMPLE

and it's indeed the first Tetris BGM.  The frequencies are slightly off, when
compared to A440, but the tune is recognizable.

Second column is supposed to be the length, but it's suspiciously all the same
values.  I think it's better to watch for the volume going off anyway.

Not sure how MIDI handles envelope though.  But at least, if we add a timing
information, we could maybe extract an ABC notation from the pulse channels.

* [2019-07-14 dim.]
** Visualizing memory reads/writes for CHIP8              :chipers:emulation:
Wanted to see if we could get interesting/pretty pictures or videos out of it.

Just hooked into the memory code: I already had code to count reads and writes
for the memory viewer.  Unfortunately, chipers failed with a mysterious SIGILL
when running in release mode.  Updated to latest rust and dependencies... took a
while to update the API calls.

Then I ran each ROM 10sec, and dumped all reads/writes in a PPM.  Reads in red,
writes in blue:

[[file:data/blink-reads-writes.png]]

Not particularly interesting.  Most ROMs just writes their program to RAM then
read a few memory places.

I also extracted videos, by dumping PPM each frame and stitching them with
ffmpeg.  The result is less static, but not more insightful.

Actually, I wanted to do that for the NES or fancier console, but then I needed
to go further than the title screens for making it interesting.  That would
require replaying inputs.  So first step is finding inputs to replay.
